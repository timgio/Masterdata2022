{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "A\n",
      "ok\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "## run-1\n",
    "## download data sku dari tatanama\n",
    "## common problems: slow server pyany & make sure path to file\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib \n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "print('A')\n",
    "data_SKU = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "print('A')\n",
    "s = requests.Session()\n",
    "s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "with open(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "    output.write(r.content)\n",
    "    \n",
    "print('ok')\n",
    "\n",
    "if os.path.isfile(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx') :    \n",
    "    SKU_append = pd.read_excel(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx')\n",
    "    SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "to_excel = data_SKU.to_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx', index = False)\n",
    "print('A')\n",
    "data_SKU['Price List NFI'] = data_SKU['Price List NFI'].astype(float).astype('int64')\n",
    "\n",
    "download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## run-2\n",
    "## belum scrap dari forstok\n",
    "download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Forstok Date\n",
      "2022-06-27-2022-07-07\n",
      "Opening Chrome\n",
      "Login Forstok\n",
      "Forstok Downloaded\n",
      "Download Data SKU\n",
      "Waiting to Download Forstok\n",
      "https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/nutrifood--forstok-sales_orders-version_1-2022-06-27-2022-07-07.xls\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "200\n",
      "Import Data ====== 1/10\n",
      "--- 11.249543190002441 seconds ---\n",
      "Formatting Data ====== 2/10\n",
      "--- 17.538622856140137 seconds ---\n",
      "Fulfilling SKU ====== 3/10\n",
      "--- 91.69492363929749 seconds ---\n",
      "Listing SKU Missing ====== 4/10\n",
      "--- 148.27203249931335 seconds ---\n",
      "Filling Brand ====== 5/10\n",
      "--- 148.89585709571838 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 149.87148332595825 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:636: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n",
      "bulk-order-download-template.csv\n",
      "Import Data ====== 1/10\n",
      "--- 354.27478647232056 seconds ---\n",
      "Formatting Data ====== 2/10\n",
      "--- 354.29043531417847 seconds ---\n",
      "Listing SKU ====== 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1051: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SKU                                    Product Name\n",
      "124  (U)2307061250  [Gift] L-Men High Protein 2 Go 200 ml (1 pcs) \n",
      "487  (B)2104148164        (PBI) Tropicana Slim Mint Cocoa 4 Sachet\n"
     ]
    }
   ],
   "source": [
    "## run-3\n",
    "## scrap data forstok & blibli lmen\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "diff_date = 10\n",
    "# data_prev = '7 Juli'\n",
    "data_now = str(datetime.today().day) + ' ' + str(datetime.today().strftime(\"%B\"))\n",
    "\n",
    "print('Input Forstok Date')\n",
    "start_date = datetime.today() - timedelta(days=diff_date)\n",
    "end_date = datetime.today()\n",
    "date = start_date.strftime('%Y-%m-%d') + '-' + end_date.strftime('%Y-%m-%d')\n",
    "print(date)\n",
    "\n",
    "if not download:\n",
    "    print('Opening Chrome')\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "    print('Login Forstok')\n",
    "    username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"andra.miftah@nutrifood.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "    password.send_keys(\"nutrimart1234\")\n",
    "\n",
    "    driver.find_element_by_name(\"commit\").click()\n",
    "\n",
    "    #komen 5 juli 2022 forstok ganti layout\n",
    "    # datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.ID, 'history_date'))) \n",
    "    # datefield.click()\n",
    "\n",
    "    # driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    # if start_date.month == end_date.month:\n",
    "    #     text = \"//div[@class='drp-calendar right']//td[@class = 'available' or @class='weekend available' or @class='in-range available' or @class = 'weekend in-range available' or @class = 'active start-date in-range available' or @class = 'weekend active start-date in-range available'][text() = \" + str(start_date.day) + \"]\"\n",
    "    # else :\n",
    "    #     text = \"//div[@class='drp-calendar left']//td[@class = 'available' or @class='weekend available' or @class='in-range available' or @class = 'weekend in-range available'][text() = \" + str(start_date.day) + \"]\"\n",
    "    # driver.find_element_by_xpath(text).click()\n",
    "    # time.sleep(2)\n",
    "    # text = \"//div[@class='drp-calendar right']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "    # driver.find_element_by_xpath(text).click()\n",
    "    # time.sleep(2)\n",
    "    # driver.find_element_by_class_name('applyBtn').click()\n",
    "    # driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "    # time.sleep(15)\n",
    "    # WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'export-button'))).click()\n",
    "    # driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    # time.sleep(2)\n",
    "    # WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'group_by_'))).click()\n",
    "    # driver.find_element(By.NAME, 'button').click()\n",
    "    # time.sleep(5)\n",
    "    # driver.quit()\n",
    "    #komen 5 juli 2022\n",
    "    \n",
    "    ##### kode timo 5 juli\n",
    "    datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH,'//*[@class=\"sc-iybRtq jRqWsV\"]')))\n",
    "    datefield.click()\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    pilih=0\n",
    "    while pilih < 3:      \n",
    "        if start_date.month == end_date.month:\n",
    "            text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "        else :\n",
    "            text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "        time.sleep(10)\n",
    "        text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "        time.sleep(10)\n",
    "        pilih=pilih+1\n",
    "    driver.find_element_by_xpath('//*[@type=\"button\" and contains(text(),\"Apply\")]').click()\n",
    "    # driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "    time.sleep(15)\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[1]\"))).click()\n",
    "    driver.find_element_by_xpath('//span[text()=\"Sales Order\"]').click()\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[2]\"))).click()\n",
    "    # driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    time.sleep(2)\n",
    "\n",
    "    driver.quit()\n",
    "    ##### kode timo 5 juli\n",
    "    \n",
    "#     driver = webdriver.Chrome()\n",
    "#     driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "#     username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "#     username.clear()\n",
    "#     username.send_keys(\"andra.miftah@nutrifood.co.id\")\n",
    "\n",
    "#     password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "#     password.send_keys(\"nutrimart1234\")\n",
    "\n",
    "#     driver.find_element_by_name(\"commit\").click()\n",
    "\n",
    "#     datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[2]/section/div')))\n",
    "#     datefield.click()\n",
    "\n",
    "#     driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#     if start_date.month != end_date.month:\n",
    "#         text = \"//*[normalize-space(text()) = '\" + str(start_date.strftime('%B')) + \"']\"\n",
    "#         driver.find_element_by_xpath(text).click()\n",
    "#     text = \"//*[normalize-space(text()) = '\" + str(start_date.strftime('%B')) + \"']\" + \"/../..//*[normalize-space(text()) = '\" + str(start_date.day) + \"']\"\n",
    "#     driver.find_element_by_xpath(text).click()\n",
    "#     text = \"//*[normalize-space(text()) = '\" + str(end_date.strftime('%B')) + \"']/../..//td[not(contains(@class, 'otherMonth'))]//*[normalize-space(text()) = '\" + str(end_date.day) + \"']\"\n",
    "#     driver.find_element_by_xpath(text).click()\n",
    "\n",
    "#     driver.find_element_by_xpath('//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[2]/section/section/aside/div/button[2]').click()\n",
    "#     driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "#     time.sleep(15)\n",
    "#     WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[1]/button'))).click()\n",
    "#     driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#     time.sleep(2)\n",
    "#     driver.find_element(By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[2]/section[1]/div/div[1]/label').click()\n",
    "#     driver.find_element(By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[2]/section[2]/button').click()\n",
    "#     time.sleep(5)\n",
    "#     driver.quit()\n",
    "\n",
    "    print('Forstok Downloaded')\n",
    "    download = True\n",
    "\n",
    "print('Download Data SKU')\n",
    "# Import library\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib \n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "\n",
    "print('Waiting to Download Forstok')\n",
    "s = requests.Session()\n",
    "r = s.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "data = {'dashboard_user_email' : 'andra.miftah@nutrifood.co.id', \"dashboard_user_password\" : 'nutrimart1234'}\n",
    "r = s.post(\"https://www.forstok.com/dashboard/users/login\", data = data)\n",
    "\n",
    "text = 'https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/nutrifood--forstok-sales_orders-version_1-' + date + '.xls'\n",
    "print(text)\n",
    "while True:\n",
    "    r = s.get(text)\n",
    "    print('Waiting to Download Forstok')\n",
    "    \n",
    "    if r.status_code == requests.codes.ok:\n",
    "        print(r.status_code)\n",
    "        with open('Input Data/Forstok_new_input.xls', 'wb') as output:\n",
    "            output.write(r.content)\n",
    "        break\n",
    "    else :\n",
    "        time.sleep(60)\n",
    "           \n",
    "with open('Input Data/nutrifood--forstok-sales_orders-' + date + '.xls', 'wb') as output:\n",
    "    output.write(r.content)\n",
    "    \n",
    "    \n",
    "# data_SKU = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx')\n",
    "\n",
    "# s = requests.Session()\n",
    "# s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "# s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "# r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "# with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "#     output.write(r.content)\n",
    "\n",
    "# if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "#     SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "#     SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "#     data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "#     data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "# to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "# Import data\n",
    "start_time = time.time()\n",
    "print(\"Import Data ====== 1/10\")\n",
    "\n",
    "# data_forstok1 = pd.read_excel(r'Input Data/nutrifood--forstok-sales_orders-version_1-2021-08-30-2021-09-15.xls')\n",
    "# data_forstok2 = pd.read_excel(r'Input Data/nutrifood--forstok-sales_orders-version_1-2021-09-10-2021-09-16.xls')\n",
    "# data_forstok1  = data_forstok1[~data_forstok1['Sales Order ID'].isin(data_forstok2)]\n",
    "# data_forstok = data_forstok1.append(data_forstok2, ignore_index = True, sort = False)\n",
    "data_forstok = pd.read_excel(r'Input Data/Forstok_new_input.xls')\n",
    "data_forstok_pure = data_forstok.copy()\n",
    "data_forstok = data_forstok.dropna(how = 'all')\n",
    "\n",
    "# display(data_forstok.groupby(['Store'])[['Order Date']].max().reset_index())#################\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "# Forstok formatting\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Formatting Data ====== 2/10\")\n",
    "\n",
    "if 'Unnamed: 35' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 35'], axis = 'columns')\n",
    "if 'Unnamed: 36' in data_forstok:\n",
    "    data_forstok = data_forstok.rename(columns={'Unnamed: 36' : 'Comment'})\n",
    "if 'Unnamed: 37' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 37'], axis = 'columns')\n",
    "if 'Unnamed: 38' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 38'], axis = 'columns')\n",
    "if 'Unnamed: 39' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 39'], axis = 'columns')\n",
    "if 'Unnamed: 40' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 40'], axis = 'columns')\n",
    "if 'Unnamed: 41' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 41'], axis = 'columns')\n",
    "    \n",
    "data_forstok[\"Order Date\"] = pd.to_datetime(data_forstok[\"Order Date\"], errors = 'coerce')\n",
    "data_forstok[\"Paid Date\"] = pd.to_datetime(data_forstok[\"Paid Date\"], errors = 'coerce')\n",
    "data_forstok[\"Cancelled Date\"] = pd.to_datetime(data_forstok[\"Cancelled Date\"], errors = 'coerce')\n",
    "data_forstok['Customer Name'] = data_forstok['Customer Name'].fillna(data_forstok['Shipping Name'])\n",
    "data_forstok = data_forstok.rename(columns = {'Seller Voucher' : 'Seller Discount'})\n",
    "data_forstok = data_forstok[~((data_forstok['Store']=='Shopee')&(data_forstok['Order Date']<'21-12-2021'))] ###TMO###\n",
    "\n",
    "# Phone formatting\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('=','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('\"','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('(','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace(')','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('-','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('+','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^620','0', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^62','0', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^620','0', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^8','08', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^21','021', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^008','08', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('(021)','021', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('+62','0', regex = False)\n",
    "\n",
    "# display(data_forstok.groupby(['Store'])[['Order Date']].max().reset_index())##################\n",
    "# print(data_forstok.info())\n",
    "\n",
    "# Forstok SKU\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Fulfilling SKU ====== 3/10\")\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str) == 'Buy 1 Get 1 FREE Tropicana Slim Goldenmil Vanilla Manuka Honey (6 Sch)'][data_forstok[data_forstok['Item Name'].astype(str) == 'Buy 1 Get 1 FREE Tropicana Slim Goldenmil Vanilla Manuka Honey (6 Sch)']['SKU'] == 'PE8B27'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = '2101384106P2'\n",
    "data_forstok.loc[data_forstok['SKU']==\"(E)2101492P04\",'SKU']=\"(E)2101492P4\"\n",
    "# data_forstok.loc[data_forstok['SKU']==\"2305551161\",'SKU']=\"2305551106\"\n",
    "\n",
    "skushopee = data_forstok[data_forstok['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "data_forstok = data_forstok[~data_forstok['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "\n",
    "skushopee = skushopee.reset_index(drop = True)\n",
    "data_forstok = data_forstok.reset_index(drop = True)\n",
    "\n",
    "forstok_all_sku = pd.read_excel(r'SKU_File\\forstok_all_sku.xlsx')\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in data_SKU['Nama Produk'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == data_SKU['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in forstok_all_sku['Item Name'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = forstok_all_sku['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == forstok_all_sku['Item Name'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str).str.contains(' - ')].index.to_list()\n",
    "# Formatting double name\n",
    "for i in indeks:\n",
    "    if data_forstok['Item Name'][i].count(' - ') == 1 :\n",
    "        if (data_forstok['Item Name'][i].split(' - ')[0] == data_forstok['Item Name'][i].split(' - ')[1]):\n",
    "            data_forstok['Item Name'][i] = data_forstok['Item Name'][i].split(' - ')[0]\n",
    "    elif data_forstok['Item Name'][i].count(' - ') > 1:\n",
    "        temp = math.ceil(data_forstok['Item Name'][i].count(' - ')/2)\n",
    "        itemname = ''\n",
    "        duplicate = ''\n",
    "        for j in range(temp):\n",
    "            if j == 0:\n",
    "                itemname = itemname + data_forstok['Item Name'][i].split(' - ')[j]\n",
    "                duplicate = duplicate + data_forstok['Item Name'][i].split(' - ')[temp+j]\n",
    "            else :\n",
    "                itemname = itemname + ' ' +data_forstok['Item Name'][i].split(' - ')[j]\n",
    "                duplicate = duplicate + ' ' +data_forstok['Item Name'][i].split(' - ')[temp+j]\n",
    "        if itemname == duplicate:\n",
    "            data_forstok['Item Name'][i] = itemname\n",
    "        \n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace(r' - $', '')\n",
    "data_forstok[\"Item Name\"] = data_forstok[\"Item Name\"].str.replace('Special Promo by Nutrimart Serba 12 RIBU Varian:', '', regex=False)\n",
    "data_forstok[\"Item Name\"] = data_forstok[\"Item Name\"].str.replace('Khusus Jabodetabek', '- Khusus Jabodetabek', regex=False)\n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace('Buy 1 Get F', 'Buy 1 Get 1 F')\n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace('Buy 1 Get H', 'Buy 1 Get 1 H')\n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace('Buy 12 FREE', 'Buy 12 FREE 12')\n",
    "\n",
    "# Formatting SKU based on name\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower().strip() in data_SKU['Nama Produk'].astype(str).str.lower().str.strip().values:\n",
    "        data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower().strip() == data_SKU['Nama Produk'].astype(str).str.lower().str.strip()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in forstok_all_sku['Item Name'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = forstok_all_sku['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == forstok_all_sku['Item Name'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.tolist()\n",
    "\n",
    "data_adasku = data_forstok[['Item Name', 'SKU']]\n",
    "data_adasku = data_adasku[data_adasku['SKU'].notnull()]\n",
    "\n",
    "data_nosku = data_forstok[['Item Name', 'SKU']]\n",
    "data_nosku = data_nosku[data_nosku['SKU'].isnull()]\n",
    "\n",
    "for i in indeks:\n",
    "    if data_adasku['SKU'].loc[data_nosku['Item Name'][i] == data_adasku['Item Name']].size != 0:\n",
    "        data_forstok['SKU'][i] = data_adasku['SKU'].loc[data_nosku['Item Name'][i] == data_adasku['Item Name']].values[0]\n",
    "\n",
    "for i in indeks:\n",
    "    if data_forstok['Item Name'][i] == 'Lokalate Kopi Durian 10s':\n",
    "        data_forstok['SKU'][i] = '1101675318'\n",
    "    elif data_forstok['Item Name'][i] == 'Nutrisari Madu Kurma Isi 16 Renceng X 10 Sachet Karton' or data_forstok['Item Name'][i] =='Nutrisari Madu Kurma Isi 16 Renceng X 10 SachetKarton': \n",
    "        data_forstok['SKU'][i] = 'PN30(16)'\n",
    "    elif data_forstok['Item Name'][i] == 'L-Men Protein Bar Crunchy Chocolate Isi X12 (Exp Date:10-Apr-2019)':\n",
    "        data_forstok['SKU'][i] = '2306592173'\n",
    "    elif data_forstok['Item Name'][i] == 'FS Hilo Active Chocolate Minuman Kesehatan [750 gr]' or data_forstok['Item Name'][i] == 'FSHilo Active Chocolate Minuman Kesehatan [750 gr]':\n",
    "        data_forstok['SKU'][i] = '2101452190'\n",
    "    elif data_forstok['Item Name'][i] == 'FS L-Men Platinum Suplemen Kesehatan + Free Spider Bottle [800 g] Hitam' or data_forstok['Item Name'][i] == 'FSL-Men Platinum Suplemen Kesehatan + Free Spider Bottle [800 g] Hitam':\n",
    "        data_forstok['SKU'][i] = '2305551288P1G26'\n",
    "    elif data_forstok['Item Name'][i] == 'NutriSari Premium ala Jus Mangga':\n",
    "        data_forstok['SKU'][i] = '1100534104'\n",
    "    elif data_forstok['Item Name'][i] == 'Buy 1 Get 1 FREE Tropicana Slim Sweetener Honey (50 Sch) - FS':\n",
    "        data_forstok['SKU'][i] = '2102501125P1G53'\n",
    "\n",
    "indeks = data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in forstok_all_sku['Item Name'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = forstok_all_sku['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == forstok_all_sku['Item Name'].astype(str).str.lower()].values[0]\n",
    "\n",
    "list_alias = []\n",
    "list_alias_name = []\n",
    "for colname in data_SKU.columns:\n",
    "    if 'Alias SKU' in colname:\n",
    "        list_alias.append(colname)\n",
    "    if 'Alias Nama' in colname:\n",
    "        list_alias_name.append(colname)\n",
    "\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias:\n",
    "        if str(data_forstok['SKU'][i]) in data_SKU[j].astype(str).values:\n",
    "            idx = data_SKU[str(data_forstok['SKU'][i]) == data_SKU[j].astype(str)].index.to_list()\n",
    "            for k in idx:\n",
    "                if str(data_forstok['Item Name'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "                    data_forstok['SKU'][i] = data_SKU['SKU'][k]\n",
    "                        \n",
    "indeks = data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias_name:\n",
    "        if str(data_forstok['Item Name'][i]).lower() in data_SKU[j].astype(str).str.lower().values:\n",
    "            data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == data_SKU[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in data_SKU['Nama Produk'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == data_SKU['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(skushopee['Item Name'][i]).lower() in data_SKU['Nama Produk'].astype(str).str.lower().values:\n",
    "        skushopee['SKU'][i] = data_SKU['SKU'].loc[str(skushopee['Item Name'][i]).lower() == data_SKU['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "        skushopee['SKU'][i] = '(S)' + str(skushopee['SKU'][i])\n",
    "\n",
    "indeks = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "for i in indeks:\n",
    "    for j in list_alias:\n",
    "        if str(skushopee['SKU'][i]).replace('(S)','') in data_SKU[j].astype(str).values:\n",
    "            idx = data_SKU[str(skushopee['SKU'][i]).replace('(S)','') == data_SKU[j].astype(str)].index.to_list()\n",
    "            for k in idx:\n",
    "                if str(skushopee['Item Name'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "                    skushopee['SKU'][i] = data_SKU['SKU'][k]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == 'Gift Sosro'].index.to_list()\n",
    "data_forstok = data_forstok.drop(indeks, axis = 0).reset_index(drop = True)\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str).str.contains('Fricella')].index.to_list()\n",
    "data_forstok = data_forstok.drop(indeks, axis = 0).reset_index(drop = True)\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str).str.contains('Zaskia Mecca')].index.to_list()\n",
    "data_forstok = data_forstok.drop(indeks, axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "# display(data_forstok.groupby(['Store'])[['Order Date']].max().reset_index())#########################\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Listing SKU Missing ====== 4/10\")\n",
    "\n",
    "data_forstok = data_forstok.append(skushopee, ignore_index = True, sort = False)\n",
    "data_forstok = data_forstok.reset_index(drop = True)\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == '71210111'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = 'PN28N29N34(2)N53N54N55'\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == '71210112'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = 'PN19N22N30N34(2)N53N55'\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == '(B) 2101656'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = '(B)2101656'\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str) == 'PRE ORDER NutriSari NUTRI-C1000 40sch Suplemen Kesehatan Vit C 1000mg '].index.to_list()\n",
    "data_forstok['SKU'][indeks] = '1102110453'\n",
    "\n",
    "# data_forstok.loc[data_forstok['Item Name']==\"Tropicana Slim Minyak Sunflower 946ml (3pcs) Free Apron Celemek Minyak Baik 100% Pure Sunflower Oil\",'SKU']=\"PT46(3)G145\"\n",
    "# data_forstok.loc[data_forstok['Item Name']==\"Buy 1 Get 1 FREE HiLo Active Caramel Latte 500gr - Susu Tinggi Kalsium\",'SKU']=\"2101478180C2\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"HiLo Active Caramel Latte 500gr - Susu Tinggi Kalsium\",'SKU']=\"2101478180\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"NutriSari Es Rujak 40 Sachet - Minuman Buah Vitamin C - Expired 4 Bulan\",'SKU']=\"(E)1101984453\"\n",
    "data_forstok.loc[data_forstok['SKU']=='PH39(12)U8(12) ','SKU']='PH39(12)U8(12)'\n",
    "\n",
    "\n",
    "shopee_con = pd.read_excel(r'Shopee Converter.xlsx')\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))][data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))]['Item Name'].astype(str).str.lower().isin(shopee_con['Product Name'].astype(str).str.lower())].index.to_list()\n",
    "product = data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))][data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))]['Item Name'].astype(str).str.lower().isin(shopee_con['Product Name'].astype(str).str.lower())]['Item Name'].unique()\n",
    "\n",
    "for i in product:\n",
    "    indeks_shopee = data_forstok.iloc[indeks][data_forstok.iloc[indeks]['Item Name'].astype(str).str.lower() == str(i).lower()].index.to_list()\n",
    "    data_forstok['SKU'][indeks_shopee] = shopee_con[shopee_con['Product Name'].astype(str).str.lower() == str(i).lower()]['Real SKU'].values[0]\n",
    "\n",
    "\n",
    "# indeks = data_forstok[data_forstok['SKU'].astype(str) == '2101453190'].index.to_list()\n",
    "# data_forstok['SKU'][indeks] = 'PH9G122'\n",
    "\n",
    "# indeks = data_forstok[data_forstok['SKU'].astype(str) == '2101453180'].index.to_list()\n",
    "# data_forstok['SKU'][indeks] = 'PH8G122'\n",
    "\n",
    "# indeks = data_forstok[data_forstok['Channel'].isin(['Blibli', 'Bukalapak', 'Tokopedia'])][data_forstok[data_forstok['Channel'].isin(['Blibli', 'Bukalapak', 'Tokopedia'])]['SKU'].astype(str) == '2101428180'].index.to_list()\n",
    "# data_forstok['SKU'][indeks] = 'PH4G122'\n",
    "\n",
    "# indeks = data_forstok[data_forstok['Channel'].isin(['Blibli', 'Bukalapak', 'Tokopedia'])][data_forstok[data_forstok['Channel'].isin(['Blibli', 'Bukalapak', 'Tokopedia'])]['SKU'].astype(str) == '2101428190'].index.to_list()\n",
    "# data_forstok['SKU'][indeks] = 'PH5G122'\n",
    "\n",
    "# indeks = data_forstok[data_forstok['Channel'].isin(['Blibli', 'Bukalapak', 'Tokopedia'])][data_forstok[data_forstok['Channel'].isin(['Blibli', 'Bukalapak', 'Tokopedia'])]['SKU'].astype(str) == '2101401180'].index.to_list()\n",
    "# data_forstok['SKU'][indeks] = 'PH3G122'\n",
    "\n",
    "to_excel = data_forstok.to_excel(r'forstok_new.xls', index = False)\n",
    "\n",
    "skushopee = data_forstok[data_forstok['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "data_forstok = data_forstok[~data_forstok['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "\n",
    "skushopee = skushopee.reset_index(drop = True)\n",
    "data_forstok = data_forstok.reset_index(drop = True)\n",
    "\n",
    "sku_exclude = ['5337754001-1623228299159-0',\"TESSS\"]\n",
    "data_forstok = data_forstok[~data_forstok['SKU'].isin(sku_exclude)]\n",
    "\n",
    "# data_forstok=data_forstok[data_forstok['Item Name']!='Hadiah Promo Ramadhan - Catokan']\n",
    "\n",
    "data_forstok.loc[data_forstok['Item Name']==\"HiLo Teen Strawberry Milkshake 500 gram – Susu Tinggi Kalsium - Milkshake\",'SKU']=\"2101683180\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Paket Minyak Hemat – Tropicana Slim Canola Oil & Tropicana Slim Sunflower Oil - Package\",'SKU']=\"PT3T46\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Buy 2 Get 1 - L-Men Protein Crunch BBQ Beef (20gr) - Triplepack\",'SKU']=\"2309005300P3\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Paket Kecap Sehat - Topicana Slim Kecap Manis & Tropicana Slim Kecap Asin - Package\",\"SKU\"]=\"PT26T44\"\n",
    "data_forstok.loc[(data_forstok['Item Name']==\"(Free Gift) 3pcs L-Men Protein Crunch BBQ Beef 20g\")&\n",
    "                 (data_forstok['Store']==\"Lazada\"),\"SKU\"]=\"(B)2309005305P3\"\n",
    "# data_forstok.loc[(data_forstok['Item Name']==\"Free L-Men 2 Go - Twin Pack L-Men Daily Dark Chocolate 250gr\")&\n",
    "#                  (data_forstok['Store']==\"Tokopedia\"),\"SKU\"]=\"PL1(2)B103\"\n",
    "# data_forstok.loc[(data_forstok['Item Name']==\"Free L-Men 2 Go - Twin Pack L-Men Daily Popcorn Caramel 250gr\")&\n",
    "#                  (data_forstok['Store']==\"Tokopedia\"),\"SKU\"]=\"PL23(2)B103\"\n",
    "# data_forstok.loc[(data_forstok['Item Name']==\"Free 2 Pcs L-Men 2 Go - L-Men Gain Mass Mangga 500gr\")&\n",
    "#                  (data_forstok['Store']==\"Tokopedia\"),\"SKU\"]=\"PL17B103(2)\"\n",
    "\n",
    "\n",
    "\n",
    "idx = []\n",
    "idx = idx + data_forstok[data_forstok['SKU'].isnull()].drop_duplicates().index.to_list()\n",
    "idx = idx + data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx = list(dict.fromkeys(idx))\n",
    "idx_s = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx_s = list(dict.fromkeys(idx_s))\n",
    "\n",
    "\n",
    "for i in product:\n",
    "    indeks_shopee = data_forstok.iloc[indeks][data_forstok.iloc[indeks]['Item Name'].astype(str).str.lower() == str(i).lower()].index.to_list()\n",
    "    data_forstok['SKU'][indeks_shopee] = shopee_con[shopee_con['Product Name'].astype(str).str.lower() == str(i).lower()]['Real SKU'].values[0]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "if len(idx) != 0 or len(idx_s) != 0:\n",
    "# if len(idx) != 0:\n",
    "    alert = data_forstok.iloc[idx, ][['SKU', 'Item Name', 'Channel']].drop_duplicates()\n",
    "    alert = alert.append(skushopee.iloc[idx_s][['SKU', 'Item Name', 'Channel', 'Selling Price']].drop_duplicates(), ignore_index = True, sort = False)\n",
    "    alert['SKU'] = alert['SKU'].astype(str)\n",
    "    alert['SKU Valid'] = np.nan\n",
    "    to_excel = alert.to_excel('ALERT_FORSTOK_SKU_MISSING.xlsx')\n",
    "    print(\"Some SKU Missing Please Complete It ====== 5/10\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    # creates SMTP session \n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "    # start TLS for security \n",
    "    s.starttls() \n",
    "\n",
    "    # Authentication \n",
    "    s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = \"ALERT SKU FORSTOK MISSING\"\n",
    "\n",
    "\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "      <head></head>\n",
    "      <body>\n",
    "        {0}\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\".format(alert.to_html())\n",
    "\n",
    "    part1 = MIMEText(html, 'html')\n",
    "    msg.attach(part1)\n",
    "\n",
    "    # sending the mail \n",
    "    s.sendmail(\"automationnfi@gmail.com\", \"andra.miftah@nutrifood.co.id\", msg.as_string()) \n",
    "\n",
    "    # terminating the session \n",
    "    s.quit() \n",
    "else :\n",
    "    print(\"Filling Brand ====== 5/10\")\n",
    "    data_forstok['SKU'] = data_forstok['SKU'].astype(str)\n",
    "    data_forstok['Item Name'] = data_forstok['Item Name'].astype(str)\n",
    "    data_SKU['Real SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "    data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "    \n",
    "    data_forstok = data_forstok.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "    temp = data_forstok[data_forstok['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Real SKU'].isnull()].index.to_list()\n",
    "    data_forstok['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_forstok['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    temp = data_forstok[data_forstok['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Real SKU'].isnull()].index.to_list()\n",
    "    data_forstok['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_forstok['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    data_forstok['Real SKU'] = data_forstok['Real SKU'].astype(str)\n",
    "    data_forstok = data_forstok.merge(data_SKU[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    data_forstok = data_forstok.drop(['SKU_y'], axis = 1)\n",
    "    data_forstok = data_forstok.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Unbundling ====== 6/10\")        \n",
    "    # Forstok Unbundling    \n",
    "    list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "    data_forstok = data_forstok.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    list_pcs = [x for x in data_forstok.columns if 'PCS' in x]\n",
    "    for i in list_pcs:\n",
    "        data_forstok[i] = data_forstok[i] * data_forstok['Quantity']\n",
    "    data_forstok = data_forstok.drop(['SKU_y'], axis = 1)\n",
    "    data_forstok = data_forstok.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Brand'] == 'Bundle'].index.to_list()\n",
    "    data_forstok['Bundle Flag'] = np.nan\n",
    "    data_forstok['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Brand'] == 'Bundle'][data_forstok[data_forstok['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "    data_forstok['SKU Produk 1'][indeks] = '(S)' + data_forstok['SKU Produk 1'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 2'][indeks] = '(S)' + data_forstok['SKU Produk 2'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 3'][indeks] = '(S)' + data_forstok['SKU Produk 3'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 4'][indeks] = '(S)' + data_forstok['SKU Produk 4'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 5'][indeks] = '(S)' + data_forstok['SKU Produk 5'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 6'][indeks] = '(S)' + data_forstok['SKU Produk 6'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 7'][indeks] = '(S)' + data_forstok['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Filling Date ====== 7/10\")\n",
    "    data_forstok['Date'] = np.nan\n",
    "    data_forstok['Month'] = np.nan\n",
    "    data_forstok['Year'] = np.nan\n",
    "\n",
    "    for i in range(data_forstok.shape[0]):\n",
    "        if int(data_forstok['Order Date'][i].strftime('%d')) <= 12:\n",
    "            data_forstok['Date'][i] = pd.to_datetime(data_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "            data_forstok['Month'][i] = pd.to_datetime(data_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "            data_forstok['Year'][i] = pd.to_datetime(data_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "        else :\n",
    "            data_forstok['Date'][i] = pd.to_datetime(data_forstok['Order Date'][i]).day\n",
    "            data_forstok['Month'][i] = pd.to_datetime(data_forstok['Order Date'][i]).month_name()\n",
    "            data_forstok['Year'][i] = pd.to_datetime(data_forstok['Order Date'][i]).year\n",
    "\n",
    "    quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "            ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "    data_forstok = data_forstok.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "    data_forstok = data_forstok.drop(['Bulan'], axis = 1)\n",
    "    data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "            {'Bulan' : 'January' , 'Number': 1},\n",
    "            {'Bulan' : 'February' , 'Number': 2},\n",
    "            {'Bulan' : 'March' , 'Number': 3},\n",
    "            {'Bulan' : 'April' , 'Number': 4},\n",
    "            {'Bulan' : 'May' , 'Number': 5},\n",
    "            {'Bulan' : 'June', 'Number': 6},\n",
    "            {'Bulan' : 'July' , 'Number': 7},\n",
    "            {'Bulan' : 'August', 'Number' : 8},\n",
    "            {'Bulan' : 'September', 'Number' : 9},\n",
    "            {'Bulan' : 'October' , 'Number': 10},\n",
    "            {'Bulan' : 'November' , 'Number': 11}])\n",
    "    temp = data_forstok.copy()\n",
    "    temp['Day'] = temp['Date']\n",
    "    temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "    temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "    data_forstok['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "    temp['Hour'] = pd.to_datetime(data_forstok['Order Date']).dt.hour\n",
    "    temp['Minute'] = pd.to_datetime(data_forstok['Order Date']).dt.minute\n",
    "    temp['Second'] = pd.to_datetime(data_forstok['Order Date']).dt.second\n",
    "    data_forstok['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "    \n",
    "    \n",
    "    forstok_all = data_forstok\n",
    "    forstok_all['Total'] = forstok_all['Sub Total']\n",
    "    forstok_all['Price List NFI'] = np.nan\n",
    "    forstok_all['Total Net'] = np.nan\n",
    "\n",
    "    forstok_all = forstok_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                            'Status' : 'Order Status',\n",
    "                                            'Order Date' : 'Order date',\n",
    "                                            'Item Name' :'Product Name',\n",
    "                                            'Bundle Name' : 'Bundle',\n",
    "                                            'Shipping Country' : 'Country',\n",
    "                                            'Shipping Province' : 'Region',\n",
    "                                            'Shipping City' : 'City',\n",
    "                                            'Shipping Zip' : 'Zip Code',\n",
    "                                            'Shipping Address1' : 'Address',\n",
    "                                            'Shipping Phone' : 'Phone',\n",
    "                                            'Quantity' : 'Qty. Invoiced',\n",
    "                                            'Item Price' : 'Regular Price',\n",
    "                                            'Sub Total' : 'Subtotal'})\n",
    "    forstok_all['Kecamatan'] = np.nan\n",
    "    forstok_all['Kelurahan'] = np.nan\n",
    "    forstok_all['Store'] = forstok_all['Channel']\n",
    "\n",
    "    print(\"Filling Location\")\n",
    "    indeks = forstok_all[forstok_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "        forstok_all['City'][indeks] = forstok_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = forstok_all[forstok_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kelurahan'][indeks] = forstok_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = forstok_all[forstok_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        forstok_all['City'][indeks] = forstok_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = forstok_all[forstok_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kelurahan'][indeks] = forstok_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    forstok_all['City'] = forstok_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "    master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "    master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "    master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "    master_map['Kode Prov'][515] = 14\n",
    "    master_map['Province'][515] = 'Riau'\n",
    "    master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "    master_map['Province'] = master_map['Province'].str.title()\n",
    "    master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "    city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "    temp = forstok_all.copy()\n",
    "    temp['City'] = temp['City'].astype(str).str.lower()\n",
    "    temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "    city['All City'] = city['All City'].astype(str).str.lower()\n",
    "    temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "    indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "    forstok_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "    province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "    temp = forstok_all.copy()\n",
    "    temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "    province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "    temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "    indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "    forstok_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "    temp = forstok_all.copy()\n",
    "    temp = temp[temp['Region'].isnull()]\n",
    "    temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "    forstok_all['Region'][temp.index] = temp['Region']  \n",
    "    \n",
    "    district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "    temp = forstok_all.copy()\n",
    "    temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "    district['All District'] = district['All District'].astype(str).str.lower()\n",
    "    temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "    indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "    forstok_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "    temp = forstok_all.copy()\n",
    "    temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "    indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "    forstok_all['City'][indeks] = np.nan\n",
    "\n",
    "    data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "    data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "    print(\"Unbundling\")\n",
    "    data_bundle1 = forstok_all[~forstok_all['Produk 1'].isnull()]\n",
    "    data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "    data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "    data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "    data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "    data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "    data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "    data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle2 = forstok_all[~forstok_all['Produk 2'].isnull()]\n",
    "    data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "    data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "    data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "    data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "    data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "    data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "    data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle3 = forstok_all[~forstok_all['Produk 3'].isnull()]\n",
    "    data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "    data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "    data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "    data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "    data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "    data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "    data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle4 = forstok_all[~forstok_all['Produk 4'].isnull()]\n",
    "    data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "    data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "    data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "    data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "    data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "    data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "    data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle5 = forstok_all[~forstok_all['Produk 5'].isnull()]\n",
    "    data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "    data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "    data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "    data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "    data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "    data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "    data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle6 = forstok_all[~forstok_all['Produk 6'].isnull()]\n",
    "    data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "    data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "    data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "    data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "    data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "    data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "    data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle7 = forstok_all[~forstok_all['Produk 7'].isnull()]\n",
    "    data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "    data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "    data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "    data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "    data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "    data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "    data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "    data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "    data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "    data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "    temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "    indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "    data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "    data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "    data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "    data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "    data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "    data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "    print(\"Pricing\")\n",
    "    forstok_all = forstok_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "    \n",
    "#     temp = forstok_all[forstok_all['Brand'] == 'L-Men'].drop_duplicates('Sales Order ID').copy()\n",
    "#     idx = data_SKU[data_SKU['SKU'].astype(str) == '(B)71210138'].index[0]\n",
    "#     temp['Item Name'] = data_SKU['Nama Produk'][idx]\n",
    "#     temp['Quantity'] = 1\n",
    "#     temp['SKU'] = '(B)71210138'\n",
    "#     temp['Brand'] = data_SKU['Brand'][idx]\n",
    "#     temp['Product Name'] = data_SKU['Nama Produk'][idx]\n",
    "#     temp['Real Nama Produk'] = data_SKU['Nama Produk'][idx]\n",
    "#     temp['Brand'] = data_SKU['Brand'][idx]\n",
    "#     temp['Bundle Name'] = np.nan\n",
    "#     temp['Price List NFI'] = data_SKU['Price List NFI'][idx]\n",
    "#     temp['Total Net'] = temp['Price List NFI'] * temp['Qty. Invoiced']\n",
    "#     temp['Sub Brand'] = data_SKU['Sub Brand'][idx]\n",
    "#     temp['SKU'] = data_SKU['SKU'][idx]\n",
    "#     temp['Real SKU'] = data_SKU['SKU'][idx]\n",
    "#     temp['Parent SKU'] = data_SKU['Parent SKU'][idx]\n",
    "#     temp['Parent Item'] = data_SKU['Parent Item'][idx]\n",
    "#     temp['Subtotal'] = 0\n",
    "#     temp['Total'] = 0\n",
    "#     temp['Regular Price'] = 0\n",
    "#     temp['Selling Price'] = 0\n",
    "#     temp['Gross Sales'] = 0\n",
    "#     temp['Seller Discount'] = 0\n",
    "#     colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "#     colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "#     colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "#     for i in colname_str:\n",
    "#         temp[i] = np.nan\n",
    "\n",
    "#     for i in colname_int:\n",
    "#         temp[i] = 0\n",
    "    \n",
    "#     data_forstok = data_forstok.append(temp , ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    forstok_all = forstok_all.merge(data_SKU[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(forstok_all.index)\n",
    "    forstok_all['Price List NFI_x'] = forstok_all['Price List NFI_x'].fillna(forstok_all['Price List NFI_y'])\n",
    "    forstok_all =  forstok_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "    forstok_all = forstok_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "    forstok_all['Price List NFI'] = pd.to_numeric(forstok_all['Price List NFI']).astype(int)\n",
    "    forstok_all['Harga Cost'] = pd.to_numeric(forstok_all['Harga Cost']).astype(int)\n",
    "    forstok_all['Qty. Invoiced'] = pd.to_numeric(forstok_all['Qty. Invoiced']).astype(int)\n",
    "    \n",
    "    forstok_all['Total Net'] = forstok_all['Price List NFI'] * forstok_all['Qty. Invoiced']\n",
    "    forstok_all['Total Harga Cost'] = forstok_all['Harga Cost'] * forstok_all['Qty. Invoiced']\n",
    "    \n",
    "    forstok_all = forstok_all.reset_index(drop = True)\n",
    "    forstok_all['Order #'] = forstok_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(\"https://seller.blibli.com/sign-in\")\n",
    "    time.sleep(30)\n",
    "\n",
    "    username = driver.find_element_by_id(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"novita.vidianti@nutrifood.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_id(\"password\")\n",
    "    password.send_keys(\"Mengejarcu4n\")\n",
    "\n",
    "    driver.find_element_by_id(\"sign-in\").click()\n",
    "    time.sleep(30)\n",
    "#     WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'close-announcement-button'))).click()\n",
    "#     WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'remind-me-later-button'))).click()\n",
    "#     WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'nav-wrapper-ORDER'))).click()\n",
    "#     driver.find_element_by_id(\"sub-nav-item-0\").click()\n",
    "    driver.get(\"https://seller.blibli.com/MTA/order/summary\")\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn-primary-mta'))).click()\n",
    "    time.sleep(10)\n",
    "    driver.find_element_by_id(\"semuaFilter\").click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"order-filter-input\").click()\n",
    "    start_date = datetime.today() - timedelta(days=14)\n",
    "    end_date = datetime.today()\n",
    "    date = start_date.strftime('%Y-%m-%d') + '-' + end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    if start_date.month == end_date.month:\n",
    "        text = \"//div[@class='calendar left']//td[@class = 'available' or @class='weekend available'][text() = \" + str(start_date.day) + \"]\"\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "        text = \"//div[@class='calendar left']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "    else :\n",
    "        driver.find_element_by_css_selector(\"th.prev.available\").click()\n",
    "        text = \"//div[@class='calendar left']//td[@class = 'available' or @class='weekend available'][text() = \" + str(start_date.day) + \"]\"\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "        text = \"//div[@class='calendar right']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "    driver.find_element_by_css_selector('button.btn.col-sm-3.btn-default.order-option-buttons.dropdown-toggle').click()\n",
    "    driver.find_element_by_xpath(\"/html/body/div[3]/div[2]/div/div/div[1]/div[3]/div[2]/ul\").click()\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_class_name(\"btn-primary-mta\").click()\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    cond = False\n",
    "    while not cond:\n",
    "        time.sleep(20)\n",
    "        driver.find_element_by_class_name('fa-bell-o').click()\n",
    "        time.sleep(10)\n",
    "        driver.find_element_by_class_name('fa-bell-o').click()\n",
    "#         time.sleep(10)\n",
    "#         driver.find_element_by_class_name('fa-bell-o').click()\n",
    "\n",
    "        time_now = str(datetime.now().hour) + ':' + str(datetime.now().minute)\n",
    "        time.sleep(5)\n",
    "        time_notif = driver.find_element_by_css_selector('li.ng-scope.notification-unread').text[-5:]\n",
    "        end = datetime.strptime(time_notif, '%H:%M').time()\n",
    "        duration = int((datetime.today() - timedelta(hours=end.hour, minutes=end.minute)).strftime('%M'))\n",
    "        if duration < 2:\n",
    "            time.sleep(1)\n",
    "            driver.find_element_by_xpath('//ul[@class = \"notification-item-container\"]//li[@class = \"ng-scope notification-unread\"]').click()\n",
    "            cond = True\n",
    "        else :\n",
    "            driver.find_element_by_class_name('fa-bell-o').click()\n",
    "            time.sleep(60)\n",
    "\n",
    "   \n",
    "    time.sleep(15)\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    else:\n",
    "        print(\"More than one file or no file downloaded\")\n",
    "    print(file_name)\n",
    "    new_name = 'Blibli ' + str(date) + '.csv'\n",
    "    if os.path.isfile('Input Data/' + str(new_name)) :\n",
    "        os.remove('Input Data/' + str(new_name))\n",
    "    os.rename('Input Data/' + str(file_name), 'Input Data/' + str(new_name))\n",
    "    driver.quit()\n",
    "    print(\"Import Data ====== 1/10\")\n",
    "    \n",
    "#     new_name = 'Blibli 2021-03-09-2021-03-15.csv'\n",
    "    lmen = pd.read_csv(r'Input Data/' + str(new_name) , dayfirst = True)\n",
    "    lmen = lmen.dropna(how = 'all')\n",
    "    lmen_pure = lmen.copy()\n",
    "\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Formatting Data ====== 2/10\")\n",
    "    lmen['No. Order'] = lmen['No. Order'].astype(str).str.replace('^=\"','')\n",
    "    lmen['No. Order'] = lmen['No. Order'].astype(str).str.replace('\"$','')\n",
    "    lmen['No. Order Item'] = lmen['No. Order Item'].astype(str).str.replace('^=\"','')\n",
    "    lmen['No. Order Item'] = lmen['No. Order Item'].astype(str).str.replace('\"$','')\n",
    "    lmen['No. Awb'] = lmen['No. Awb'].astype(str).str.replace('^=\"','')\n",
    "    lmen['No. Awb'] = lmen['No. Awb'].astype(str).str.replace('\"$','')\n",
    "    lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('^=\"','')\n",
    "    lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('\"$','')\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Listing SKU ====== 3/10\")\n",
    "    lmen_sku = pd.read_excel(r'SKU_File/Converter Paket Blibli.xlsx')\n",
    "\n",
    "    lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('\\.0$','', regex = True)\n",
    "\n",
    "    null_sku = lmen[lmen['Merchant SKU'] == 'nan'].copy()\n",
    "    lmen = lmen[lmen['Merchant SKU'] != 'nan']\n",
    "\n",
    "    null_sku['Nama Produk'] = null_sku['Nama Produk'].astype(str).str.strip()\n",
    "    lmen_sku['Nama Produk'] = lmen_sku['Nama Produk'].astype(str).str.strip()\n",
    "    null_sku['Merchant SKU'] = null_sku.merge(lmen_sku[['SKU Merchant', 'Nama Produk']].drop_duplicates(['Nama Produk']), how = 'left', on = 'Nama Produk').set_index(null_sku.index)['SKU Merchant']\n",
    "\n",
    "    lmen = lmen.append(null_sku, ignore_index = True, sort = False)\n",
    "\n",
    "    gaada_sku = lmen[~lmen['Merchant SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].copy()\n",
    "    lmen = lmen[lmen['Merchant SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]\n",
    "\n",
    "    gaada_sku['Nama Produk'] = gaada_sku['Nama Produk'].astype(str).str.strip()\n",
    "    lmen_sku['Nama Produk'] = lmen_sku['Nama Produk'].astype(str).str.strip()\n",
    "    gaada_sku['Merchant SKU'] = gaada_sku.merge(lmen_sku[['SKU Merchant', 'Nama Produk']].drop_duplicates(['Nama Produk']), how = 'left', on = 'Nama Produk').set_index(gaada_sku.index)['SKU Merchant']\n",
    "    lmen = lmen.append(gaada_sku, ignore_index = True, sort = False)\n",
    "\n",
    "    indeks = []\n",
    "    indeks = indeks + lmen[lmen['Merchant SKU'].isnull()].index.to_list()\n",
    "    indeks = indeks + lmen[~lmen['Merchant SKU'].astype(str).str.replace('\\.0$','', regex = True).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0 :\n",
    "        alert = lmen.iloc[indeks][['Blibli SKU','Merchant SKU', 'Nama Produk']].drop_duplicates()\n",
    "        alert['SKU Valid'] = np.nan\n",
    "        to_excel = alert.to_excel('ALERT_LMEN-STORE_SKU_MISSING.xlsx')\n",
    "        print(\"Some SKU Missing Please Complete It ====== 4/10\")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    else :\n",
    "        data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "        data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "        lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str)\n",
    "        data_SKU['Price List NFI'] = data_SKU['Price List NFI'].astype(float).astype('int64')\n",
    "        lmen = lmen.merge(data_SKU[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU', 'Price List NFI']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'Merchant SKU', right_on = 'Real SKU')\n",
    "        lmen['Total Net'] = lmen['Price List NFI'] * lmen['Total Barang']\n",
    "\n",
    "        indeks = lmen[lmen['Brand'] == 'Bundle'].index.to_list()\n",
    "        lmen['Bundle Flag'] = np.nan\n",
    "        lmen['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        lmen['Date'] = pd.to_datetime(lmen['Tanggal Order'], format = '%d/%m/%Y %H:%M').dt.day\n",
    "        lmen['Month'] = pd.to_datetime(lmen['Tanggal Order'], format = '%d/%m/%Y %H:%M').dt.month_name()\n",
    "        lmen['Year'] = pd.to_datetime(lmen['Tanggal Order'], format = '%d/%m/%Y %H:%M').dt.year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                    ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        lmen = lmen.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        lmen = lmen.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = lmen.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        lmen['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        lmen['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "\n",
    "        lmen = lmen.rename(columns = {'No. Order' : 'Order #', 'No. Order Item' : 'No. Order Item L-Men Blibli',\n",
    "                                    'Tanggal Order' : 'Order date', 'Nama Pemesan' : 'Customer Name',\n",
    "                                    'Merchant SKU' : 'SKU', 'Nama Produk' : 'Product Name', 'Total Barang':'Qty. Invoiced',\n",
    "                                    'Harga Produk' : 'Selling Price', 'Servis Logistik' : 'Shipping Courier', 'Nama Store' : 'Channel',\n",
    "                                    'Toko/Gudang' : 'Warehouse Name', 'No. Awb' : 'AWB'\n",
    "                                    })\n",
    "\n",
    "        lmen['Channel'] = 'L-Men Store Blibli'\n",
    "        lmen['Store'] = 'Blibli'\n",
    "\n",
    "        data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "        data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "        lmen['SKU'] = lmen['SKU'].astype(str)\n",
    "        list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Cost 7')+1].to_list()\n",
    "        lmen = lmen.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        lmen = lmen.drop(['SKU_y'], axis = 1)\n",
    "        lmen = lmen.rename(columns = {'SKU_x':'SKU'})\n",
    "        data_bundle1 = lmen[~lmen['Produk 1'].isnull()]\n",
    "\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1'] * data_bundle1['Qty. Invoiced']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1'] * data_bundle1['Qty. Invoiced']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = lmen[~lmen['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2'] * data_bundle2['Qty. Invoiced']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] * data_bundle2['Qty. Invoiced']\n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = lmen[~lmen['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']* data_bundle3['Qty. Invoiced']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] * data_bundle3['Qty. Invoiced']\n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = lmen[~lmen['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']* data_bundle4['Qty. Invoiced']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] * data_bundle4['Qty. Invoiced']\n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = lmen[~lmen['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']* data_bundle5['Qty. Invoiced']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5'] * data_bundle5['Qty. Invoiced']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = lmen[~lmen['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']* data_bundle6['Qty. Invoiced']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6'] * data_bundle6['Qty. Invoiced']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = lmen[~lmen['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']* data_bundle7['Qty. Invoiced']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7'] * data_bundle7['Qty. Invoiced']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        lmen = lmen.append(data_bundle, ignore_index = True, sort = False)\n",
    "        lmen = lmen.merge(data_SKU[['Real SKU', 'Harga Cost']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "        lmen['Total Harga Cost'] = pd.to_numeric(lmen['Harga Cost'], errors = 'coerce') * lmen['Qty. Invoiced']\n",
    "        print(lmen[lmen['Harga Cost'] == 0][['SKU','Product Name']].drop_duplicates())\n",
    "        lmen['Total'] = lmen['Selling Price'] * lmen['Qty. Invoiced']\n",
    "        lmen['Subtotal'] = lmen['Selling Price'] * lmen['Qty. Invoiced']\n",
    "        lmen = lmen.rename(columns = {'Real SKU_x' : 'Real SKU'})\n",
    "\n",
    "        forstok_all = forstok_all.append(lmen, ignore_index = True, sort = False)\n",
    "\n",
    "        list_bundle = forstok_all[forstok_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        forstok_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        forstok_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        forstok_all['Total'][temp.index] = temp['Total']\n",
    "        forstok_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        forstok_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "        \n",
    "\n",
    "        forstok_all['Order #'] = forstok_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = forstok_all[forstok_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        forstok_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        forstok_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = forstok_all.merge(temp_group, how = 'left', on = 'Order #').set_index(forstok_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        forstok_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = forstok_all[forstok_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        forstok_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        forstok_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        forstok_all['True datetime'] = pd.to_datetime(forstok_all['True datetime'])\n",
    "        forstok_all['Promo'] = np.nan\n",
    "        forstok_all['Discount MC'] = np.nan\n",
    "        \n",
    "        # indeks = forstok_all[forstok_all['Channel'] == 'Shopee'].index.to_list()\n",
    "        # forstok_all['Warehouse Name'][indeks] = 'Shopee Warehouse'\n",
    "        \n",
    "#         print(\"Marketing Calendar JD\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/JD (baru).xlsx')\n",
    "\n",
    "#         MC_JD = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names:\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/JD (baru).xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_JD = MC_JD.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_JD['Start Date'] = pd.to_datetime(MC_JD['Start Date'])\n",
    "#         MC_JD['End Date'] = pd.to_datetime(MC_JD['End Date'])\n",
    "\n",
    "#         MC_JD = MC_JD.dropna(subset = ['Promo'])\n",
    "#         MC_JD = MC_JD.reset_index(drop = True)\n",
    "\n",
    "#         JD = forstok_all[forstok_all['Channel'] == 'JD Indonesia']\n",
    "\n",
    "#         for i in range(MC_JD.shape[0]):\n",
    "#             promo = MC_JD['Promo'][i]\n",
    "#             start = MC_JD['Start Date'][i]\n",
    "#             end = MC_JD['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_JD['SKU'][i]\n",
    "#             diskon = MC_JD['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = JD[JD['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = JD[JD['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         print(\"Marketing Calendar Blibli\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Blibli.xlsx')\n",
    "\n",
    "#         MC_Blibli = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names:\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Blibli.xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_Blibli = MC_Blibli.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_Blibli['Start Date'] = pd.to_datetime(MC_Blibli['Start Date'])\n",
    "#         MC_Blibli['End Date'] = pd.to_datetime(MC_Blibli['End Date'])\n",
    "\n",
    "#         MC_Blibli = MC_Blibli.dropna(subset = ['Promo'])\n",
    "#         MC_Blibli = MC_Blibli.reset_index(drop = True)\n",
    "\n",
    "#         Blibli = forstok_all[forstok_all['Channel'] == 'Blibli']\n",
    "\n",
    "#         for i in range(MC_Blibli.shape[0]):\n",
    "#             promo = MC_Blibli['Promo'][i]\n",
    "#             start = MC_Blibli['Start Date'][i]\n",
    "#             end = MC_Blibli['End Date'][i] + timedelta(days=1)\n",
    "#             SKU = MC_Blibli['SKU'][i]\n",
    "#             diskon = MC_Blibli['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Blibli[Blibli['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Blibli[Blibli['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         Blibli = forstok_all[forstok_all['Channel'] == 'L-Men Store Blibli']\n",
    "\n",
    "#         for i in range(MC_Blibli.shape[0]):\n",
    "#             promo = MC_Blibli['Promo'][i]\n",
    "#             start = MC_Blibli['Start Date'][i]\n",
    "#             end = MC_Blibli['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_Blibli['SKU'][i]\n",
    "#             diskon = MC_Blibli['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Blibli[Blibli['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Blibli[Blibli['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         print(\"Marketing Calendar Lazada\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 10 Mei.xlsx')\n",
    "\n",
    "#         MC_Lazada = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names:\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 10 Mei.xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_Lazada = MC_Lazada.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_Lazada['Start Date'] = pd.to_datetime(MC_Lazada['Start Date'])\n",
    "#         MC_Lazada['End Date'] = pd.to_datetime(MC_Lazada['End Date'])\n",
    "\n",
    "#         MC_Lazada = MC_Lazada.dropna(subset = ['Promo'])\n",
    "#         MC_Lazada = MC_Lazada.reset_index(drop = True)\n",
    "\n",
    "#         Lazada = forstok_all[forstok_all['Channel'] == 'Lazada']\n",
    "\n",
    "#         for i in range(MC_Lazada.shape[0]):\n",
    "#             promo = MC_Lazada['Promo'][i]\n",
    "#             start = MC_Lazada['Start Date'][i]\n",
    "#             end = MC_Lazada['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_Lazada['SKU'][i]\n",
    "#             diskon = MC_Lazada['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Lazada[Lazada['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Lazada[Lazada['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         print(\"Marketing Calendar Tokopedia\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Tokopedia.xlsx')\n",
    "\n",
    "#         MC_Tokopedia = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names[:2]:\n",
    "#             print(i)\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Tokopedia.xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_Tokopedia = MC_Tokopedia.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_Tokopedia['Start Date'] = pd.to_datetime(MC_Tokopedia['Start Date'])\n",
    "#         MC_Tokopedia['End Date'] = pd.to_datetime(MC_Tokopedia['End Date'])\n",
    "\n",
    "#         MC_Tokopedia['Promo'] = MC_Tokopedia['Promo'].fillna('Promo Februari 2020')\n",
    "#         MC_Tokopedia = MC_Tokopedia.reset_index(drop = True)\n",
    "\n",
    "#         Tokopedia = forstok_all[forstok_all['Channel'] == 'Tokopedia']\n",
    "\n",
    "#         for i in range(MC_Tokopedia.shape[0]):\n",
    "#             promo = MC_Tokopedia['Promo'][i]\n",
    "#             start = MC_Tokopedia['Start Date'][i]\n",
    "#             end = MC_Tokopedia['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_Tokopedia['SKU'][i]\n",
    "#             diskon = MC_Tokopedia['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Tokopedia[Tokopedia['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Tokopedia[Tokopedia['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         print(\"Marketing Calendar Bukalapak\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Bukalapak.xlsx')\n",
    "\n",
    "#         MC_Bukalapak = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names:\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Bukalapak.xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_Bukalapak = MC_Bukalapak.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_Bukalapak['Start Date'] = pd.to_datetime(MC_Bukalapak['Start Date'])\n",
    "#         MC_Bukalapak['End Date'] = pd.to_datetime(MC_Bukalapak['End Date'])\n",
    "\n",
    "#         MC_Bukalapak = MC_Bukalapak.dropna(subset = ['Promo'])\n",
    "#         MC_Bukalapak = MC_Bukalapak.reset_index(drop = True)\n",
    "\n",
    "#         Bukalapak = forstok_all[forstok_all['Channel'] == 'Bukalapak']\n",
    "\n",
    "#         for i in range(MC_Bukalapak.shape[0]):\n",
    "#             promo = MC_Bukalapak['Promo'][i]\n",
    "#             start = MC_Bukalapak['Start Date'][i]\n",
    "#             end = MC_Bukalapak['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_Bukalapak['SKU'][i]\n",
    "#             diskon = MC_Bukalapak['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Bukalapak[Bukalapak['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Bukalapak[Bukalapak['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         print(\"Marketing Calendar FBL\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 10 Mei.xlsx')\n",
    "\n",
    "#         MC_Lazada = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names:\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 10 Mei.xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_Lazada = MC_Lazada.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_Lazada['Start Date'] = pd.to_datetime(MC_Lazada['Start Date'])\n",
    "#         MC_Lazada['End Date'] = pd.to_datetime(MC_Lazada['End Date'])\n",
    "\n",
    "#         MC_Lazada = MC_Lazada.dropna(subset = ['Promo'])\n",
    "#         MC_Lazada = MC_Lazada.reset_index(drop = True)\n",
    "\n",
    "#         Lazada = forstok_all[forstok_all['Channel'] == 'FBL']\n",
    "\n",
    "#         for i in range(MC_Lazada.shape[0]):\n",
    "#             promo = MC_Lazada['Promo'][i]\n",
    "#             start = MC_Lazada['Start Date'][i]\n",
    "#             end = MC_Lazada['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_Lazada['SKU'][i]\n",
    "#             diskon = MC_Lazada['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Lazada[Lazada['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Lazada[Lazada['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "        \n",
    "#         forstok_all_final = forstok_all.copy()\n",
    "#         from datetime import datetime\n",
    "\n",
    "#         print(\"Starting Magento\")\n",
    "#         before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "#         # Download the file using Selenium here\n",
    "\n",
    "#         options = Options()\n",
    "#         options.add_experimental_option(\"prefs\", {\n",
    "#                 \"download.default_directory\": os.path.abspath(\"C:/Users/andra.miftah/Demo 9/Input Data\"),\n",
    "#                 \"download.directory_upgrade\": True,\n",
    "#                 \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "#                 \"safebrowsing.enabled\": False\n",
    "#         })\n",
    "\n",
    "#         print('Opening Chrome')\n",
    "#         driver = webdriver.Chrome(options=options)\n",
    "#         driver.get(\"https://bo.nutrimart.co.id/backoffice\")\n",
    "#         print('Login Magento')\n",
    "#         username = driver.find_element_by_id(\"username\")\n",
    "#         username.clear()\n",
    "#         username.send_keys(\"andra\")\n",
    "#         password = driver.find_element_by_id(\"login\")\n",
    "#         password.send_keys(\"andra123\")\n",
    "\n",
    "#         print('Go To Sales Form')\n",
    "#         driver.find_element_by_xpath(\"//button[@class = 'action-login action-primary']\").click()\n",
    "#         WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"menu-magento-sales-sales\"]'))).click()\n",
    "#         time.sleep(1)\n",
    "#         driver.find_element_by_xpath('//*[@id=\"menu-magento-sales-sales\"]/div/ul/li[3]/ul/li[1]/div/ul/li[1]/a').click()\n",
    "#         driver.find_element_by_xpath('//*[@id=\"profile_id\"]').click()\n",
    "#         driver.find_element_by_xpath('//*[@id=\"profile_id\"]/optgroup[2]/option[2]').click()\n",
    "        \n",
    "#         start_date = datetime.today() - timedelta(days=14)\n",
    "#         end_date = datetime.today()\n",
    "#         date = start_date.strftime('%d %b %Y') + '-' + end_date.strftime('%d %b %Y')\n",
    "\n",
    "#         print('Input Date')\n",
    "#         date_from = driver.find_element_by_name('daterange_from')\n",
    "#         date_from.clear()\n",
    "#         date_from.send_keys(start_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "#         date_to = driver.find_element_by_name('daterange_to')\n",
    "#         date_to.clear()\n",
    "#         date_to.send_keys(end_date.strftime('%m/%d/%Y'))\n",
    "#         print('Download Magento')\n",
    "#         driver.find_element_by_xpath('//*[@id=\"export_button\"]').click()\n",
    "\n",
    "#         time.sleep(60)\n",
    "#         after = os.listdir(os.getcwd() + '/Input Data')\n",
    "#         change = set(after) - set(before)\n",
    "#         if len(change) == 1:\n",
    "#             file_name = change.pop()\n",
    "#         else:\n",
    "#             print(\"More than one file or no file downloaded\")\n",
    "\n",
    "#         data_magento = pd.read_csv('Input Data/' + file_name, sep = ',', index_col = False)\n",
    "#         before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "#         driver.find_element_by_xpath('//*[@id=\"profile_id\"]').click()\n",
    "#         driver.find_element_by_xpath('//*[@id=\"profile_id\"]/optgroup[2]/option[1]').click()\n",
    "\n",
    "#         start_date = datetime.today() - timedelta(days=7)\n",
    "#         end_date = datetime.today()\n",
    "#         date = start_date.strftime('%d %b %Y') + '-' + end_date.strftime('%d %b %Y')\n",
    "\n",
    "#         date_from = driver.find_element_by_name('daterange_from')\n",
    "#         date_from.clear()\n",
    "#         date_from.send_keys(start_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "#         date_to = driver.find_element_by_name('daterange_to')\n",
    "#         date_to.clear()\n",
    "#         date_to.send_keys(end_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "#         driver.find_element_by_xpath('//*[@id=\"export_button\"]').click()\n",
    "#         time.sleep(60)\n",
    "#         after = os.listdir(os.getcwd() + '/Input Data')\n",
    "#         change = set(after) - set(before)\n",
    "#         if len(change) == 1:\n",
    "#             file_name = change.pop()\n",
    "#             print(file_name)\n",
    "#         else:\n",
    "#             print(\"More than one file or no file downloaded\")\n",
    "#             print(change)\n",
    "#         driver.quit()\n",
    "\n",
    "#         data_SKU = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx')\n",
    "\n",
    "#         s = requests.Session()\n",
    "#         s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "#         s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "#         r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "#         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "#             output.write(r.content)\n",
    "\n",
    "#         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "#             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "#             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "#             data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "#             data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "#         to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "#         data_magentoUser2 = pd.read_csv('Input Data/' + file_name, sep = ',', index_col = False)\n",
    "#         for i in range(data_magentoUser2.shape[1]):\n",
    "#             data_magentoUser2 = data_magentoUser2.rename(columns={ data_magentoUser2.columns[i] : data_magentoUser2.columns[i].replace(\"    \",\" \")})\n",
    "\n",
    "#         # Import library\n",
    "#         import time\n",
    "#         import pandas as pd\n",
    "#         import numpy as np\n",
    "#         import datetime\n",
    "#         import math\n",
    "#         import os\n",
    "\n",
    "#         # Import data\n",
    "#         start_time = time.time()\n",
    "#         print(\"Import Data ====== 1/10\")\n",
    "#         # data_magento = pd.read_excel(r'magento_new.xls')\n",
    "#         data_magentoUser = pd.read_excel('All Data\\data_magentoUser_2020.xlsx', index_col = False)\n",
    "#         data_magentoUser = data_magentoUser[~data_magentoUser['Sales Order Id'].astype(str).isin(data_magentoUser2['Sales Order Id'].astype(str))]\n",
    "#         data_magentoUser = data_magentoUser.append(data_magentoUser2, ignore_index = True, sort = False)\n",
    "#         magento_pure = data_magento.copy()\n",
    "\n",
    "#         list_skumiss = []\n",
    "\n",
    "#         # Formatting Magento\n",
    "#         print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#         print(\"Formatting Data ====== 2/10\")\n",
    "\n",
    "#         pd.options.mode.chained_assignment = None\n",
    "#         if set(['Qty. Ordered\"', 'Qty. Shipped\"']).issubset(data_magento.columns):\n",
    "#             data_magento = data_magento.rename(columns={'Qty. Ordered\"' : 'Qty. Ordered', \n",
    "#                                                     'Qty. Shipped\"' : 'Qty. Shipped'})\n",
    "#         if \"Manufacturer\" in data_magento.columns:\n",
    "#             data_magento= data_magento.drop([\"Manufacturer\"], axis=1)\n",
    "#         if \"Item Cost\" in data_magento.columns:\n",
    "#             data_magento= data_magento.drop([\"Item Cost\"], axis=1)\n",
    "#         if \"Package Name\" in data_magento.columns:\n",
    "#             data_magento= data_magento.drop([\"Package Name\"], axis=1)\n",
    "#         if \"Tax Refunded\" in data_magento.columns:\n",
    "#             data_magento= data_magento.drop([\"Tax Refunded\"], axis=1)\n",
    "#         if \"Catalog Name Rule\" in data_magento.columns:\n",
    "#             data_magento= data_magento.drop([\"Catalog Name Rule\"], axis=1)\n",
    "#         if \"Order date\" in data_magento.columns:\n",
    "#             data_magento[\"Order date\"] = pd.to_datetime(data_magento[\"Order date\"], errors = 'coerce')\n",
    "#         if \"Customer Email\" in data_magento.columns:\n",
    "#             data_magento[\"Customer Email\"] = data_magento[\"Customer Email\"].replace(regex = r'\"', value=\"\")\n",
    "#         if \"Qty. Ordered\" in data_magento.columns:\n",
    "#             data_magento['Qty. Ordered'] = data_magento['Qty. Ordered'].fillna(0)\n",
    "#             if \"Qty. Invoiced\" in data_magento.columns:\n",
    "#                 data_magento['Qty. Invoiced'] = data_magento['Qty. Invoiced'].fillna(0)\n",
    "#             if \"Qty. Shipped\" in data_magento.columns:\n",
    "#                 data_magento['Qty. Shipped'] = data_magento['Qty. Shipped'].fillna(0)\n",
    "#             if \"Qty. Refunded\" in data_magento.columns:\n",
    "#                 data_magento['Qty. Refunded'] = data_magento['Qty. Refunded'].fillna(0)\n",
    "#             if \"Item Price\" in data_magento.columns:\n",
    "#                 data_magento['Item Price'] = data_magento['Item Price'].fillna(0)\n",
    "#             if \"Subtotal\" in data_magento.columns:\n",
    "#                 data_magento['Subtotal'] = data_magento['Subtotal'].fillna(0)\n",
    "#             if \"Discounts\" in data_magento.columns:\n",
    "#                 data_magento['Discounts'] = data_magento['Discounts'].fillna(0)\n",
    "#             if \"Invoiced\" in data_magento.columns:\n",
    "#                 data_magento['Invoiced'] = data_magento['Invoiced'].fillna(0)\n",
    "#             if \"Tax Invoiced\" in data_magento.columns:\n",
    "#                 data_magento['Tax Invoiced'] = data_magento['Tax Invoiced'].fillna(0)\n",
    "#             if \"Voucher Amount\" in data_magento.columns:\n",
    "#                 data_magento[data_magento['Voucher Amount'].astype(str).str.isdigit()]['Voucher Amount'] = data_magento[data_magento['Voucher Amount'].fillna(0).astype(str).str.isdigit()]['Voucher Amount'].astype(float).div(10000)\n",
    "#             if \"Discount Poin Reward\" in data_magento.columns:\n",
    "#                 data_magento['Discount Poin Reward'] = data_magento['Discount Poin Reward'].fillna(0)\n",
    "#             if \"Discount Product\" in data_magento.columns:\n",
    "#                 data_magento['Discount Product'] = data_magento['Discount Product'].fillna(0)\n",
    "#         if \"Tax\" in data_magento.columns:\n",
    "#             data_magento['Tax'] = data_magento['Tax'].astype('Float32')\n",
    "#         if \"Total\" in data_magento.columns:\n",
    "#             data_magento['Total'] = data_magento['Total'].astype('Float32')\n",
    "#         if \"Total incl. Tax\" in data_magento.columns:\n",
    "#             data_magento['Total incl. Tax'] = pd.to_numeric(data_magento['Total incl. Tax'], errors = 'coerce').astype('Float32')\n",
    "#         if \"Invoiced incl. Tax\" in data_magento.columns:\n",
    "#             data_magento['Invoiced incl. Tax'] = data_magento['Invoiced incl. Tax'].astype('Float32')\n",
    "#         if \"Refunded\" in data_magento.columns:\n",
    "#             data_magento['Refunded'] = data_magento['Refunded'].astype('Float32')\n",
    "#         if \"Refunded incl. Tax\" in data_magento.columns:\n",
    "#             data_magento['Refunded incl. Tax'] = data_magento['Refunded incl. Tax'].astype('Float32')\n",
    "#         if \"Ship Date\" in data_magento.columns:\n",
    "#             data_magento['Ship Date'] = data_magento['Ship Date'].astype(str).str.replace('false', '')\n",
    "\n",
    "#         # Customer Information Filling  \n",
    "#         for i in range(data_magentoUser.shape[1]):\n",
    "#             data_magentoUser = data_magentoUser.rename(columns={ data_magentoUser.columns[i] : data_magentoUser.columns[i].replace(\"    \",\" \")})\n",
    "\n",
    "#         for i in range(data_magento.shape[0]):\n",
    "#             if str(data_magento[\"Customer Group\"][i]) == 'nan':\n",
    "#                 if str(data_magento[\"Order #\"][i]) in data_magentoUser[\"Sales Order Id\"].astype(str).values:\n",
    "#                     data_magento[\"Customer Name\"][i] = data_magentoUser[\"Shipping Name\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"Customer Group\"][i] = \"Not Logged In\"\n",
    "#                     data_magento[\"Country\"][i] = data_magentoUser[\"Shipping Country\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"Region\"][i] = data_magentoUser[\"Shipping Province\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"City\"][i] = data_magentoUser[\"Shipping City\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"Zip Code\"][i] = data_magentoUser[\"Shipping Zip\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"Address\"][i] = data_magentoUser[\"Shipping Address1\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"Phone\"][i] = data_magentoUser[\"Shipping Phone\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "\n",
    "#         indeks = data_magento[data_magento['Phone'].isnull()].index.to_list()\n",
    "#         data_magento['Phone Condition'] = np.nan\n",
    "#         data_magento['Phone Condition'][indeks] = 'X'\n",
    "\n",
    "#         data_magentoUser['Sales Order Id'] = data_magentoUser['Sales Order Id'].astype(str)\n",
    "#         data_magento['Order #'] = data_magento['Order #'].astype(str)\n",
    "\n",
    "#         temp2 = data_magento.merge(data_magentoUser[['Sales Order Id', 'AWB', 'Shipping Cost', 'Shipping Address1', 'Shipping City', 'Shipping Province', 'Shipping Phone']].drop_duplicates('Sales Order Id'), how = 'left', left_on = 'Order #', right_on = 'Sales Order Id').set_index(data_magento.index)\n",
    "\n",
    "#         data_magento['Shipping'] = np.nan\n",
    "#         data_magento['AWB'] = np.nan\n",
    "\n",
    "#         data_magento['Shipping'][temp2.index] = temp2['Shipping Cost']\n",
    "#         data_magento['AWB'][temp2.index] = temp2['AWB']\n",
    "\n",
    "\n",
    "#         # Phone formatting\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].fillna(0.0)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\" \",\"\")\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"-\",\"\")\n",
    "#         temp = data_magento[\"Phone\"].astype(str).str.split(\",\", expand = True)\n",
    "#         data_magento[\"Phone\"] = temp[0]\n",
    "#         temp = data_magento[\"Phone\"].astype(str).str.split(\"/\", expand = True)\n",
    "#         data_magento[\"Phone\"] = temp[0]\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+620\", \"0\", regex = True)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^620\", \"0\", regex = True)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^8\", \"08\", regex = True)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^21\", \"021\", regex = True)\n",
    "        \n",
    "        \n",
    "#         data_magento['Shipping Address1'] = np.nan\n",
    "#         data_magento['Shipping City'] = np.nan\n",
    "#         data_magento['Shipping Province'] = np.nan\n",
    "#         data_magento['Shipping Phone'] = np.nan\n",
    "\n",
    "#         data_magento['Shipping Address1'][temp2.index] = temp2['Shipping Address1']\n",
    "#         data_magento['Shipping City'][temp2.index] = temp2['Shipping City']\n",
    "#         data_magento['Shipping Province'][temp2.index] = temp2['Shipping Province']\n",
    "#         data_magento['Shipping Phone'][temp2.index] = temp2['Shipping Phone']\n",
    "        \n",
    "        \n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].fillna(0.0)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\" \",\"\")\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"-\",\"\")\n",
    "#         temp = data_magento[\"Shipping Phone\"].astype(str).str.split(\",\", expand = True)\n",
    "#         data_magento[\"Shipping Phone\"] = temp[0]\n",
    "#         temp = data_magento[\"Shipping Phone\"].astype(str).str.split(\"/\", expand = True)\n",
    "#         data_magento[\"Shipping Phone\"] = temp[0]\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+620\", \"0\", regex = True)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^620\", \"0\", regex = True)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^8\", \"08\", regex = True)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^21\", \"021\", regex = True)\n",
    "\n",
    "#         # Master tatanama\n",
    "#         print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#         print(\"Fulfilling SKU ====== 3/10\")\n",
    "\n",
    "#         data_magento['SKU'] = data_magento['SKU'].astype(str).str.split('-').str[0]\n",
    "#         indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "\n",
    "#         skuhd = data_magento[data_magento['SKU'].astype(str).str.contains('hd', case = False)]\n",
    "#         skushopee = data_magento[data_magento['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "#         data_magento = data_magento[~data_magento['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "#         data_magento = data_magento[~data_magento['SKU'].astype(str).isin(skuhd['SKU'].astype(str))]\n",
    "\n",
    "#         skuhd = skuhd.reset_index(drop = True)\n",
    "#         skushopee = skushopee.reset_index(drop = True)\n",
    "#         data_magento = data_magento.reset_index(drop = True)\n",
    "\n",
    "#         indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "#         for i in indeks:\n",
    "#             if data_magento['Product Name'][i].lower() in data_SKU['Nama Produk'].str.lower().values:\n",
    "#                 data_magento['SKU'][i] = data_SKU['SKU'].loc[data_SKU['Nama Produk'].str.lower() == str(data_magento['Product Name'][i]).lower()].values[0]\n",
    "\n",
    "#         list_alias = []\n",
    "#         list_alias_name = []\n",
    "#         for colname in data_SKU.columns:\n",
    "#             if 'Alias SKU' in colname:\n",
    "#                 list_alias.append(colname)\n",
    "#             if 'Alias Nama' in colname:\n",
    "#                 list_alias_name.append(colname)\n",
    "\n",
    "#         for i in indeks:\n",
    "#             for j in list_alias:\n",
    "#                 if str(data_magento['SKU'][i]) in data_SKU[j].astype(str).values:\n",
    "#                     idx = data_SKU[str(data_magento['SKU'][i]) == data_SKU[j].astype(str)].index.to_list()\n",
    "#                     for k in idx:\n",
    "#                         if str(data_magento['SKU'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "#                             data_magento['SKU'][i] = data_SKU['SKU'][k]\n",
    "\n",
    "#         indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "\n",
    "#         for i in indeks:\n",
    "#             for j in list_alias_name:\n",
    "#                 if str(data_magento['Product Name'][i]).lower() in data_SKU[j].astype(str).str.lower().values:\n",
    "#                     data_magento['SKU'][i] = data_SKU['SKU'].loc[str(data_magento['Product Name'][i]).lower() == data_SKU[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "#         data_magento = data_magento[data_magento['Product Name'].astype(str) != 'WRP Everyday Low Fat Milk Coklat 4 Pillow Bag']\n",
    "#         data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Kitchen Japanese Matcha Latte (12 Sch)']\n",
    "#         data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Kitchen Vietnamese Coffee Latte (12 Sch)']\n",
    "#         data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Raspberry Pumpkin (24 pcs)']\n",
    "#         data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Raspberry Pumpkin (1 pc)']\n",
    "        \n",
    "#         data_magento['SKU'] = data_magento['SKU'].astype(str).str.replace('7300281P24', '7300281')\n",
    "        \n",
    "#         data_magento = data_magento[~data_magento['Product Name'].astype(str).str.contains('JANGAN DIORDER INI TESTING')]\n",
    "#         data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('7300851')]\n",
    "        \n",
    "        \n",
    "#         print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#         print(\"Listing SKU Missing ====== 4/10\")   \n",
    "#         idx = data_magento[['SKU']][data_magento['SKU'].isnull()].drop_duplicates().index.to_list()\n",
    "#         idx = idx + data_magento[['SKU', 'Product Name']][~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "#         idx = list(dict.fromkeys(idx))\n",
    "#         idx_s = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "#         idx_s = list(dict.fromkeys(idx_s))\n",
    "#         idx_hd = skuhd[~skuhd['SKU'].astype(str).str.replace('hd','',case = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "#         idx_hd = list(dict.fromkeys(idx_hd))\n",
    "\n",
    "#         to_excel = data_magento.to_excel(r'magento_new.xls', index = False)\n",
    "#         print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#         if len(idx) != 0 or len(idx_s) != 0 or len(idx_hd) != 0:\n",
    "#             print('SKU is missing')\n",
    "#             alert = data_magento.iloc[idx, ][['SKU', 'Product Name']].drop_duplicates()\n",
    "#             alert = alert.append(skushopee.iloc[idx_s][['SKU', 'Product Name']].drop_duplicates(), ignore_index = True, sort = False)\n",
    "#             alert['SKU Valid'] = np.nan\n",
    "#             to_excel = alert.to_excel('ALERT_MAGENTO_SKU_MISSING.xlsx')\n",
    "#             print(\"Some SKU Missing Please Complete It ====== 5/10\")\n",
    "#             print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#             s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "#             # start TLS for security \n",
    "#             s.starttls() \n",
    "\n",
    "#             # Authentication \n",
    "#             s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "#             msg = MIMEMultipart()\n",
    "#             msg['Subject'] = \"ALERT SKU MAGENTO MISSING\"\n",
    "\n",
    "\n",
    "#             html = \"\"\"\\\n",
    "#             <html>\n",
    "#             <head></head>\n",
    "#             <body>\n",
    "#                 {0}\n",
    "#             </body>\n",
    "#             </html>\n",
    "#             \"\"\".format(alert.to_html())\n",
    "\n",
    "#             part1 = MIMEText(html, 'html')\n",
    "#             msg.attach(part1)\n",
    "\n",
    "#             # sending the mail \n",
    "#             s.sendmail(\"automationnfi@gmail.com\", \"andra.miftah@nutrifood.co.id\", msg.as_string()) \n",
    "\n",
    "#             # terminating the session \n",
    "#             s.quit()\n",
    "#         else :\n",
    "#             print(\"Preparing Appending Magento to Masterdata\")\n",
    "#             print(\"Filling Brand ====== 5/10\")  \n",
    "#             data_magento = data_magento.append(skushopee, ignore_index = True, sort = False)\n",
    "#             data_magento = data_magento.reset_index(drop = True)\n",
    "\n",
    "#             data_magento['SKU'] = data_magento['SKU'].astype(str)\n",
    "#             data_magento['Product Name'] = data_magento['Product Name'].astype(str)\n",
    "#             data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "#             data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "#             data_magento = data_magento.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "#             temp = data_magento[data_magento['Real SKU'].isnull()].copy()\n",
    "#             temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "#             temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "#             temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "#             temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "#             temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "#             temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "#             indeks = data_magento[data_magento['Real SKU'].isnull()].index.to_list()\n",
    "#             data_magento['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "#             data_magento['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "#             temp = data_magento[data_magento['Real SKU'].isnull()].copy()\n",
    "#             temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "#             temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "#             temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "#             temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "#             temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "#             temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "#             indeks = data_magento[data_magento['Real SKU'].isnull()].index.to_list()\n",
    "#             data_magento['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "#             data_magento['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "#             data_magento['Real SKU'] = data_magento['Real SKU'].astype(str)\n",
    "#             data_magento = data_magento.merge(data_SKU[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "#             data_magento = data_magento.drop(['SKU_y'], axis = 1)\n",
    "#             data_magento = data_magento.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "#             print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#             print(\"Unbundling ====== 6/10\")\n",
    "#             list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "#             data_magento = data_magento.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "#             data_magento = data_magento.drop(['SKU_y'], axis = 1)\n",
    "#             data_magento = data_magento.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "#             indeks = data_magento[data_magento['Brand'] == 'Bundle'].index.to_list()\n",
    "#             data_magento['Bundle Flag'] = np.nan\n",
    "#             data_magento['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "#             print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#             print(\"Filling Date ====== 7/10\")\n",
    "#             data_magento['Date'] = np.nan\n",
    "#             data_magento['Month'] = np.nan\n",
    "#             data_magento['Year'] = np.nan\n",
    "\n",
    "#             for i in range(data_magento.shape[0]):\n",
    "#                 if int(data_magento['Order date'][i].strftime('%d')) <= 12:\n",
    "#                     data_magento['Date'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "#                     data_magento['Month'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "#                     data_magento['Year'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "#                 else :\n",
    "#                     data_magento['Date'][i] = pd.to_datetime(data_magento['Order date'][i]).day\n",
    "#                     data_magento['Month'][i] = pd.to_datetime(data_magento['Order date'][i]).month_name()\n",
    "#                     data_magento['Year'][i] = pd.to_datetime(data_magento['Order date'][i]).year\n",
    "\n",
    "\n",
    "#             quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "#                     ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "#             data_magento = data_magento.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "#             data_magento = data_magento.drop(['Bulan'], axis = 1)\n",
    "#             data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "#                     {'Bulan' : 'January' , 'Number': 1},\n",
    "#                     {'Bulan' : 'February' , 'Number': 2},\n",
    "#                     {'Bulan' : 'March' , 'Number': 3},\n",
    "#                     {'Bulan' : 'April' , 'Number': 4},\n",
    "#                     {'Bulan' : 'May' , 'Number': 5},\n",
    "#                     {'Bulan' : 'June', 'Number': 6},\n",
    "#                     {'Bulan' : 'July' , 'Number': 7},\n",
    "#                     {'Bulan' : 'August', 'Number' : 8},\n",
    "#                     {'Bulan' : 'September', 'Number' : 9},\n",
    "#                     {'Bulan' : 'October' , 'Number': 10},\n",
    "#                     {'Bulan' : 'November' , 'Number': 11}])\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['Day'] = temp['Date']\n",
    "#             temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "#             temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "#             data_magento['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "#             data_magento['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "#             data_magento['Channel'] = 'Nutrimart'\n",
    "#             data_magento['Store'] = 'Nutrimart'\n",
    "#             data_magento['Selling Price'] = data_magento['Item Price']\n",
    "#             print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#             print(\"Pricing\")\n",
    "#             data_magento = data_magento.merge(data_SKU[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(data_magento.index)\n",
    "#             data_magento = data_magento.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "#             data_magento['Price List NFI'] = pd.to_numeric(data_magento['Price List NFI']).astype(int)\n",
    "#             data_magento['Harga Cost'] = pd.to_numeric(data_magento['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "#             data_magento['Qty. Invoiced'] = pd.to_numeric(data_magento['Qty. Invoiced']).astype(int)\n",
    "#             data_magento['Total Net'] = data_magento['Price List NFI'] * data_magento['Qty. Invoiced']\n",
    "#             data_magento['Total Harga Cost'] = data_magento['Harga Cost'] * data_magento['Qty. Invoiced']\n",
    "\n",
    "#             data_magento = data_magento.drop('SKU_y', axis = 1)\n",
    "#             data_magento = data_magento.reset_index(drop = True)\n",
    "#             data_magento['Order #'] = data_magento['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "#             list_bundle = data_magento[data_magento['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "#             list_nobundle = data_magento[data_magento['Bundle Name'].notnull()]\n",
    "#             list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "#             list_nobundle\n",
    "\n",
    "#             data_magento['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "#             data_magento['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "#             temp = data_magento[data_magento['Bundle Name'].notnull()]\n",
    "#             temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "#             temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "#             temp['Selling Price'] = temp['Subtotal'] / temp['Qty. Invoiced']\n",
    "\n",
    "#             data_magento['Total'][temp.index] = temp['Total'].fillna(0).astype(int)\n",
    "#             data_magento['Subtotal'][temp.index] = temp['Subtotal'].fillna(0).astype(int)\n",
    "#             data_magento['Selling Price'][temp.index] = temp['Selling Price'].fillna(0).astype(int)\n",
    "\n",
    "#             print(\"Filling Location\")\n",
    "#             data_magento['Kecamatan'] = np.nan\n",
    "#             data_magento['Kelurahan'] = np.nan\n",
    "# #             data_magento = data_magento.rename(columns = {'Shipping City' : 'City', 'Shipping Province' : 'Region'})\n",
    "\n",
    "#             indeks = data_magento[data_magento['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Kecamatan'][indeks] = data_magento['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "#                 data_magento['City'][indeks] = data_magento['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "#             indeks = data_magento[data_magento['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Kelurahan'][indeks] = data_magento['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "#                 data_magento['Kecamatan'][indeks] = data_magento['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "#             indeks = data_magento[data_magento['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Kecamatan'][indeks] = data_magento['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "#                 data_magento['City'][indeks] = data_magento['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "#             indeks = data_magento[data_magento['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Kelurahan'][indeks] = data_magento['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "#                 data_magento['Kecamatan'][indeks] = data_magento['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "#             city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['City'] = temp['City'].astype(str).str.lower()\n",
    "#             city['All City'] = city['All City'].astype(str).str.lower()\n",
    "#             temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "#             indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "#             data_magento['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "#             province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "#             province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "#             temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "#             indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "#             data_magento['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "#             temp = data_magento.copy()\n",
    "#             temp = temp[temp['Region'].isnull()]\n",
    "#             temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "#             data_magento['Region'][temp.index] = temp['Region']\n",
    "\n",
    "#             district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "#             district['All District'] = district['All District'].astype(str).str.lower()\n",
    "#             temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "#             indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "#             data_magento['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "#             temp = data_magento.copy()\n",
    "#             temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "#             indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "#             data_magento['City'][indeks] = np.nan\n",
    "            \n",
    "#             indeks = data_magento[data_magento['Shipping City'].astype(str).str.contains('/')]['Shipping City'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Shipping City'][indeks] = data_magento['Shipping City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "#             indeks = data_magento[data_magento['Shipping City'].astype(str).str.contains(',')]['Shipping City'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Shipping City'][indeks] = data_magento['Shipping City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "#             city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['Shipping City'] = temp['Shipping City'].astype(str).str.lower()\n",
    "#             city['All City'] = city['All City'].astype(str).str.lower()\n",
    "#             temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'Shipping City', right_on = 'All City').set_index(temp.index)\n",
    "#             indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "#             data_magento['Shipping City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "#             province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['Shipping Province'] = temp['Shipping Province'].astype(str).str.lower()\n",
    "#             province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "#             temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Shipping Province', right_on = 'All Province').set_index(temp.index)\n",
    "#             indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "#             data_magento['Shipping Province'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "#             temp = data_magento.copy()\n",
    "#             temp = temp[temp['Shipping Province'].isnull()]\n",
    "#             temp['Shipping Province'] = temp.merge(master_map, how = 'left', left_on = 'Shipping City', right_on = 'City').set_index(temp.index)['Shipping Province']\n",
    "#             data_magento['Shipping Province'][temp.index] = temp['Shipping Province']\n",
    "\n",
    "#             temp = data_magento.copy()\n",
    "#             temp2 = temp[['Shipping Province', 'Shipping City']].merge(master_map, how = 'left', left_on = 'Shipping City', right_on = 'City')\n",
    "#             indeks = temp2[temp2['Shipping Province'] != temp2['Province']][temp2[temp2['Shipping Province'] != temp2['Province']]['Shipping City'].notnull()].index.to_list()\n",
    "#             data_magento['Shipping City'][indeks] = np.nan\n",
    "#             data_magento['Warehouse Name'] = 'Primary Warehouse'\n",
    "\n",
    "#             import os\n",
    "#             import glob\n",
    "\n",
    "#             list_of_files = glob.glob('Clean Data/*.csv')\n",
    "#             latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "#             data_all = pd.read_csv(latest_file, sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "#             data_all = data_all[data_all['Store Type'] != 'Retail Online']\n",
    "            \n",
    "#             data_all['Phone'] = data_all['Phone'].astype(str).str.replace('=\"', '', regex = False)\n",
    "#             data_all['Phone'] = data_all['Phone'].astype(str).str.replace('\"', '', regex = False)\n",
    "\n",
    "#             lmen_store = forstok_all[forstok_all['Channel'] == 'L-Men Store Blibli']\n",
    "#             forstok_all = forstok_all[forstok_all['Channel'] != 'L-Men Store Blibli']\n",
    "\n",
    "#             lmen_store = lmen_store[~lmen_store['Order #'].astype(str).isin(data_all['Order #'].astype(str))]\n",
    "#             lmen_store['Sales Order ID'] = lmen_store['Sales Order ID'].fillna(lmen_store['No. Order Item L-Men Blibli'])\n",
    "#             ornum = lmen_store[['Order #', 'Sales Order ID']].drop_duplicates('Order #')\n",
    "\n",
    "#             options = Options()\n",
    "#             options.add_experimental_option(\"prefs\", {\n",
    "#                     \"download.default_directory\": str(os.getcwd())  + '/Input Data',\n",
    "#                     \"download.directory_upgrade\": True,\n",
    "#                     \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "#                     \"safebrowsing.enabled\": False\n",
    "#             })\n",
    "\n",
    "#             driver = webdriver.Chrome(options=options)\n",
    "#             driver.get(\"https://seller.blibli.com/sign-in\")\n",
    "\n",
    "\n",
    "#             username = driver.find_element_by_id(\"email\")\n",
    "#             username.clear()\n",
    "#             username.send_keys(\"novita.vidianti@nutrifood.co.id\")\n",
    "\n",
    "#             password = driver.find_element_by_id(\"password\")\n",
    "#             password.send_keys(\"EsPodeeng2021\")\n",
    "\n",
    "#             driver.find_element_by_id(\"sign-in\").click()\n",
    "#             time.sleep(5)\n",
    "# #             WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'close-announcement-button'))).click()\n",
    "# #             WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'remind-me-later-button'))).click()\n",
    "#             #     WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'nav-wrapper-ORDER'))).click()\n",
    "#             #     driver.find_element_by_id(\"sub-nav-item-0\").click()\n",
    "#             driver.get(\"https://seller.blibli.com/MTA/order/summary\")\n",
    "#             WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn-primary-mta'))).click()\n",
    "#             driver.find_element_by_id(\"semuaFilter\").click()\n",
    "\n",
    "#             ornum['Phone'] = np.nan\n",
    "#             ornum['Email'] = np.nan\n",
    "#             ornum['Address'] = np.nan\n",
    "\n",
    "#             for i in ornum.index:\n",
    "#                 orderNo = ornum['Order #'][i]\n",
    "#                 orderItemNo = int(pd.to_numeric(ornum['Sales Order ID'][i]))\n",
    "#                 link = \"https://merchant.blibli.com/MTA/neo/order/order-detail/\" + \"?orderNo=\" + str(orderNo) + \"&orderItemNo=\" + str(orderItemNo)\n",
    "#                 driver.get(link)\n",
    "#                 WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"customer-phone\"]/span')))\n",
    "#                 hp = driver.find_elements_by_xpath('//*[@id=\"customer-phone\"]/span')[0].text\n",
    "#                 if len(driver.find_elements_by_xpath('//*[@id=\"customer-email\"]/span')) != 0:\n",
    "#                     email = driver.find_elements_by_xpath('//*[@id=\"customer-email\"]/span')[0].text\n",
    "#                     ornum['Email'][i] = email\n",
    "#                 address = driver.find_elements_by_xpath('//*[@id=\"alamat-pengiriman\"]//div//p')[0].text\n",
    "#                 ornum['Phone'][i] = hp\n",
    "#                 ornum['Address'][i] = address\n",
    "\n",
    "#             driver.quit()\n",
    "#             if len(ornum) != 0:\n",
    "#                 tes = ornum.copy()\n",
    "#                 tes['Real Address'] = tes['Address'].str.split('\\n', expand = True)[1].str.strip()\n",
    "#                 tes['Kelurahan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[0].str.strip()\n",
    "#                 tes['Kecamatan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[1].str.strip()\n",
    "#                 tes['City'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[0].str.strip()\n",
    "#                 tes['Region'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[1].str.strip()\n",
    "#                 tes['Zip Code'] = tes['Address'].str.split('\\n', expand = True)[5].str.strip()\n",
    "\n",
    "#                 lmen_store['Order #'] = lmen_store['Order #'].astype(str)\n",
    "#                 tes['Order #'] = tes['Order #'].astype(str)\n",
    "#                 lmen_store = lmen_store.merge(tes[['Order #', 'Phone', 'Email', 'Real Address', 'Kelurahan', 'Kecamatan', 'City', 'Region', 'Zip Code']].drop_duplicates('Order #'), how = 'left', on = 'Order #')\n",
    "\n",
    "#                 indeks = lmen_store[lmen_store['Phone_y'].notnull()].index.to_list()\n",
    "#                 lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "#                 lmen_store['Customer Email'][indeks] = lmen_store['Email'][indeks]\n",
    "#                 lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "#                 lmen_store['Region_x'][indeks] = lmen_store['Region_y'][indeks]\n",
    "#                 lmen_store['City_x'][indeks] = lmen_store['City_y'][indeks]\n",
    "#                 lmen_store['Kecamatan_x'][indeks] = lmen_store['Kecamatan_y'][indeks]\n",
    "#                 lmen_store['Kelurahan_x'][indeks] = lmen_store['Kelurahan_y'][indeks]\n",
    "#                 lmen_store['Zip Code_x'][indeks] = lmen_store['Zip Code_y'][indeks]\n",
    "#                 lmen_store['Address'][indeks] = lmen_store['Real Address'][indeks]\n",
    "\n",
    "#                 lmen_store = lmen_store.drop(['Phone_y', 'Email', 'Region_y', 'City_y', 'Kecamatan_y', 'Kelurahan_y', 'Real Address', 'Zip Code_y'], axis = 1)\n",
    "#                 lmen_store = lmen_store.rename(columns = {'Phone_x' : 'Phone', 'Region_x' : 'Region', 'City_x' : 'City', 'Kecamatan_x' : 'Kecamatan', 'Kelurahan_x' : 'Kelurahan', 'Zip Code_x' : 'Zip Code'})\n",
    "\n",
    "#             forstok_all = forstok_all.append(lmen_store, ignore_index = True, sort = False)\n",
    "\n",
    "#             indeks = data_all[data_all['Channel'] == 'L-Men Store Blibli'].index.to_list()\n",
    "#             data_all['Store'][indeks] = 'Blibli'\n",
    "\n",
    "#             data_all = data_all[~data_all['Order #'].astype(str).isin(forstok_all['Order #'].astype(str))]\n",
    "#             data_all = data_all[~data_all['Order #'].astype(str).isin(data_magento['Order #'].astype(str))]\n",
    "#             data_all = data_all.append(forstok_all, ignore_index = True, sort = False)\n",
    "#             data_all = data_all.append(data_magento, ignore_index = True, sort = False)\n",
    "#             data_all['Brand'] = data_all['Brand'].astype(str).str.replace('Tropicana Slim', 'TS')\n",
    "\n",
    "#             indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "#             data_all['Qty. Invoiced'][indeks] = data_all['Qty. Shipped'][indeks]\n",
    "#             data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "#             indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "#             data_all['Qty. Invoiced'][indeks] = data_all['Qty. Ordered'][indeks]\n",
    "#             data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "\n",
    "# #             data_SKU['Brand Temp'] = np.nan\n",
    "# #             for i in range(len(data_SKU)):\n",
    "# #                 if data_SKU['Brand'][i] == 'Bonus Produk':\n",
    "# #                     if 'hilo' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = 'HiLo'\n",
    "# #                     elif 'tropicana' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = 'TS'\n",
    "# #                     elif 'l-men' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = 'L-Men'\n",
    "# #                     elif \"w'dank\" in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = \"W'dank\"\n",
    "# #                     elif 'nutrisari' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = 'NS'\n",
    "# #                     elif 'ts ' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = 'TS'\n",
    "# #                     data_SKU['Brand Temp'][i] = brand\n",
    "# #             data_SKU['Brand Temp'] = data_SKU['Brand Temp'].fillna(data_SKU['Brand'])\n",
    "\n",
    "# #             data_SKU['List Brand'] = np.nan\n",
    "# #             for i in range(len(data_SKU)):\n",
    "# #                 list_brand = []\n",
    "# #                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "# #                     col_SKU = [x for x in data_SKU.columns if 'SKU Produk' in x]\n",
    "# #                     for j in col_SKU:\n",
    "# #                         if str(data_SKU[j][i]) != 'nan' and str(data_SKU[j][i]) != '0':\n",
    "# #                             brand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Brand Temp'].values[0]\n",
    "# #                             if brand == 'Gimmick' : \n",
    "# #                                 if 'voucher' in data_SKU['Nama Produk'][i].lower() or 'saldo' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Voucher'\n",
    "# #                                 elif 'pouch' in data_SKU['Nama Produk'][i].lower() or 'bag ' in data_SKU['Nama Produk'][i].lower() or 'tas ' in data_SKU['Nama Produk'][i].lower() or 'totebag' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Bag'\n",
    "# #                                 elif 'bottle' in data_SKU['Nama Produk'][i].lower() or 'gelas ' in data_SKU['Nama Produk'][i].lower() or 'shaker' in data_SKU['Nama Produk'][i].lower() or 'tumblr' in data_SKU['Nama Produk'][i].lower() or 'tumbler' in data_SKU['Nama Produk'][i].lower() or 'botol' in data_SKU['Nama Produk'][i].lower() or 'thumbler' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Tumblr'\n",
    "# #                                 elif 'lunch' in data_SKU['Nama Produk'][i].lower() or 'tupper' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Lunch Box'\n",
    "# #                                 elif 'emoney' in data_SKU['Nama Produk'][i].lower() or 'e-money' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'E-Money'\n",
    "# #                                 elif 'magnet' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Magnet'\n",
    "# #                                 elif 'masker' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Masker'\n",
    "# #                                 elif 'spatula' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Spatula'\n",
    "# #                                 elif 'nivea' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Nivea'\n",
    "# #                                 elif 'card ' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Card'\n",
    "# #                                 elif 'mug' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Mug'\n",
    "# #                             list_brand.append(brand)\n",
    "# #                 data_SKU['List Brand'][i] = list_brand\n",
    "\n",
    "# #             for i in range(len(data_SKU)):\n",
    "# #                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "# #                     list_brand = list(dict.fromkeys(data_SKU['List Brand'][i]))\n",
    "# #                     sum_brand = sum([1 for x in list_brand if x in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]])\n",
    "# #                     if sum_brand == 1:\n",
    "# #                         list_brand = ' + '.join(list_brand)\n",
    "# #                     else :\n",
    "# #                         not_brand = [x for x in list_brand if x not in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]]\n",
    "# #                         if len(not_brand) == 0:\n",
    "# #                             list_brand = 'Cross Brand'\n",
    "# #                         else :\n",
    "# #                             list_brand = 'Cross Brand + ' + ' + '.join(not_brand)\n",
    "# #                     data_SKU['Sub Brand'][i] = list_brand\n",
    "# #             temp = data_all[data_all['Brand'] == 'Bundle']\n",
    "# #             temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "# #             data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "# #             data_all['Sub Brand'][temp.index] = temp.merge(data_SKU[['SKU', 'Sub Brand']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(temp.index)['Sub Brand_y']\n",
    "        \n",
    "            \n",
    "#             import re \n",
    "#             data_all['Phone'] = data_all['Phone'].astype(str).str.split(';', expand = True)[0]\n",
    "#             data_all['Phone'] = data_all['Phone'].astype(str).str.replace('.0','', regex = False)\n",
    "#             non_phone = data_all[~data_all['Phone'].astype(str).str.isnumeric()]['Phone'].unique()\n",
    "#             for i in non_phone:\n",
    "#                 index = data_all[data_all['Phone'].astype(str) == str(i)].index.to_list()\n",
    "#                 if str(i) != 'nan' and str(i) != '':\n",
    "#                     phone = re.sub(\"[^0-9]\", \"\", i)\n",
    "#                     if phone[0] == '8':\n",
    "#                         phone = '0' + phone\n",
    "#                     data_all['Phone'][index] = phone\n",
    "#             data_all['Phone'] = data_all['Phone'].astype(str).str.replace('^628', '08', regex = True)\n",
    "#             data_all['Phone'] = data_all['Phone'].apply('=\"{}\"'.format)\n",
    "#             data_all['Shipping Phone'] = data_all['Shipping Phone'].apply('=\"{}\"'.format)\n",
    "#             indeks = data_all[data_all['City'] == 'nan'].index.to_list()\n",
    "#             data_all['City'][indeks] = np.nan\n",
    "\n",
    "#             indeks = data_all[data_all['Region'] == 'nan'].index.to_list()\n",
    "#             data_all['Region'][indeks] = np.nan\n",
    "\n",
    "#             indeks = data_all[data_all['Channel'] == 'FBL'].index.to_list()\n",
    "#             data_all['Warehouse Name'][indeks] = 'Lazada Warehouse'\n",
    "\n",
    "#             indeks = data_all[data_all['Warehouse Name'] == 'Lazada Warehouse'].index.to_list()\n",
    "#             data_all['Channel'][indeks] = 'FBL'\n",
    "\n",
    "#             print(\"Read Data Settlement\")\n",
    "#             data_set = pd.read_csv(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Settlement\\test.csv')\n",
    "#             data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "#             data_set['channelorderid'] = data_set['channelorderid'].astype(str)\n",
    "\n",
    "#             temp_set = data_all.merge(data_set[['channelorderid', 'nominal', 'btlcost', 'gs', 'commfee', 'fullfee']].drop_duplicates('channelorderid'), how = 'left', left_on = 'Order #', right_on = 'channelorderid').set_index(data_all.index)\n",
    "#             if 'nominal' not in data_all.columns:\n",
    "#                 data_all['nominal'] = np.nan\n",
    "#                 data_all['btlcost'] = np.nan\n",
    "#                 data_all['gs'] = np.nan\n",
    "#                 data_all['commfee'] = np.nan\n",
    "#                 data_all['fullfee'] = np.nan\n",
    "#                 temp_set = temp_set[temp_set['Bundle Flag'] == 'nan']\n",
    "#                 temp_set['nominal'] = temp_set['nominal'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['btlcost'] = temp_set['btlcost'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['gs'] = temp_set['gs'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['commfee'] = temp_set['commfee'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['fullfee'] = temp_set['fullfee'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set = temp_set[temp_set['nominal'].notnull()]\n",
    "#                 data_all['nominal'][temp_set.index] = temp_set['nominal']\n",
    "#                 data_all['btlcost'][temp_set.index] = temp_set['btlcost']\n",
    "#                 data_all['gs'][temp_set.index] = temp_set['gs']\n",
    "#                 data_all['commfee'][temp_set.index] = temp_set['commfee']\n",
    "#                 data_all['fullfee'][temp_set.index] = temp_set['fullfee']\n",
    "#             else :\n",
    "#                 temp_set = temp_set[temp_set['Bundle Flag'].isnull()]\n",
    "#                 temp_set['nominal_y'] = temp_set['nominal_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['btlcost_y'] = temp_set['btlcost_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['gs_y'] = temp_set['gs_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['commfee_y'] = temp_set['commfee_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['fullfee_y'] = temp_set['fullfee_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set = temp_set[temp_set['nominal_y'].notnull()]\n",
    "#                 data_all['nominal'][temp_set.index] = temp_set['nominal_y']\n",
    "#                 data_all['btlcost'][temp_set.index] = temp_set['btlcost_y']\n",
    "#                 data_all['gs'][temp_set.index] = temp_set['gs_y']\n",
    "#                 data_all['commfee'][temp_set.index] = temp_set['commfee_y']\n",
    "#                 data_all['fullfee'][temp_set.index] = temp_set['fullfee_y']\n",
    "\n",
    "#             print(\"Export Data All\")\n",
    "#             for i in data_all.columns[data_all.columns.get_loc('nominal'):]:\n",
    "#                 data_all[i] = pd.to_numeric(data_all[i], errors = 'coerce').fillna(0).astype(int)\n",
    "                \n",
    "#             temp = data_all.copy()\n",
    "#             temp = temp.rename(columns = {'Date' : 'Day'})\n",
    "#             temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "#             temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "#             temp['Hour'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.hour\n",
    "#             temp['Minute'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.minute\n",
    "#             temp['Second'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.second\n",
    "#             data_all['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "#             data_all['Hour'] = temp['Hour']\n",
    "\n",
    "#             from datetime import datetime\n",
    "\n",
    "#             print('Input Forstok Date')\n",
    "#             start_date = datetime.today() - timedelta(days=(diff_date+14))\n",
    "#             end_date = datetime.today()\n",
    "#             date = start_date.strftime('%Y-%m-%d') + '-' + end_date.strftime('%Y-%m-%d')\n",
    "#             print(date)\n",
    "\n",
    "\n",
    "#             print('Opening Chrome')\n",
    "#             driver = webdriver.Chrome()\n",
    "#             driver.fullscreen_window()\n",
    "#             driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "#             print('Login Forstok')\n",
    "#             username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "#             username.clear()\n",
    "#             username.send_keys(\"andra.miftah@nutrifood.co.id\")\n",
    "\n",
    "#             password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "#             password.send_keys(\"nutrimart1234\")\n",
    "\n",
    "#             driver.find_element_by_name(\"commit\").click()\n",
    "\n",
    "#             datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.ID, 'history_date')))\n",
    "#             datefield.click()\n",
    "\n",
    "#             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#             if start_date.month == end_date.month:\n",
    "#                 text = \"//div[@class='drp-calendar right']//td[@class = 'available' or @class='weekend available' or @class='in-range available' or @class = 'weekend in-range available'][text() = \" + str(start_date.day) + \"]\"\n",
    "#             else :\n",
    "#                 text = \"//div[@class='drp-calendar left']//td[@class = 'available' or @class='weekend available' or @class='in-range available' or @class = 'weekend in-range available'][text() = \" + str(start_date.day) + \"]\"\n",
    "#             driver.find_element_by_xpath(text).click()\n",
    "#             text = \"//div[@class='drp-calendar right']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "#             driver.find_element_by_xpath(text).click()\n",
    "#             time.sleep(2)\n",
    "#             driver.find_element_by_class_name('applyBtn').click()\n",
    "#             driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "#             time.sleep(15)\n",
    "#             WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'export-button'))).click()\n",
    "#             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#             time.sleep(2)\n",
    "#             WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'group_by_'))).click()\n",
    "#             driver.find_element(By.NAME, 'button').click()\n",
    "#             time.sleep(5)\n",
    "#             driver.quit()\n",
    "# #             driver = webdriver.Chrome()\n",
    "# #             driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "# #             username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "# #             username.clear()\n",
    "# #             username.send_keys(\"andra.miftah@nutrifood.co.id\")\n",
    "\n",
    "# #             password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "# #             password.send_keys(\"nutrimart1234\")\n",
    "\n",
    "# #             driver.find_element_by_name(\"commit\").click()\n",
    "\n",
    "# #             datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[2]/section/div')))\n",
    "# #             datefield.click()\n",
    "\n",
    "# #             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "# #             if start_date.month != end_date.month:\n",
    "# #                 text = \"//*[normalize-space(text()) = '\" + str(start_date.strftime('%B')) + \"']\"\n",
    "# #                 driver.find_element_by_xpath(text).click()\n",
    "# #             text = \"//*[normalize-space(text()) = '\" + str(start_date.strftime('%B')) + \"']\" + \"/../..//*[normalize-space(text()) = '\" + str(start_date.day) + \"']\"\n",
    "# #             driver.find_element_by_xpath(text).click()\n",
    "# #             text = \"//*[normalize-space(text()) = '\" + str(end_date.strftime('%B')) + \"']/../..//td[not(contains(@class, 'otherMonth'))]//*[normalize-space(text()) = '\" + str(end_date.day) + \"']\"\n",
    "# #             driver.find_element_by_xpath(text).click()\n",
    "\n",
    "# #             driver.find_element_by_xpath('//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[2]/section/section/aside/div/button[2]').click()\n",
    "# #             driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "# #             time.sleep(15)\n",
    "# #             WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[1]/button'))).click()\n",
    "# #             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "# #             time.sleep(2)\n",
    "# #             driver.find_element(By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[2]/section[1]/div/div[1]/label').click()\n",
    "# #             driver.find_element(By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[2]/section[2]/button').click()\n",
    "# #             time.sleep(15)\n",
    "# #             driver.quit()\n",
    "\n",
    "#             print('Forstok Downloaded')\n",
    "\n",
    "#             print('Download Data SKU')\n",
    "#             # Import library\n",
    "\n",
    "#             import time\n",
    "#             import pandas as pd\n",
    "#             import numpy as np\n",
    "#             import math\n",
    "\n",
    "#             import smtplib \n",
    "#             from email.mime.text import MIMEText\n",
    "#             from email.mime.application import MIMEApplication\n",
    "#             from email.mime.multipart import MIMEMultipart\n",
    "#             from smtplib import SMTP\n",
    "#             import smtplib\n",
    "#             import sys\n",
    "#             import requests\n",
    "#             import os\n",
    "\n",
    "#             print('Waiting to Download Forstok')\n",
    "#             s = requests.Session()\n",
    "#             r = s.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "#             data = {'dashboard_user_email' : 'andra.miftah@nutrifood.co.id', \"dashboard_user_password\" : 'nutrimart1234'}\n",
    "#             r = s.post(\"https://www.forstok.com/dashboard/users/login\", data = data)\n",
    "\n",
    "#             text = 'https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/nutrifood--forstok-sales_orders-version_1-' + date + '.xls'\n",
    "#             print(text)\n",
    "#             while True:\n",
    "#                 r = s.get(text)\n",
    "#                 print('Waiting to Download Forstok')\n",
    "\n",
    "#                 if r.status_code == requests.codes.ok:\n",
    "#                     print(r.status_code)\n",
    "#                     with open('Input Data/Forstok_new_input.xls', 'wb') as output:\n",
    "#                         output.write(r.content)\n",
    "#                     break\n",
    "#                 else :\n",
    "#                     time.sleep(60)\n",
    "\n",
    "#             with open('Input Data/nutrifood--forstok-sales_orders-' + date + '.xls', 'wb') as output:\n",
    "#                 output.write(r.content)\n",
    "\n",
    "#             orstat_forstok = pd.read_excel(r'Input Data/Forstok_new_input.xls')\n",
    "#             orstat_forstok['Date'] = np.nan\n",
    "#             orstat_forstok['Month'] = np.nan\n",
    "#             orstat_forstok['Year'] = np.nan\n",
    "\n",
    "#             orstat_forstok['Order Date'] = pd.to_datetime(orstat_forstok['Order Date'])\n",
    "#             for i in range(orstat_forstok.shape[0]):\n",
    "#                 if int(orstat_forstok['Order Date'][i].strftime('%d')) <= 12:\n",
    "#                     orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "#                     orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "#                     orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "#                 else :\n",
    "#                     orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).day\n",
    "#                     orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).month_name()\n",
    "#                     orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).year\n",
    "\n",
    "#             temp = orstat_forstok.copy()\n",
    "#             temp['Day'] = temp['Date']\n",
    "#             temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "#             temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "#             orstat_forstok['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "#             temp['Hour'] = pd.to_datetime(orstat_forstok['Order Date']).dt.hour\n",
    "#             temp['Minute'] = pd.to_datetime(orstat_forstok['Order Date']).dt.minute\n",
    "#             temp['Second'] = pd.to_datetime(orstat_forstok['Order Date']).dt.second\n",
    "#             orstat_forstok['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "            \n",
    "#             print(\"Update Order Status\")\n",
    "#             date_min  = orstat_forstok['True datetime'].min()\n",
    "#             orstat_forstok = orstat_forstok[['Sales Order ID','Status']].drop_duplicates('Sales Order ID')\n",
    "#             shopee_bp = data_all[data_all['Customer Name'] == 'Shopee Brand Portal']\n",
    "#             data_all = data_all[data_all['Customer Name'] != 'Shopee Brand Portal']\n",
    "#             temp_all = data_all[data_all['True datetime'] >= pd.to_datetime(date_min)][~data_all[data_all['True datetime'] >= pd.to_datetime(date_min)]['Channel'].isin(['Nutrimart', 'L-Men Store Blibli', 'Order Online', 'Order Online Jakarta', 'Order Online Surabaya'])]\n",
    "#             orstat_forstok['Sales Order ID'] = orstat_forstok['Sales Order ID'].astype(str)\n",
    "#             temp_all['Sales Order ID'] = temp_all['Sales Order ID'].astype(str)\n",
    "#             temp_all = temp_all.merge(orstat_forstok, how = 'left', on = 'Sales Order ID')\n",
    "#             temp_all['Status'] = temp_all['Status'].fillna('Canceled')\n",
    "#             temp_all['Order Status'] = temp_all['Status']\n",
    "#             temp_all = temp_all.drop('Status', axis = 1)\n",
    "#             data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "#             temp_all['Order #'] = temp_all['Order #'].astype(str)\n",
    "#             data_all = data_all[~data_all['Order #'].isin(temp_all['Order #'])]\n",
    "#             data_all = data_all.append(temp_all, ignore_index = True, sort = False)\n",
    "#             data_all = data_all.append(shopee_bp, ignore_index = True, sort = False)\n",
    "#             print(\"Export Master Data\")\n",
    "            \n",
    "#             SKU = pd.read_excel(r'SKU_File/data_SKU.xlsx')\n",
    "#             SKU_baru = pd.read_excel(r'Subbrand Baru.xlsx')\n",
    "\n",
    "#             SKU_final = SKU.copy()\n",
    "#             SKU_baru['Item Group Code'] = SKU_baru['Item Group Code'].astype(str).str.replace('.0','', regex = False)\n",
    "#             SKU_final['SKU Clean'] = SKU_final['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False)\n",
    "#             SKU_final = SKU_final.merge(SKU_baru.drop_duplicates('Item Group Code'), how = 'left', left_on = 'SKU Clean', right_on = 'Item Group Code')\n",
    "\n",
    "#             no_pair = SKU[SKU['SKU'].astype(str).isin(SKU_final[SKU_final['Category Baru'].isnull()]['SKU'].astype(str))]\n",
    "#             SKU_final = SKU_final[~SKU_final['SKU'].astype(str).isin(no_pair['SKU'].astype(str))]\n",
    "\n",
    "#             no_pair['SKU Clean'] = no_pair['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False).str.replace('E', '', regex = False)\n",
    "#             SKU_baru['Item Group Code'] = SKU_baru['Product Code'].astype(str).str.replace('.0','', regex = False)\n",
    "\n",
    "#             index = no_pair[no_pair['SKU'].astype(str) == '1101984451'].index[0]\n",
    "#             no_pair['SKU Clean'][index] = '1101984453'\n",
    "\n",
    "#             index = no_pair[no_pair['SKU'].astype(str) == '2104393210'].index[0]\n",
    "#             no_pair['SKU Clean'][index] = '2104392210'\n",
    "\n",
    "#             no_pair = no_pair.merge(SKU_baru.drop_duplicates('Product Code'), how = 'left', left_on = 'SKU Clean', right_on = 'Product Code')\n",
    "\n",
    "#             SKU_final = SKU_final.append(no_pair, ignore_index = True, sort = False)\n",
    "\n",
    "#             index = SKU_final[SKU_final['SKU'].astype(str) == '1101569360'].index[0]\n",
    "#             SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "#             SKU_final['Unnamed: 3'][index] = \"NS JERUK PERAS REF 12DX500G\"\n",
    "\n",
    "#             index = SKU_final[SKU_final['SKU'].astype(str) == '1101686036'].index[0]\n",
    "#             SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "#             SKU_final['Unnamed: 3'][index] = \"W'DANK LKLT KOPI KAWISTA PLS 12RX10SX15G\"\n",
    "\n",
    "#             index = SKU_final[SKU_final['SKU'].astype(str) == '2104407'].index[0]\n",
    "#             SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "#             SKU_final['Unnamed: 3'][index] = 'TS EXTRA VIRGIN OLIVE OIL 12BTLX500ML'\n",
    "            \n",
    "#             index = SKU_final[SKU_final['SKU'].astype(str) == '2305551106'].index[0]\n",
    "#             SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "#             SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#             SKU = SKU.merge(SKU_final[['SKU', 'Category Baru', 'Unnamed: 3']].drop_duplicates('SKU'), how = 'left', on = 'SKU')\n",
    "#             SKU = SKU.rename(columns = {'Unnamed: 3' : 'Exported Parent Item'})\n",
    "\n",
    "#             index = data_all[data_all['Real SKU'] == '2101492P24'].index.to_list()\n",
    "#             data_all['Brand'][index] = 'Bundle'\n",
    "#             index = data_all[data_all['SKU'].isin(['71210111', '71210112'])].index.to_list()\n",
    "#             data_all['Brand'][index] = 'Bundle'\n",
    "#             indeks = data_all[data_all['Brand'] == 'TS'][data_all[data_all['Brand'] == 'TS']['Real SKU'].astype(str) == '2101453180'].index.to_list()\n",
    "#             data_all['Real SKU'][indeks] = data_all['SKU'][indeks]\n",
    "#             data_all['Parent Item'][indeks] = 'Tropicana Slim Milk Low Fat Vanilla 500gr'\n",
    "#             index = data_all[data_all['Brand'] == \"W'dank\"].index.to_list()\n",
    "#             data_all['Brand'][index] = 'NS'\n",
    "\n",
    "#             data_all['Real SKU'] = data_all['Real SKU'].astype(str)\n",
    "#             data_all = data_all.drop(['Category Baru', 'Exported Parent Item'], axis = 1)\n",
    "#             data_all.rename(columns = {'SKU_x' : 'SKU'}, inplace = True)\n",
    "#             data_all = data_all.merge(SKU[['SKU', 'Category Baru', 'Exported Parent Item']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "\n",
    "#             data_SKU = SKU.copy()\n",
    "#             data_SKU['Category Baru'] = data_SKU['Category Baru'].fillna(data_SKU['Sub Brand'])\n",
    "#             data_SKU['Category Baru'] = data_SKU['Category Baru'].fillna(data_SKU['Brand'])\n",
    "#             data_SKU['Sub Brand'] = data_SKU['Category Baru']\n",
    "#             data_all['Sub Brand'] = data_all['Category Baru']\n",
    "#             data_all = data_all.drop('SKU_y', axis = 1)\n",
    "#             data_all.rename(columns = {'SKU_x' : 'SKU'}, inplace = True)\n",
    "\n",
    "#             data_SKU['List Brand'] = np.nan\n",
    "#             for i in range(len(data_SKU)):\n",
    "#                 list_brand = []\n",
    "#                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "#                     col_SKU = [x for x in data_SKU.columns if 'SKU Produk' in x]\n",
    "#                     for j in col_SKU:\n",
    "#                         if str(data_SKU[j][i]) != 'nan' and str(data_SKU[j][i]) != '0':\n",
    "#                             subbrand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Sub Brand'].values[0]\n",
    "#                             brand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Brand'].values[0]\n",
    "#                             if brand == 'Gimmick' : \n",
    "#                                 if str(data_SKU['Nama Produk'][i]).lower() != 'nan' :\n",
    "#                                     if 'voucher' in data_SKU['Nama Produk'][i].lower() or 'saldo' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Voucher'\n",
    "#                                     elif 'pouch' in data_SKU['Nama Produk'][i].lower() or 'bag ' in data_SKU['Nama Produk'][i].lower() or 'tas ' in data_SKU['Nama Produk'][i].lower() or 'totebag' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Bag'\n",
    "#                                     elif 'bottle' in data_SKU['Nama Produk'][i].lower() or 'gelas ' in data_SKU['Nama Produk'][i].lower() or 'shaker' in data_SKU['Nama Produk'][i].lower() or 'tumblr' in data_SKU['Nama Produk'][i].lower() or 'tumbler' in data_SKU['Nama Produk'][i].lower() or 'botol' in data_SKU['Nama Produk'][i].lower() or 'thumbler' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Tumblr'\n",
    "#                                     elif 'lunch' in data_SKU['Nama Produk'][i].lower() or 'tupper' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Lunch Box'\n",
    "#                                     elif 'emoney' in data_SKU['Nama Produk'][i].lower() or 'e-money' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'E-Money'\n",
    "#                                     elif 'magnet' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Magnet'\n",
    "#                                     elif 'masker' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Masker'\n",
    "#                                     elif 'spatula' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Spatula'\n",
    "#                                     elif 'nivea' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Nivea'\n",
    "#                                     elif 'card ' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Card'\n",
    "#                                     elif 'mug' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Mug'\n",
    "#                                     list_brand.append(brand)\n",
    "#                                     data_SKU['Sub Brand'][i] = brand\n",
    "#                                 else :\n",
    "#                                     list_brand.append(subbrand)\n",
    "#                 data_SKU['List Brand'][i] = str(list_brand)\n",
    "\n",
    "#             for i in range(len(data_SKU)):\n",
    "#                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "#                     list_brand = list(dict.fromkeys(data_SKU['List Brand'][i]))\n",
    "#             #         sum_brand = sum([1 for x in list_brand if x in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]])\n",
    "#             #         if sum_brand == 1:\n",
    "#                     list_brand = ' + '.join(list_brand)\n",
    "#             #         else :\n",
    "#             #             not_brand = [x for x in list_brand if x not in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]]\n",
    "#             #             if len(not_brand) == 0:\n",
    "#             #                 list_brand = 'Cross Brand'\n",
    "#             #             else :\n",
    "#             #                 list_brand = 'Cross Brand + ' + ' + '.join(not_brand)\n",
    "#                     data_SKU['Sub Brand'][i] = list_brand\n",
    "\n",
    "\n",
    "#             temp = data_all.copy()\n",
    "#             temp['Real SKU'] = temp['Real SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "#             data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "#             data_all['Sub Brand'][temp.index] = temp.merge(data_SKU[['SKU', 'Sub Brand']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(temp.index)['Sub Brand_y']\n",
    "#             data_all.to_csv(r'Clean Data/data_all_' + data_now + '.csv', sep = ';', index = False)\n",
    "#             print(\"Clean Data Finish\")\n",
    "#             data_all[['Order #','Order Status','Date', 'Month','Year',\n",
    "#              'Hour',\n",
    "#              'Channel', 'Store',\n",
    "#              'SKU',\n",
    "#              'Brand',\n",
    "#              'Product Name',\n",
    "#              'Bundle Name',\n",
    "#              'Price List NFI',\n",
    "#              'Qty. Invoiced',\n",
    "#              'Total Net',\n",
    "#              'Sub Brand',\n",
    "#              'Real SKU',\n",
    "#              'Real Nama Produk',\n",
    "#              'Parent Item',\n",
    "#              'Parent SKU',\n",
    "#              'Bundle Flag',\n",
    "#              'Customer Email',\n",
    "#              'Customer Name',\n",
    "#              'Customer Group',\n",
    "#              'Phone',\n",
    "#              'Country',\n",
    "#              'Region',\n",
    "#              'City',\n",
    "#              'Kecamatan',\n",
    "#              'Kelurahan',\n",
    "#              'Address',\n",
    "#              'Zip Code','Shipping Courier',\n",
    "#              'Total',\n",
    "#              'Coupon Code','Subtotal',\n",
    "#              'Discounts','Cart Name Rule','Voucher Amount','Warehouse Name',\n",
    "#              'Regular Price',\n",
    "#              'Selling Price','Shipping',\n",
    "#              'Actual Shipping',\n",
    "#              'Seller Discount','True datetime',\n",
    "#              'Promo',\n",
    "#              'Discount MC',\n",
    "#              'Harga Cost',\n",
    "#              'Total Harga Cost','nominal',\n",
    "#              'btlcost',\n",
    "#              'gs',\n",
    "#              'commfee',\n",
    "#              'fullfee','Shipping Province',\n",
    "#              'Shipping City',\n",
    "#              'Shipping Address1',\n",
    "#              'Shipping Phone']].to_csv(r'Export Data/data_all_' + data_now + '.csv', sep = ';', index = False)\n",
    "#             print(\"Export Data Finish\")\n",
    "           \n",
    "#             data_all[data_all['Year'] == 2020][['Order #','Order Status','Date', 'Month','Year',\n",
    "#                  'Hour',\n",
    "#                  'Channel', 'Store',\n",
    "#                  'SKU',\n",
    "#                  'Brand',\n",
    "#                  'Product Name',\n",
    "#                  'Bundle Name',\n",
    "#                  'Price List NFI',\n",
    "#                  'Qty. Invoiced',\n",
    "#                  'Total Net',\n",
    "#                  'Sub Brand',\n",
    "#                  'Real SKU',\n",
    "#                  'Real Nama Produk',\n",
    "#                  'Parent Item',\n",
    "#                  'Parent SKU',\n",
    "#                  'Bundle Flag',\n",
    "#                  'Customer Email',\n",
    "#                  'Customer Name',\n",
    "#                  'Customer Group',\n",
    "#                  'Phone',\n",
    "#                  'Country',\n",
    "#                  'Region',\n",
    "#                  'City',\n",
    "#                  'Kecamatan',\n",
    "#                  'Kelurahan',\n",
    "#                  'Address',\n",
    "#                  'Zip Code','Shipping Courier',\n",
    "#                  'Total',\n",
    "#                  'Coupon Code','Subtotal',\n",
    "#                  'Discounts','Cart Name Rule','Voucher Amount','Warehouse Name',\n",
    "#                  'Regular Price',\n",
    "#                  'Selling Price','Shipping',\n",
    "#                  'Actual Shipping',\n",
    "#                  'Seller Discount','True datetime',\n",
    "#                  'Promo',\n",
    "#                  'Discount MC',\n",
    "#                  'Harga Cost',\n",
    "#                  'Total Harga Cost','nominal',\n",
    "#                  'btlcost',\n",
    "#                  'gs',\n",
    "#                  'commfee',\n",
    "#                  'fullfee','Shipping Province',\n",
    "#                  'Shipping City',\n",
    "#                  'Shipping Address1',\n",
    "#                  'Shipping Phone']].to_csv(r'Export Data/data_all_2020_' + data_now + '.csv', sep = ';', index = False)\n",
    "#             print(\"Export Data 2020 Finish\")\n",
    "            \n",
    "#             data_success = data_all[~data_all['Order Status'].isin(['\"Cancelled, Open\"', '\"Cancelled, Delivered\"', '\"Cancelled\"','\"Delivered, Cancelled\"','\"Cancelled, Delivered, Open\"','\"Cancelled, Delivered, Ready to Ship\"',\n",
    "#                                                     '\"Shipped, Cancelled\"','Order Batal', 'Pengiriman Gagal','canceled','\"Cancelled, Shipped\"','\"Cancelled, Ready to Ship\"', '\"Ready to Ship, Cancelled\"',\n",
    "#                                                     '\"Printed, Cancelled\"','\"Printed, Delivered, Cancelled\"','\"Shipped, Cancelled, Open\"','gosend_rejected','Canceled', 'CANCEL', 'CANCEL-REORDER'])]\n",
    "#             all_single = data_success[data_success['Brand'].isin(['NS', 'TS', 'L-Men', 'HiLo'])]\n",
    "\n",
    "#             print(\"Prepare E-mailing\")\n",
    "#             table_brand = all_single[['Brand', 'Sub Brand']].drop_duplicates().reset_index(drop = True)\n",
    "#             all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "#             from datetime import datetime, timedelta\n",
    "\n",
    "#             today = datetime.today()\n",
    "#             yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "#             today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "#             yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "\n",
    "#             yesterday_sales = all_single[all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "#             yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "#             yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "#             table_brand = table_brand.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "#             mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "#             mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "#             mtd_sales = all_single[all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "#             mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "#             mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "#             table_brand = table_brand.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "#             table_brand['Average This Month'] = table_brand['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "\n",
    "#             from calendar import monthrange\n",
    "#             number_of_days = monthrange(today.year, today.month)[1]\n",
    "\n",
    "#             table_brand['Projected'] = table_brand['Average This Month'] * number_of_days\n",
    "\n",
    "#             from dateutil import rrule\n",
    "#             from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#             start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "#             start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "#             end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "#             for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "#                 first_date = pd.to_datetime(dt)\n",
    "#                 print(\"First Date \" + str(first_date))\n",
    "#                 last_date = first_date + relativedelta(months=1)\n",
    "#                 print(\"Last Date \" + str(last_date))\n",
    "#                 temp_sales = all_single[all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "#                 temp_sales = temp_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "#                 colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "#                 temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "#                 table_brand = table_brand.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "#             table_brand = table_brand.reset_index(drop = True)\n",
    "#             table_brand = table_brand.drop('Average This Month', axis = 1)\n",
    "\n",
    "#             def highlight_max(x):\n",
    "#                 return ['font-weight: bold' if v == x.loc[x.index.max()] else ''\n",
    "#                             for v in x]\n",
    "\n",
    "#             table_brand = table_brand[table_brand['Local Sales'].notnull()]\n",
    "#             table_brand['Yesterday Sales'] = table_brand['Yesterday Sales'].astype(int)\n",
    "#             table_brand['Local Sales'] = table_brand['Local Sales'].astype(int)\n",
    "#             table_brand = table_brand.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "#             table_ecom = table_brand.copy()\n",
    "\n",
    "#             for i in table_ecom.columns[2:]:\n",
    "#                 table_ecom[i] = table_ecom[i].astype(int)\n",
    "\n",
    "#             table_ecom = table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "#             for i in table_ecom.columns[2:]:\n",
    "#                 table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "#                 table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "#             table_ecom = table_ecom.drop('Brand', axis = 1)\n",
    "#             table_ecom['Sub Brand'][table_ecom.index.max()] = '<b>Total E-Commerce Sales<b>'\n",
    "#             table_ecom = table_ecom.rename(columns = {'Sub Brand' : ''})\n",
    "\n",
    "#             table_ecom = table_ecom.iloc[[-1]].reset_index(drop = True)\n",
    "\n",
    "#             for i in table_brand.columns[2:]:\n",
    "#                 table_brand[i] = table_brand[i].astype(int)\n",
    "\n",
    "#             table_brand_hilo = table_brand[table_brand['Brand'] == 'HiLo'].reset_index(drop = True)\n",
    "#             table_brand_hilo = table_brand_hilo.append(table_brand_hilo.sum(numeric_only=True), ignore_index=True)\n",
    "#             table_brand_hilo['Sub Brand'][table_brand_hilo.index.max()] = '<b>TOTAL<b>'\n",
    "#             table_brand_hilo['Brand'][table_brand_hilo.index.max()] = ''\n",
    "\n",
    "\n",
    "#             table_brand_ns= table_brand[table_brand['Brand'] == 'NS'].reset_index(drop = True)\n",
    "#             table_brand_ns = table_brand_ns.append(table_brand_ns.sum(numeric_only=True), ignore_index=True)\n",
    "#             table_brand_ns['Sub Brand'][table_brand_ns.index.max()] = '<b>TOTAL<b>'\n",
    "#             table_brand_ns['Brand'][table_brand_ns.index.max()] = ''\n",
    "\n",
    "\n",
    "#             table_brand_lmen = table_brand[table_brand['Brand'] == 'L-Men'].reset_index(drop = True)\n",
    "#             table_brand_lmen = table_brand_lmen.append(table_brand_lmen.sum(numeric_only=True), ignore_index=True)\n",
    "#             table_brand_lmen['Sub Brand'][table_brand_lmen.index.max()] = '<b>TOTAL<b>'\n",
    "#             table_brand_lmen['Brand'][table_brand_lmen.index.max()] = ''\n",
    "\n",
    "\n",
    "#             table_brand_ts = table_brand[table_brand['Brand'] == 'TS'].reset_index(drop = True)\n",
    "#             table_brand_ts = table_brand_ts.append(table_brand_ts.sum(numeric_only=True), ignore_index=True)\n",
    "#             table_brand_ts['Sub Brand'][table_brand_ts.index.max()] = '<b>TOTAL<b>'\n",
    "#             table_brand_ts['Brand'][table_brand_ts.index.max()] = ''\n",
    "\n",
    "\n",
    "#             for i in table_brand_hilo.columns[2:]:\n",
    "#                 table_brand_hilo[i] = table_brand_hilo[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "#                 table_brand_hilo[i][table_brand_hilo.index.max()] = \"<b> {} </b>\".format(table_brand_hilo[i][table_brand_hilo.index.max()])\n",
    "\n",
    "#             for i in table_brand_lmen.columns[2:]:\n",
    "#                 table_brand_lmen[i] = table_brand_lmen[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "#                 table_brand_lmen[i][table_brand_lmen.index.max()] = \"<b> {} </b>\".format(table_brand_lmen[i][table_brand_lmen.index.max()])\n",
    "\n",
    "#             for i in table_brand_ns.columns[2:]:\n",
    "#                 table_brand_ns[i] = table_brand_ns[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "#                 table_brand_ns[i][table_brand_ns.index.max()] = \"<b> {} </b>\".format(table_brand_ns[i][table_brand_ns.index.max()])\n",
    "\n",
    "#             for i in table_brand_ts.columns[2:]:\n",
    "#                 table_brand_ts[i] = table_brand_ts[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "#                 table_brand_ts[i][table_brand_ts.index.max()] = \"<b> {} </b>\".format(table_brand_ts[i][table_brand_ts.index.max()])\n",
    "\n",
    "#             table_brand = table_brand_hilo.append(pd.Series(), ignore_index = True, sort = False)\n",
    "#             table_brand = table_brand.append(table_brand_lmen, ignore_index = True, sort = False)\n",
    "#             table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
    "#             table_brand = table_brand.append(table_brand_ns, ignore_index = True, sort = False)\n",
    "#             table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
    "#             table_brand = table_brand.append(table_brand_ts, ignore_index = True, sort = False)\n",
    "#             for i in table_brand.columns:\n",
    "#                 table_brand[i] = table_brand[i].fillna('')\n",
    "\n",
    "#             # table_brand_hilo.style.apply(highlight_max)\n",
    "#             # table_brand_ns.style.apply(highlight_max)\n",
    "#             # table_brand_lmen.style.apply(highlight_max)\n",
    "#             # table_brand_ts.style.apply(highlight_max)\n",
    "\n",
    "#             table_item = all_single[['Brand', 'Sub Brand', 'Exported Parent Item']].drop_duplicates().reset_index(drop = True)\n",
    "#             all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "#             from datetime import datetime, timedelta\n",
    "\n",
    "#             today = datetime.today()\n",
    "#             yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "#             today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "#             yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "\n",
    "#             yesterday_sales = all_single[all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "#             yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "#             yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "#             table_item = table_item.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "#             mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "#             mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "#             mtd_sales = all_single[all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "#             mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "#             mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "#             table_item = table_item.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "#             table_item['Average This Month'] = table_item['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "\n",
    "#             from calendar import monthrange\n",
    "#             number_of_days = monthrange(today.year, today.month)[1]\n",
    "\n",
    "#             table_item['Projected'] = table_item['Average This Month'] * number_of_days\n",
    "\n",
    "#             from dateutil import rrule\n",
    "#             from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#             start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "#             start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "#             end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "#             for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "#                 first_date = pd.to_datetime(dt)\n",
    "#                 last_date = first_date + relativedelta(months=1)\n",
    "#                 temp_sales = all_single[all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "#                 temp_sales = temp_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "#                 colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "#                 temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "#                 table_item = table_item.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "#             table_item = table_item[table_item['Local Sales'].notnull()]\n",
    "#             table_item['Yesterday Sales'] = pd.to_numeric(table_item['Yesterday Sales'], errors = 'coerce').fillna(0).astype(int)\n",
    "#             table_item['Local Sales'] = pd.to_numeric(table_item['Local Sales'], errors = 'coerce').fillna(0).astype(int)\n",
    "#             table_item = table_item.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "#             for i in table_item.columns[3:]:\n",
    "#                 table_item[i] = table_item[i].fillna(0).apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "\n",
    "#             table_item = table_item.reset_index(drop = True)\n",
    "#             table_item = table_item.drop('Average This Month', axis = 1)\n",
    "\n",
    "#             table_hilo = table_item[table_item['Brand'] == 'HiLo'].reset_index(drop = True)\n",
    "#             table_ns= table_item[table_item['Brand'] == 'NS'].reset_index(drop = True)\n",
    "#             table_lmen = table_item[table_item['Brand'] == 'L-Men'].reset_index(drop = True)\n",
    "#             table_ts = table_item[table_item['Brand'] == 'TS'].reset_index(drop = True)\n",
    "\n",
    "#             print(\"Prepare Emailing\")\n",
    "#             s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "#             # start TLS for security \n",
    "#             s.starttls() \n",
    "\n",
    "#             # Authentication \n",
    "#             s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "#             me = \"automationnfi@gmail.com\"\n",
    "#             to = \"andra.miftah@nutrifood.co.id\"\n",
    "\n",
    "#             # text = \"\"\"\n",
    "#             # Dear all,\n",
    "\n",
    "#             # Berikut data jualan E-Com tanggal {tanggal} per Brand :\n",
    "#             # {table_brand}\n",
    "\n",
    "#             # Dan Berikut data jualan E-Com tanggal {tanggal} per Item :\n",
    "\n",
    "#             # {table_hilo}\n",
    "\n",
    "#             # {table_ns}\n",
    "\n",
    "#             # {table_lmen}\n",
    "\n",
    "#             # {table_ts}\n",
    "\n",
    "#             # Best regards,\n",
    "\n",
    "#             # Andra Miftah Ar Rahman\n",
    "#             # E-Commerce Executive\n",
    "#             # \"\"\"\n",
    "\n",
    "#             print(\"Prepare Emailing\")\n",
    "#             s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "#             # start TLS for security \n",
    "#             s.starttls() \n",
    "\n",
    "#             # Authentication \n",
    "#             s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "#             me = \"automationnfi@gmail.com\"\n",
    "#             to = \"andra.miftah@nutrifood.co.id\"\n",
    "\n",
    "#             html = '''\n",
    "#             <html>\n",
    "#             <head>\n",
    "#             <style>\n",
    "\n",
    "#                 h2 {\n",
    "#                     text-align: center;\n",
    "#                     font-family: Helvetica, Arial, sans-serif;\n",
    "#                 }\n",
    "#                 table { \n",
    "#                     margin-left: auto;\n",
    "#                     margin-right: auto;\n",
    "#                 }\n",
    "#                 table, th, td {\n",
    "#                     border: 1px solid black;\n",
    "#                     border-collapse: collapse;\n",
    "#                 }\n",
    "#                 th, td {\n",
    "#                     padding: 5px;\n",
    "#                     text-align: center;\n",
    "#                     font-family: Helvetica, Arial, sans-serif;\n",
    "#                     font-size: 90%;\n",
    "#                 }\n",
    "#                 table tbody tr:hover {\n",
    "#                     background-color: #dddddd;\n",
    "#                 }\n",
    "#                 .wide {\n",
    "#                     width: 90%; \n",
    "#                 }\n",
    "\n",
    "#             </style>\n",
    "#             </head>\n",
    "#             <body>\n",
    "#                 '''\n",
    "#             html = html + \"\"\"\n",
    "#                 <p> Dear all, </p>\n",
    "#                 <p> Berikut data penjualan E-Com (After PPN) tanggal <b> {tanggal} </b> : </p>\n",
    "#             \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y')))\n",
    "\n",
    "#             html = html + table_ecom.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "#             html = html + \"\"\"\n",
    "#                 <p> Dan Berikut data penjualan E-Com (After PPN) tanggal <b> {tanggal} </b> per Brand :</p>\n",
    "#             \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y'))) \n",
    "\n",
    "#             html = html + table_brand.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "#             html = html + \"\"\"\n",
    "#                 <p> Dan berikut data penjualan E-Com (After PPN) per Item :</p>\n",
    "#                 <p> HiLo : </p>\"\"\"\n",
    "\n",
    "#             html = html + table_hilo.to_html(classes='wide', escape=False)\n",
    "\n",
    "#             html = html + \"<p> L-Men : </p>\"    \n",
    "\n",
    "#             html = html + table_lmen.to_html(classes='wide', escape=False)\n",
    "\n",
    "#             html = html + \"<p> NutriSari : </p>\"    \n",
    "\n",
    "#             html = html + table_ns.to_html(classes='wide', escape=False)\n",
    "\n",
    "#             html = html + \"<p> Tropicana Slim : </p>\"    \n",
    "\n",
    "#             html = html + table_ts.to_html(classes='wide', escape=False)\n",
    "\n",
    "#             html = html + \"\"\"\n",
    "#                 <p></p>\n",
    "#                 <p> Best regards, </p>\n",
    "#                 <p> Andra Miftah Ar Rahman </p>\n",
    "#                 <p> E-Commerce Executive </p>\n",
    "#             <body>\n",
    "#             </html>\n",
    "#             \"\"\"\n",
    "\n",
    "#             # text = text.format(tanggal = str(datetime.today().date()), table_brand = table_brand.to_html(), table_hilo = table_hilo.to_html(), table_ns = table_ns.to_html(), table_lmen = table_lmen.to_html(), table_ts = table_ts.to_html())\n",
    "\n",
    "#             msg = MIMEMultipart(\"alternative\", None, [MIMEText(html, 'html')])\n",
    "#             msg['Subject'] = \"Testing Report Ecom \" + str(datetime.today().date().strftime('%B %d, %Y'))\n",
    "\n",
    "#             # part1 = MIMEText(text)\n",
    "#             # msg.attach(part1)\n",
    "\n",
    "#             # sending the mail \n",
    "#             s.sendmail(\"automationnfi@gmail.com\", \"andra.miftah@nutrifood.co.id\", msg.as_string()) \n",
    "\n",
    "#             # terminating the session \n",
    "#             s.quit() \n",
    "#             print(\"E-mailing Finish\")\n",
    "#             # import pandas as pd\n",
    "#             # import numpy as np\n",
    "#             # import pypyodbc\n",
    "\n",
    "#             # conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#             #                 'Server=BAF-DB-01;'\n",
    "#             #                 'Database=e-commerce;'\n",
    "#             #                 )\n",
    "\n",
    "#             # cursor = conn.cursor()\n",
    "#             # ortrans = pd.read_sql(r'Select * from [Order Transaction]', conn)\n",
    "#             # orders = pd.read_sql(r'Select * from \"Order\"', conn)\n",
    "#             # or_ortrans = ortrans.merge(orders, how = 'left', left_on = 'order id', right_on = 'id')\n",
    "\n",
    "#             # print(\"Read Data All\")\n",
    "#             # # data_all = pd.read_csv(r'Clean Data/data_all_17 Juni.csv', sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "#             # data_all['Brand'] = data_all['Brand'].astype(str).str.replace('Tropicana Slim', 'TS')\n",
    "#             # data_all['Phone'] = data_all['Phone'].astype(str).str.replace('=\"', '', regex = False)\n",
    "#             # data_all['Phone'] = data_all['Phone'].astype(str).str.replace('\"', '', regex = False)\n",
    "\n",
    "\n",
    "#             # # product = pd.read_sql(r'Select * from Product', conn)\n",
    "#             # # or_ortrans = or_ortrans.merge(product, how = 'left', left_on = 'product id', right_on = 'id')\n",
    "#             # # or_april = or_ortrans[or_ortrans['year'] == 2020][or_ortrans[or_ortrans['year'] == 2020]['month'] == 'May'].copy()\n",
    "#             # # list_id = or_april['id_x'].to_list()\n",
    "#             # # for i in list_id:\n",
    "#             # #     print(i)\n",
    "#             # #     cursor.execute('Delete from [Order Transaction] Where id = ?', [i])\n",
    "#             # #     conn.commit()\n",
    "\n",
    "#             # temp = data_all[data_all['Month'] == 'February'][data_all[data_all['Month'] == 'February']['Year'] == 2020].copy()\n",
    "#             # or_april = or_ortrans[or_ortrans['order #'].astype(str).isin(temp['Order #'].astype(str))]\n",
    "#             # list_id = or_april['id_x'].to_list()\n",
    "\n",
    "#             # print('Delete from Order Transaction')\n",
    "#             # for i in list_id:\n",
    "#             # #     print(i)\n",
    "#             #     cursor.execute('Delete from [Order Transaction] Where id = ?', [i])\n",
    "#             #     conn.commit()\n",
    "\n",
    "#             # print('Delete from Order')\n",
    "#             # list_id = or_april['order id'].to_list()\n",
    "#             # for i in list_id:\n",
    "#             # #     print(i)\n",
    "#             #     cursor.execute('Delete from [Order] Where id = ?', [i])\n",
    "#             #     conn.commit()\n",
    "\n",
    "#             # print('Delete Finish')\n",
    "\n",
    "#             # list_id = or_april['id'].to_list()\n",
    "#             # conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#             #                 'Server=BAF-DB-01;'\n",
    "#             #                 'Database=e-commerce;'\n",
    "#             #                 )\n",
    "\n",
    "#             # cursor = conn.cursor()\n",
    "#             # print('Delete from Order Transaction')\n",
    "#             # for i in list_id:\n",
    "#             # #     print(i)\n",
    "#             #     cursor.execute('Delete from [Order Transaction] Where  [order id]= ?', [i])\n",
    "#             #     conn.commit()\n",
    "\n",
    "#             # print('Delete from Order')\n",
    "#             # for i in list_id:\n",
    "#             # #     print(i)\n",
    "#             #     cursor.execute('Delete from [Order] Where id = ?', [i])\n",
    "#             #     conn.commit()\n",
    "\n",
    "#             # print('Delete Finish')\n",
    "                \n",
    "#             import requests\n",
    "#             import time\n",
    "\n",
    "#             import pandas as pd\n",
    "#             import numpy as np\n",
    "#             import datetime\n",
    "#             import math\n",
    "\n",
    "#             import smtplib \n",
    "#             from email.mime.text import MIMEText\n",
    "#             from email.mime.application import MIMEApplication\n",
    "#             from email.mime.multipart import MIMEMultipart\n",
    "#             from smtplib import SMTP\n",
    "#             import smtplib\n",
    "#             import sys\n",
    "#             import os\n",
    "\n",
    "#             data_SKU = pd.read_excel(r'SKU_File/data_SKU.xlsx')\n",
    "\n",
    "#             s = requests.Session()\n",
    "#             s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "#             s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "#             r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "#             with open('SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "#                 output.write(r.content)\n",
    "\n",
    "#             if os.path.isfile('SKU_File/Master tatanama.xlsx') :    \n",
    "#                 SKU_append = pd.read_excel(r'SKU_File/Master tatanama.xlsx')\n",
    "#                 SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "#                 data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "#                 data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "#             to_excel = data_SKU.to_excel(r'SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "#             print(\"Start insert to Database\")\n",
    "#             import pypyodbc\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             orders = pd.read_sql('select * from \"Order\"', conn)\n",
    "#             ortrans = pd.read_sql(r'Select * From [Order Transaction]', conn)\n",
    "#             or_ortrans = ortrans.merge(orders, how = 'left', left_on = 'order id', right_on = 'id')\n",
    "#             or_ortrans['order #'] = orders['order #'].astype(str)\n",
    "#             data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "\n",
    "#             data_insert = data_all[~data_all['Order #'].astype(str).isin(or_ortrans['order #'].astype(str))]\n",
    "#             cust = pd.read_sql('Select * From Customers', conn)\n",
    "#             indeks = data_insert[~data_insert['Phone'].astype(str).isin(cust['phone'].astype(str))].drop_duplicates('Phone')['Phone'].index.to_list()\n",
    "#             lmen_phone = data_insert[data_insert['Phone'].isnull()].copy()\n",
    "#             indeks = indeks + lmen_phone[lmen_phone['Customer Name'].isin(cust['customer name'])].drop_duplicates('Customer Name').index.to_list()\n",
    "#             customers = data_insert[['Phone', 'Customer Email', 'Customer Name', 'Customer Group', 'Zip Code', 'Address', 'Shipping Address2', 'Country', 'Region', 'City', 'Kecamatan']].loc[indeks]\n",
    "\n",
    "#             customers['Zip Code'] = pd.to_numeric(customers['Zip Code'], errors = 'coerce').fillna(0)\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             print(\"Customer Database\")\n",
    "#             for index,row in customers.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute('Insert into Customers([phone], [customer email], [customer name], [customer group], [zip code], [address], [shipping address2], [country], [region], [city], [kecamatan]) Values (?, ?, ?, ?, ?,?, ?, ?, ?, ?, ?)', [str(row['Phone']), str(row['Customer Email']), str(row['Customer Name']), str(row['Customer Group']), int(row['Zip Code']), str(row['Address']), str(row['Shipping Address2']), str(row['Country']), str(row['Region']), str(row['City']), str(row['Kecamatan'])])\n",
    "#                 conn.commit()\n",
    "\n",
    "                \n",
    "#             product = pd.read_sql('Select * from Product', conn)\n",
    "#             all_product = data_insert[~data_insert['Real SKU'].astype(str).isin(product['real sku'].astype(str))].drop_duplicates('Real SKU')\n",
    "#             all_product = all_product[['Brand', 'Price List NFI', 'Sub Brand', 'Real SKU', 'Real Nama Produk', 'Parent Item', 'Parent SKU','Bundle Flag']]\n",
    "#             sql_arg = ''\n",
    "#             values_arg = ''\n",
    "#             for i in product.columns:\n",
    "#                 if i != 'id':\n",
    "#                     sql_arg = sql_arg + '[' + i + '], '\n",
    "#                     values_arg = values_arg + '?,'\n",
    "\n",
    "#             sql_arg = sql_arg[:-2]\n",
    "#             print(sql_arg)\n",
    "#             values_arg = values_arg[:-1]\n",
    "#             print(values_arg)\n",
    "\n",
    "#             sql_arg = 'Insert into Product(' + sql_arg + ') Values (' + values_arg + ')'\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             print(\"Product Database\")\n",
    "#             for index,row in all_product.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute('Insert into Product([brand], [price list nfi], [sub brand], [real sku], [real nama produk], [parent item], [parent sku], [bundle flag]) Values (?,?,?,?,?,?,?,?)',[str(row['Brand']), int(row['Price List NFI']), str(row['Sub Brand']), str(row['Real SKU']), str(row['Real Nama Produk']), str(row['Parent Item']), str(row['Parent SKU']), str(row['Bundle Flag'])])\n",
    "#                 conn.commit()\n",
    "                \n",
    "#             product = pd.read_sql('Select * from Product', conn)\n",
    "#             product['id'] = product['id'].astype(int)\n",
    "#             product['real sku'] = product['real sku'].astype(str)\n",
    "#             data_insert['Real SKU'] = data_insert['Real SKU'].astype(str)\n",
    "#             data_insert = data_insert.merge(product[['id', 'real sku']].drop_duplicates('real sku'), how = 'left', left_on = 'Real SKU', right_on = 'real sku')\n",
    "#             data_insert = data_insert.rename(columns = {'id' : 'Product Id'})\n",
    "#             data_insert = data_insert.drop('real sku', axis = 1)\n",
    "\n",
    "#             sql_bundle = pd.read_sql('Select * From [Bundle Details]', conn)\n",
    "#             bundle = product[product['bundle flag'] == 'Bundle'][~product[product['bundle flag'] == 'Bundle']['id'].isin(sql_bundle['product id'])]\n",
    "#             bundle_details = data_insert[data_insert['Real SKU'].isin(bundle['real sku'])].drop_duplicates('Real SKU')\n",
    "#             bundle_details = bundle_details[['Product Id'] + bundle_details.columns[bundle_details.columns.get_loc('Produk 1') : bundle_details.columns.get_loc('Harga Cost 7') + 1].to_list()]\n",
    "\n",
    "#             sql_arg = ''\n",
    "#             values_arg = ''\n",
    "#             for i in sql_bundle.columns:\n",
    "#                 if i != 'id':\n",
    "#                     sql_arg = sql_arg + '[' + i + '], '\n",
    "#                     values_arg = values_arg + '?,'\n",
    "\n",
    "#             sql_arg = sql_arg[:-2]\n",
    "#             print(sql_arg)\n",
    "#             values_arg = values_arg[:-1]\n",
    "#             print(values_arg)\n",
    "\n",
    "#             sql_arg = 'Insert into [Bundle Details](' + sql_arg + ') Values (' + values_arg + ')'\n",
    "\n",
    "#             for i in bundle_details.columns:\n",
    "#                 if 'PCS' in i or 'Subtotal' in i or 'Harga' in i or 'Price' in i:\n",
    "#                     bundle_details[i] = bundle_details[i].fillna(0)\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                     'Server=BAF-DB-01;'\n",
    "#                     'Database=e-commerce;'\n",
    "#                     )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             print(\"Bundle Database\")\n",
    "#             for index,row in bundle_details.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute(sql_arg, [int(row['Product Id']), str(row['Produk 1']), str(row['SKU Produk 1']), int(row['PCS Produk 1']), int(row['Price List NFI 1']), int(row['Subtotal Produk 1']), int(row['Harga Display 1']), int(row['Harga Cost 1']), str(row['Produk 2']), str(row['SKU Produk 2']), int(row['PCS Produk 2']), int(row['Price List NFI 2']), int(row['Subtotal Produk 2']), int(row['Harga Display 2']), int(row['Harga Cost 2']), str(row['Produk 3']), str(row['SKU Produk 3']), int(row['PCS Produk 3']), int(row['Price List NFI 3']), int(row['Subtotal Produk 3']), int(row['Harga Display 3']), int(row['Harga Cost 3']), str(row['Produk 4']), str(row['SKU Produk 4']), int(row['PCS Produk 4']), int(row['Price List NFI 4']), int(row['Subtotal Produk 4']), int(row['Harga Display 4']), int(row['Harga Cost 4']), str(row['Produk 5']), str(row['SKU Produk 5']), int(row['PCS Produk 5']), int(row['Price List NFI 5']), int(row['Subtotal Produk 5']), int(row['Harga Display 5']), int(row['Harga Cost 5']), str(row['Produk 6']), str(row['SKU Produk 6']), int(row['PCS Produk 6']), int(row['Price List NFI 6']), int(row['Subtotal Produk 6']), int(row['Harga Display 6']), int(row['Harga Cost 6']), str(row['Produk 7']), str(row['SKU Produk 7']), int(row['PCS Produk 7']), int(row['Price List NFI 7']), int(row['Subtotal Produk 7']), int(row['Harga Display 7']), int(row['Harga Cost 7'])])\n",
    "#                 conn.commit()\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "\n",
    "#             cust = pd.read_sql('Select * From Customers', conn)\n",
    "#             data_insert['Phone'] = data_insert['Phone'].astype(str)\n",
    "#             cust['phone'] = cust['phone'].astype(str)\n",
    "#             data_insert = data_insert.merge(cust[['id', 'phone']].drop_duplicates('phone'), how = 'left', left_on = 'Phone', right_on = 'phone')\n",
    "#             data_insert = data_insert.rename(columns = {'id' : 'Customer Id'})\n",
    "#             data_insert = data_insert.drop('phone', axis = 1)\n",
    "\n",
    "#             # lmen_phone = data_insert[data_insert['Phone'].isnull()].copy()\n",
    "#             # lmen_phone = lmen_phone.merge(cust[cust['phone'] == 'nan'][['id', 'customer name']].drop_duplicates('customer name'), how = 'left', left_on = 'Customer Name', right_on = 'customer name').set_index(lmen_phone.index)\n",
    "#             # data_insert['Customer Id'][lmen_phone.index] = lmen_phone['id'] \n",
    "\n",
    "#             orders = pd.read_sql('select * from \"Order\"', conn)\n",
    "#             orders['order #'] = orders['order #'].astype(str)\n",
    "#             data_insert['Order #'] = data_insert['Order #'].astype(str)\n",
    "\n",
    "#             all_order = data_insert[['Order #', 'Sales Order ID', 'AWB', 'Order date', 'Paid Date', 'Order Status', 'Channel', 'Customer Id', 'Coupon Code', 'Cart Name Rule', 'Ship Date', 'Payment Channel', 'Cancelled Date', 'Currency Code', 'Loc ID', 'Barcode ID', 'Warehouse Name', 'Store', 'Notes', 'Week', 'Date', 'Month', 'Quarter', 'Year', 'Shipping Name', 'Shipping Courier', 'True datetime']].drop_duplicates(['Order #'])\n",
    "\n",
    "#             temp = all_order.copy()\n",
    "#             temp.columns = [str(x).lower() for x in temp.columns]\n",
    "\n",
    "#             temp2 = orders.append(temp, ignore_index = True, sort = False)\n",
    "#             temp2['true datetime'] = pd.to_datetime(temp2['true datetime'])\n",
    "#             temp2 = temp2.sort_values('true datetime')\n",
    "#             temp2 = temp2.assign(count = temp2.groupby(['customer id']).cumcount())\n",
    "#             all_order = all_order.merge(temp2[['order #', 'count']].drop_duplicates('order #'), how = 'left', left_on = 'Order #', right_on = 'order #')\n",
    "#             all_order = all_order.rename(columns = {'count' : 'Pembelian Ke'})\n",
    "#             all_order = all_order.drop('order #', axis = 1)\n",
    "#             all_order['Pembelian Ke'] = all_order['Pembelian Ke']+1\n",
    "\n",
    "#             indeks = all_order[all_order['Pembelian Ke'] == 1].index.to_list()\n",
    "#             all_order['Repeat Return'] = np.nan\n",
    "#             all_order['Repeat Return'][indeks] = 'New'\n",
    "#             indeks = all_order[all_order['Pembelian Ke'] > 1].index.to_list()\n",
    "#             all_order['Repeat Return'][indeks] = 'Repeat'\n",
    "\n",
    "#             all_order['Order date'] = pd.to_datetime(all_order['Order date'], errors = 'coerce')\n",
    "#             all_order['Paid Date'] = pd.to_datetime(all_order['Paid Date'].fillna(pd.NaT), errors = 'coerce')\n",
    "#             all_order['Cancelled Date'] = pd.to_datetime(all_order['Cancelled Date'].fillna(pd.NaT), errors = 'coerce')\n",
    "#             all_order['Ship Date'] = pd.to_datetime(all_order['Ship Date'], errors = 'coerce')\n",
    "\n",
    "#             sql_arg = ''\n",
    "#             values_arg = ''\n",
    "#             for i in orders.columns:\n",
    "#                 if i != 'id':\n",
    "#                     sql_arg = sql_arg + '[' + i + '], '\n",
    "#                     values_arg = values_arg + '?,'\n",
    "\n",
    "#             sql_arg = sql_arg[:-2]\n",
    "#             print(sql_arg)\n",
    "#             values_arg = values_arg[:-1]\n",
    "#             print(values_arg)\n",
    "\n",
    "#             sql_arg = 'Insert into \"Order\"(' + sql_arg + ') Values (' + values_arg + ')'\n",
    "\n",
    "#             order_ada = all_order[all_order['Order #'].astype(str).isin(orders['order #'].astype(str))]\n",
    "#             order_gaada = all_order[~all_order['Order #'].astype(str).isin(orders['order #'].astype(str))]\n",
    "\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             print(\"Order ada Database\")\n",
    "#             for index,row in order_ada.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute('Update \"Order\" set [order status] = ? where CONVERT(VARCHAR, [order #]) = ?',[str(row['Order Status']), str(row['Order #'])])\n",
    "#                 conn.commit()\n",
    "                \n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             print(\"Order Baru Database\")\n",
    "#             for index,row in order_gaada.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor = conn.cursor()\n",
    "#                 o_date = row['Order date']\n",
    "#                 p_date = row['Paid Date']\n",
    "#                 c_date = row['Cancelled Date']\n",
    "#                 s_date = row['Ship Date']\n",
    "#                 if str(o_date) == 'NaT':\n",
    "#                     o_date = None\n",
    "#                 if str(p_date) == 'NaT':\n",
    "#                     p_date = None\n",
    "#                 if str(c_date) == 'NaT':\n",
    "#                     c_date = None\n",
    "#                 if str(s_date) == 'NaT':\n",
    "#                     s_date = None\n",
    "#                 cursor.execute(sql_arg,[str(row['Order #']),str(row['Sales Order ID']),str(row['AWB']),o_date,p_date,str(row['Order Status']),str(row['Channel']),str(row['Customer Id']),str(row['Coupon Code']),str(row['Cart Name Rule']),s_date,str(row['Payment Channel']),c_date,str(row['Currency Code']),str(row['Loc ID']),str(row['Barcode ID']),str(row['Warehouse Name']),str(row['Store']),str(row['Notes']),int(row['Week']),int(row['Date']),str(row['Month']),str(row['Quarter']),int(row['Year']),str(row['Shipping Name']),str(row['Shipping Courier']), pd.to_datetime(row['True datetime']), row['Pembelian Ke'], row['Repeat Return']])\n",
    "#                 conn.commit()\n",
    "                    \n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "\n",
    "#             temp = data_insert.copy()\n",
    "#             orders = pd.read_sql('select * from \"Order\"', conn)\n",
    "#             temp = temp.merge(orders[['id', 'order #']].drop_duplicates('order #'), how = 'left', left_on = 'Order #', right_on = 'order #')\n",
    "#             temp = temp.rename(columns = {'id' : 'Order Id'})\n",
    "#             temp = temp.drop('order #', axis = 1)\n",
    "\n",
    "#             ortrans = pd.read_sql('select * from [Order Transaction]', conn)\n",
    "\n",
    "#             order_trans = temp[['Order Id','Product Id', 'SKU', 'Product Name', 'Bundle Name', 'Qty. Invoiced', 'Total Net', 'Total',\n",
    "#                     'Qty. Ordered', 'Qty. Shipped', 'Qty. Refunded', 'Item Price',\n",
    "#                     'Subtotal', 'Discounts', 'Tax', 'Total incl. Tax', 'Invoiced',\n",
    "#                     'Tax Invoiced', 'Invoiced incl. Tax', 'Refunded', 'Refunded incl. Tax',\n",
    "#                     'Voucher Amount', 'Discount Poin Reward', 'Discount Product', 'Bundle',\n",
    "#                     'Regular Price', 'Selling Price', 'VAT', 'Shipping', 'Actual Shipping',\n",
    "#                     'Seller Discount', 'Seller Rebate', 'Gross Sales', 'Discount MC', 'Promo', 'Harga Cost', 'Total Harga Cost', 'btlcost', 'fullfee', 'commfee', 'nominal']]\n",
    "\n",
    "\n",
    "#             sql_arg = ''\n",
    "#             values_arg = ''\n",
    "#             for i in ortrans.columns:\n",
    "#                 if i != 'id' and i != 'marketing cost':\n",
    "#                     sql_arg = sql_arg + '[' + i + '], '\n",
    "#                     values_arg = values_arg + '?,'\n",
    "\n",
    "#             sql_arg = sql_arg[:-2]\n",
    "#             print(sql_arg)\n",
    "#             values_arg = values_arg[:-1]\n",
    "#             print(values_arg)\n",
    "\n",
    "#             sql_arg = 'Insert into [Order Transaction](' + sql_arg + ') Values (' + values_arg + ')'\n",
    "#             sql_arg\n",
    "\n",
    "#             for i in order_trans.columns:\n",
    "#                 if i in order_trans.columns[:5].to_list() + ['Bundle Name', 'Bundle', 'Promo']:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     order_trans[i] = order_trans[i].fillna(0)\n",
    "\n",
    "#             print(\"Order Transaction Database\")\n",
    "#             for index,row in order_trans.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute(sql_arg,[int(row['Order Id']), int(row['Product Id']), str(row['SKU']), str(row['Product Name']),str(row['Bundle Name']), int(row['Qty. Invoiced']), int(row['Total Net']), int(row['Total']), int(row['Qty. Ordered']), int(row['Qty. Shipped']), int(row['Qty. Refunded']), int(row['Item Price']), int(row['Subtotal']), int(row['Discounts']), int(row['Tax']), int(row['Total incl. Tax']), int(row['Invoiced']), int(row['Tax Invoiced']), int(row['Invoiced incl. Tax']), int(row['Refunded']), int(row['Refunded incl. Tax']), int(row['Voucher Amount']), int(row['Discount Poin Reward']), int(row['Discount Product']), str(row['Bundle']), int(row['Regular Price']), int(row['Selling Price']), int(row['VAT']), int(row['Shipping']), int(row['Actual Shipping']), int(row['Seller Discount']), int(row['Seller Rebate']), int(row['Gross Sales']), float(row['Discount MC']), str(row['Promo']), int(row['Harga Cost']), int(row['Total Harga Cost']), int(row['btlcost']), int(row['fullfee']), int(row['commfee']), int(row['nominal'])])\n",
    "#                 conn.commit()    \n",
    "\n",
    "#             print(\"Data Dashboard Customers\")\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "\n",
    "#             print(\"Pull data from database\")\n",
    "#             orders = pd.read_sql(r'Select * From \"Order\"', conn)\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             ortrans = pd.read_sql(r'Select * From [Order Transaction]', conn)\n",
    "\n",
    "#             or_ortrans = ortrans.merge(orders, how = 'left', left_on = 'order id', right_on = 'id')\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             cust = pd.read_sql('Select * from Customers', conn)\n",
    "#             customers = cust.copy()\n",
    "#             or_ortrans = or_ortrans.merge(cust, how = 'left', left_on = 'customer id', right_on = 'id')\n",
    "\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             products = pd.read_sql(r'Select * From Product', conn)\n",
    "#             or_ortrans = or_ortrans.merge(products, how = 'left', left_on = 'product id', right_on = 'id')\n",
    "\n",
    "#             from datetime import datetime\n",
    "#             from datetime import timedelta\n",
    "\n",
    "#             print(\"RFM\")\n",
    "#             cust = data_all[['Phone', 'Customer Email', 'Customer Name', 'Customer Group', 'Zip Code', 'Address', 'Shipping Address2', 'Country', 'Region', 'City', 'Kecamatan']].drop_duplicates('Phone')\n",
    "#             cust['Phone'] = cust['Phone'].astype(str)\n",
    "#             cust = cust.rename(columns = {'Phone' : 'phone'})\n",
    "#             cust = cust.merge(customers[['id', 'phone']], how = 'left', on = 'phone')\n",
    "\n",
    "#             max_purchase = or_ortrans.groupby('customer id')['true datetime'].max().reset_index()\n",
    "#             max_purchase.columns = ['id', 'MaxPurchaseDate']\n",
    "#             max_purchase['Recency'] = (datetime.today()- max_purchase['MaxPurchaseDate']).dt.days\n",
    "\n",
    "#             cust['recency'] = cust.merge(max_purchase[['id', 'Recency']], how = 'left', on = 'id')['Recency']\n",
    "\n",
    "#             data_freq = or_ortrans[or_ortrans['true datetime'] > datetime.today() - timedelta(days=365)]\n",
    "#             frequency = data_freq.groupby('customer id').agg({'order #' : pd.Series.nunique}).reset_index()\n",
    "\n",
    "#             frequency.columns = ['id', 'Frequency']\n",
    "#             cust['frequency']= cust.merge(frequency[['id', 'Frequency']], how = 'left', on = 'id')['Frequency']\n",
    "\n",
    "#             monetary = data_freq.groupby('customer id')['total net'].sum().reset_index()\n",
    "#             monetary.columns = ['id', 'Monetary']\n",
    "#             cust['monetary']= cust.merge(monetary[['id', 'Monetary']], how = 'left', on = 'id')['Monetary']\n",
    "\n",
    "#             cust['recency month'] = round(cust['recency']/30)\n",
    "\n",
    "#             indeks = cust[cust['recency'] >= 365].index.to_list()\n",
    "#             cust['status lf'] = np.nan\n",
    "#             cust['status bs'] = np.nan\n",
    "#             cust['status freq'] = np.nan\n",
    "\n",
    "#             cust['status lf'][indeks] = 'lost'\n",
    "#             cust['status freq'][indeks] = 'false'\n",
    "#             cust['status bs'][indeks] = 'dormain'\n",
    "\n",
    "#             indeks = cust[cust['recency month'] <= 3].index.to_list()\n",
    "#             cust['status lf'][indeks] = 'active'\n",
    "\n",
    "#             indeks = cust[cust['recency month'] > 3][cust[cust['recency month'] >= 3]['recency month']<=6].index.to_list()\n",
    "#             cust['status lf'][indeks] = 'at risk'\n",
    "\n",
    "#             indeks = cust[cust['recency month'] > 3][cust[cust['recency month'] >= 3]['recency month']<=6].index.to_list()\n",
    "#             cust['status lf'][indeks] = 'at risk'\n",
    "\n",
    "#             indeks = cust[cust['recency month'] > 6][cust[cust['recency month'] > 6]['recency month']<=12].index.to_list()\n",
    "#             cust['status lf'][indeks] = 'almost lost'\n",
    "\n",
    "#             indeks = cust[cust['frequency'] == 1].index.to_list()\n",
    "#             cust['status freq'][indeks] = 'one timer'\n",
    "\n",
    "#             indeks = cust[cust['frequency'] > 1][cust[cust['frequency'] > 1]['frequency']<=3].index.to_list()\n",
    "#             cust['status freq'][indeks] = 'repeat'\n",
    "\n",
    "#             indeks = cust[cust['frequency'] > 3].index.to_list()\n",
    "#             cust['status freq'][indeks] = 'loyal'\n",
    "\n",
    "#             indeks = cust[cust['monetary'] <= 500000].index.to_list()\n",
    "#             cust['status bs'][indeks] = 'silver'\n",
    "\n",
    "#             indeks = cust[cust['monetary'] > 500000][cust[cust['monetary'] > 500000]['monetary'] < 2000000].index.to_list()\n",
    "#             cust['status bs'][indeks] = 'gold'\n",
    "\n",
    "#             indeks = cust[cust['monetary'] > 2000000][cust[cust['monetary'] > 2000000]['monetary'] < 5000000].index.to_list()\n",
    "#             cust['status bs'][indeks] = 'platinum'\n",
    "\n",
    "#             indeks = cust[cust['monetary'] > 5000000].index.to_list()\n",
    "#             cust['status bs'][indeks] = 'diamond'\n",
    "\n",
    "#             indeks = cust[cust['recency'] >= 365].index.to_list()\n",
    "#             cust['status lf'][indeks] = 'lost'\n",
    "#             cust['status freq'][indeks] = 'false'\n",
    "#             cust['status bs'][indeks] = 'dormain'\n",
    "\n",
    "#             cust['frequency'] = cust['frequency'].fillna(0)\n",
    "#             cust['monetary'] = cust['monetary'].fillna(0)\n",
    "\n",
    "#             print(\"Affinity Scores\")\n",
    "#             brand_aff = or_ortrans[or_ortrans['bundle flag'] != 'Bundle']\n",
    "#             brand_aff = brand_aff[brand_aff['brand'].isin(['TS', 'NS', 'L-Men', 'HiLo', \"W'dank\", 'WRP'])]\n",
    "#             brand_aff = brand_aff.groupby(['customer id', 'brand'])['order #'].nunique().reset_index()\n",
    "#             brand_aff['percentage'] = brand_aff['order #']/brand_aff.groupby('customer id')['order #'].transform('sum')\n",
    "#             brand_aff = brand_aff.sort_values(['customer id', 'percentage'], ascending = [True, False])\n",
    "#             brand_aff = brand_aff.assign(count = brand_aff.groupby(['customer id']).cumcount())\n",
    "\n",
    "#             brand_aff1 = brand_aff[brand_aff['count'] == 0]\n",
    "#             brand_aff2 = brand_aff[brand_aff['count'] == 1]\n",
    "#             brand_aff = brand_aff1[['customer id', 'brand', 'percentage']].merge(brand_aff2[['customer id', 'brand', 'percentage']], how = 'left', on = 'customer id')\n",
    "#             brand_aff = brand_aff.rename(columns = {'customer id' : 'id','brand_x' : 'brand affinity', 'percentage_x' : 'brand affinity score','brand_y' : 'brand affinity 2', 'percentage_y' : 'brand affinity 2 score'})\n",
    "\n",
    "#             cust = cust.merge(brand_aff, how = 'left', on = 'id')\n",
    "\n",
    "#             store_aff = or_ortrans[or_ortrans['bundle flag'] != 'Bundle']\n",
    "#             store_aff = store_aff.groupby(['customer id', 'store'])['order #'].nunique().reset_index()\n",
    "#             store_aff['percentage'] = store_aff['order #']/store_aff.groupby('customer id')['order #'].transform('sum')\n",
    "#             store_aff = store_aff.sort_values(['customer id', 'percentage'], ascending = [True, False])\n",
    "#             store_aff = store_aff.assign(count = store_aff.groupby(['customer id']).cumcount())\n",
    "\n",
    "#             store_aff1 = store_aff[store_aff['count'] == 0]\n",
    "#             store_aff2 = store_aff[store_aff['count'] == 1]\n",
    "#             store_aff = store_aff1[['customer id', 'store', 'percentage']].merge(store_aff2[['customer id', 'store', 'percentage']], how = 'left', on = 'customer id')\n",
    "#             store_aff = store_aff.rename(columns = {'customer id' : 'id','store_x' : 'store affinity', 'percentage_x' : 'store affinity score','store_y' : 'store affinity 2', 'percentage_y' : 'store affinity 2 score'})\n",
    "\n",
    "#             cust = cust.merge(store_aff, how = 'left', on = 'id')\n",
    "\n",
    "#             first = or_ortrans.groupby('customer id')['true datetime'].min().reset_index().rename(columns = {'true datetime' : 'first date'})\n",
    "#             last = or_ortrans.groupby('customer id')['true datetime'].max().reset_index().rename(columns = {'true datetime' : 'last date'})\n",
    "\n",
    "#             cust = cust.merge(first, how = 'left', left_on = 'id', right_on = 'customer id').drop('customer id', axis = 1)\n",
    "#             cust = cust.merge(last, how = 'left', left_on = 'id', right_on = 'customer id').drop('customer id', axis = 1)\n",
    "\n",
    "#             store_num = or_ortrans.groupby('customer id')['store'].nunique().reset_index().rename(columns = {'store' : 'number of store'})\n",
    "#             cust = cust.merge(store_num, how = 'left', left_on = 'id', right_on = 'customer id').drop('customer id', axis = 1)\n",
    "#             cust['Jabodetabek'] = np.nan\n",
    "\n",
    "#             indeks = cust[cust['City'].astype(str).str.contains('Jakarta|Bekasi|Bogor|Depok|Tangerang', regex = True)].index.to_list()\n",
    "#             cust['Jabodetabek'][indeks] = 'Yes'\n",
    "\n",
    "#             for i in cust.columns:\n",
    "#                 if i in ['Zip Code', 'brand affinity score', 'brand affinity 2 score','store affinity score','store affinity 2 score']:\n",
    "#                     cust[i] = cust[i].fillna(0)\n",
    "\n",
    "#             cust = cust.rename(columns = {'store' : 'number of store'})\n",
    "#             cust['Zip Code'] = pd.to_numeric(cust['Zip Code'], errors = 'coerce').fillna(0)\n",
    "#             cust['number of store'] = pd.to_numeric(cust['number of store'], errors = 'coerce').fillna(0)\n",
    "\n",
    "#             command = 'Update Customers set '\n",
    "#             for i in cust.columns:\n",
    "#                 if i not in ['phone', 'id']:\n",
    "#                     command = command + '[' + i + '] = ?,'\n",
    "#             command = command[:-1]\n",
    "#             command = command + ' Where id = ?'\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "\n",
    "#             cust_not = cust[~cust['phone'].isin(data_insert['Phone'])]\n",
    "#             cust = cust[cust['phone'].isin(data_insert['Phone'])]\n",
    "\n",
    "#             for index, row in cust.iterrows():\n",
    "#                 if row['phone'] != 'nan' and str(row['id']) != 'nan':\n",
    "#                     f_date = row['first date']\n",
    "#                     l_date = row['last date']\n",
    "#                     if str(f_date) == 'NaT':\n",
    "#                         f_date = None\n",
    "#                     if str(l_date) == 'NaT':\n",
    "#                         l_date = None\n",
    "#                     # print(index)\n",
    "#                     cursor.execute(command, [str(row['Customer Email']), str(row['Customer Name']), str(row['Customer Group']), int(row['Zip Code']), str(row['Address']), str(row['Shipping Address2']), str(row['Country']), str(row['Region']), str(row['City']), str(row['Kecamatan']), str(row['recency']), str(row['frequency']), str(row['monetary']), str(row['recency month']), str(row['status lf']), str(row['status bs']), str(row['status freq']), str(row['brand affinity']), int(row['brand affinity score']), str(row['brand affinity 2']), int(row['brand affinity 2 score']), str(row['store affinity']), int(row['store affinity score']), str(row['store affinity 2']), int(row['store affinity 2 score']), pd.to_datetime(f_date), pd.to_datetime(l_date), int(row['number of store']), str(row['Jabodetabek']), row['id']])\n",
    "#                     conn.commit()\n",
    "\n",
    "#             for index, row in cust_not.iterrows():\n",
    "#                 if row['phone'] != 'nan' and str(row['id']) != 'nan':\n",
    "#                     f_date = row['first date']\n",
    "#                     l_date = row['last date']\n",
    "#                     if str(f_date) == 'NaT':\n",
    "#                         f_date = None\n",
    "#                     if str(l_date) == 'NaT':\n",
    "#                         l_date = None\n",
    "#                     # print(index)\n",
    "#                     cursor.execute('Update Customers set recency = ? where id = ?', [str(row['recency']), row['id']])\n",
    "#                     conn.commit()\n",
    "\n",
    "#             print(\"Move to Organic Data\")\n",
    "#             cumcount = or_ortrans.sort_values('true datetime', ascending = True).drop_duplicates('order #')\n",
    "#             cumcount = cumcount.assign(count = cumcount.groupby(['customer id']).cumcount())\n",
    "#             prev_store = cumcount[['customer id', 'count', 'true datetime', 'store']][cumcount[['customer id', 'count', 'true datetime', 'store']]['store'] == 'Nutrimart'][cumcount[['customer id', 'count', 'true datetime', 'store']][cumcount[['customer id', 'count', 'true datetime', 'store']]['store'] == 'Nutrimart']['count'] > 0].groupby('customer id')['count', 'true datetime'].first().reset_index()\n",
    "#             prev_store['count-1'] = prev_store['count']-1\n",
    "#             prev_store = prev_store.merge(cumcount[['customer id', 'count', 'store']], how = 'left', left_on = ['customer id', 'count-1'], right_on = ['customer id', 'count'])\n",
    "#             to_organic = prev_store[prev_store['store'] != 'Nutrimart']\n",
    "#             to_organic = to_organic[['customer id', 'store']].rename(columns = {'store' : 'previous store'})\n",
    "\n",
    "#             print(\"Insert into Customers Database\")\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             for index,row in to_organic.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute('Update Customers set [move to organic] = ?, [previous store] = ? where id = ?', ['Yes', row['previous store'], row['customer id']])\n",
    "#                 conn.commit()\n",
    "\n",
    "#             print('All Finish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### opsional , if errror\n",
    "### cek sku missing (belum ada di tatanama)\n",
    "### to do regist single / bundle /  alias\n",
    "\n",
    "data_forstok[data_forstok['SKU'].isnull()]['Item Name'].unique()\n",
    "data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))][['Store','Item Name','SKU']].drop_duplicates().values#.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Date</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blibli</th>\n",
       "      <td>9251535.0</td>\n",
       "      <td>10038801.0</td>\n",
       "      <td>9375380.0</td>\n",
       "      <td>12224700.0</td>\n",
       "      <td>14319660.0</td>\n",
       "      <td>3034000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bukalapak</th>\n",
       "      <td>2865500.0</td>\n",
       "      <td>6333250.0</td>\n",
       "      <td>1972100.0</td>\n",
       "      <td>1841750.0</td>\n",
       "      <td>2385600.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JD Indonesia</th>\n",
       "      <td>11077300.0</td>\n",
       "      <td>17425600.0</td>\n",
       "      <td>13029800.0</td>\n",
       "      <td>10392200.0</td>\n",
       "      <td>70233100.0</td>\n",
       "      <td>26928200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lazada</th>\n",
       "      <td>24519400.0</td>\n",
       "      <td>22759900.0</td>\n",
       "      <td>24166900.0</td>\n",
       "      <td>26559600.0</td>\n",
       "      <td>97214600.0</td>\n",
       "      <td>25934450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shopee</th>\n",
       "      <td>102580000.0</td>\n",
       "      <td>83962100.0</td>\n",
       "      <td>88176200.0</td>\n",
       "      <td>82036400.0</td>\n",
       "      <td>85906400.0</td>\n",
       "      <td>16406500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>5400000.0</td>\n",
       "      <td>5756000.0</td>\n",
       "      <td>5178500.0</td>\n",
       "      <td>16796900.0</td>\n",
       "      <td>13916500.0</td>\n",
       "      <td>1074200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokopedia</th>\n",
       "      <td>127577500.0</td>\n",
       "      <td>123427800.0</td>\n",
       "      <td>137305420.0</td>\n",
       "      <td>137477700.0</td>\n",
       "      <td>102589650.0</td>\n",
       "      <td>23722750.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Date                  1.0          2.0          3.0          4.0          5.0  \\\n",
       "Store                                                                           \n",
       "Blibli          9251535.0   10038801.0    9375380.0   12224700.0   14319660.0   \n",
       "Bukalapak       2865500.0    6333250.0    1972100.0    1841750.0    2385600.0   \n",
       "JD Indonesia   11077300.0   17425600.0   13029800.0   10392200.0   70233100.0   \n",
       "Lazada         24519400.0   22759900.0   24166900.0   26559600.0   97214600.0   \n",
       "Shopee        102580000.0   83962100.0   88176200.0   82036400.0   85906400.0   \n",
       "TikTok          5400000.0    5756000.0    5178500.0   16796900.0   13916500.0   \n",
       "Tokopedia     127577500.0  123427800.0  137305420.0  137477700.0  102589650.0   \n",
       "\n",
       "Date                 6.0  \n",
       "Store                     \n",
       "Blibli         3034000.0  \n",
       "Bukalapak            NaN  \n",
       "JD Indonesia  26928200.0  \n",
       "Lazada        25934450.0  \n",
       "Shopee        16406500.0  \n",
       "TikTok         1074200.0  \n",
       "Tokopedia     23722750.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### opsional cek tarikan forstok\n",
    "### kalau value < normal cek dashboard forstok\n",
    "\n",
    "from datetime import datetime\n",
    "forstok_all[(forstok_all['Month']==datetime.now().strftime('%B'))&\n",
    "            (forstok_all['Year']==datetime.now().year)&(forstok_all['Bundle Name'].isnull())\n",
    "           ].groupby(['Store','Date'])[['Total']].sum().reset_index().pivot(columns='Date',index='Store')['Total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Magento\n",
      "Opening Chrome\n",
      "Login Magento\n",
      "Go To Sales Form\n",
      "Input Date\n",
      "Download Magento\n",
      "bulk-order-download-template.csv\n",
      "Import Data ====== 1/10\n",
      "--- 10.924937725067139 seconds ---\n",
      "Formatting Data ====== 2/10\n",
      "--- 11.474328756332397 seconds ---\n",
      "Fulfilling SKU ====== 3/10\n",
      "--- 11.716238498687744 seconds ---\n",
      "Listing SKU Missing ====== 4/10\n",
      "--- 13.631691694259644 seconds ---\n",
      "Preparing Appending Magento to Masterdata\n",
      "Filling Brand ====== 5/10\n",
      "--- 13.765473127365112 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 13.827362060546875 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:650: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 15.57964038848877 seconds ---\n",
      "Pricing\n",
      "Filling Location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3170: DtypeWarning: Columns (23,35,57,60,74,80,81,87,88,94,95,101,102,110,122,123,134,135,136,138,153,156,157,158,167,168,172,173,174,175,176,194) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: net::ERR_CONNECTION_RESET\n  (Session info: chrome=103.0.5060.114)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\TIMOTI~1.GIO\\AppData\\Local\\Temp/ipykernel_5720/3462062925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://seller.blibli.com/sign-in\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: net::ERR_CONNECTION_RESET\n  (Session info: chrome=103.0.5060.114)\n"
     ]
    }
   ],
   "source": [
    "## Run-4\n",
    "## scrap magento detail order blibli update order status\n",
    "\n",
    "magento_scrape = False\n",
    "magentoUser_scrape = False\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Marketing Calendar Lazada\")\n",
    "# iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 26 July.xlsx')\n",
    "\n",
    "# MC_Lazada = pd.DataFrame()\n",
    "\n",
    "\n",
    "# for i in iterator.sheet_names:\n",
    "#     temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 26 July.xlsx', sheet_name = i)\n",
    "#     temp = temp.drop(0)\n",
    "#     MC_Lazada = MC_Lazada.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "# MC_Lazada['Start Date'] = pd.to_datetime(MC_Lazada['Start Date'])\n",
    "# MC_Lazada['End Date'] = pd.to_datetime(MC_Lazada['End Date'])\n",
    "\n",
    "# MC_Lazada = MC_Lazada.dropna(subset = ['Promo'])\n",
    "# MC_Lazada = MC_Lazada.reset_index(drop = True)\n",
    "\n",
    "# Lazada = forstok_all[forstok_all['Channel'] == 'Lazada']\n",
    "\n",
    "# for i in range(MC_Lazada.shape[0]):\n",
    "#     promo = MC_Lazada['Promo'][i]\n",
    "#     start = MC_Lazada['Start Date'][i]\n",
    "#     end = MC_Lazada['End Date'][i]+ timedelta(days=1)\n",
    "#     SKU = MC_Lazada['SKU'][i]\n",
    "#     diskon = MC_Lazada['Diskon'][i]\n",
    "#     if '(S)' in str(SKU):\n",
    "#         temp = Lazada[Lazada['SKU'].astype(str) == str(SKU)]\n",
    "#     else :\n",
    "#         temp = Lazada[Lazada['Real SKU'].astype(str) == str(SKU)]\n",
    "#     temp = temp[temp['True datetime'] >= start]\n",
    "#     temp = temp[temp['True datetime'] < end]\n",
    "#     temp['Promo'] = promo\n",
    "#     temp['Discount MC'] = diskon\n",
    "#     forstok_all['Promo'][temp.index] = promo\n",
    "#     forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "# print(\"Marketing Calendar Tokopedia\")\n",
    "# iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Tokopedia.xlsx')\n",
    "\n",
    "# MC_Tokopedia = pd.DataFrame()\n",
    "\n",
    "# for i in iterator.sheet_names[:2]:\n",
    "#     print(i)\n",
    "#     temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Tokopedia.xlsx', sheet_name = i)\n",
    "#     temp = temp.drop(0)\n",
    "#     MC_Tokopedia = MC_Tokopedia.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "# MC_Tokopedia['Start Date'] = pd.to_datetime(MC_Tokopedia['Start Date'])\n",
    "# MC_Tokopedia['End Date'] = pd.to_datetime(MC_Tokopedia['End Date'])\n",
    "\n",
    "# MC_Tokopedia['Promo'] = MC_Tokopedia['Promo'].fillna('Promo Februari 2020')\n",
    "# MC_Tokopedia = MC_Tokopedia.reset_index(drop = True)\n",
    "\n",
    "# Tokopedia = forstok_all[forstok_all['Channel'] == 'Tokopedia']\n",
    "\n",
    "# for i in range(MC_Tokopedia.shape[0]):\n",
    "#     promo = MC_Tokopedia['Promo'][i]\n",
    "#     start = MC_Tokopedia['Start Date'][i]\n",
    "#     end = MC_Tokopedia['End Date'][i]+ timedelta(days=1)\n",
    "#     SKU = MC_Tokopedia['SKU'][i]\n",
    "#     diskon = MC_Tokopedia['Diskon'][i]\n",
    "#     if '(S)' in str(SKU):\n",
    "#         temp = Tokopedia[Tokopedia['SKU'].astype(str) == str(SKU)]\n",
    "#     else :\n",
    "#         temp = Tokopedia[Tokopedia['Real SKU'].astype(str) == str(SKU)]\n",
    "#     temp = temp[temp['True datetime'] >= start]\n",
    "#     temp = temp[temp['True datetime'] < end]\n",
    "#     temp['Promo'] = promo\n",
    "#     temp['Discount MC'] = diskon\n",
    "#     forstok_all['Promo'][temp.index] = promo\n",
    "#     forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "# print(\"Marketing Calendar Bukalapak\")\n",
    "# iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Bukalapak.xlsx')\n",
    "\n",
    "# MC_Bukalapak = pd.DataFrame()\n",
    "\n",
    "# for i in iterator.sheet_names:\n",
    "#     temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Bukalapak.xlsx', sheet_name = i)\n",
    "#     temp = temp.drop(0)\n",
    "#     MC_Bukalapak = MC_Bukalapak.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "# MC_Bukalapak['Start Date'] = pd.to_datetime(MC_Bukalapak['Start Date'])\n",
    "# MC_Bukalapak['End Date'] = pd.to_datetime(MC_Bukalapak['End Date'])\n",
    "\n",
    "# MC_Bukalapak = MC_Bukalapak.dropna(subset = ['Promo'])\n",
    "# MC_Bukalapak = MC_Bukalapak.reset_index(drop = True)\n",
    "\n",
    "# Bukalapak = forstok_all[forstok_all['Channel'] == 'Bukalapak']\n",
    "\n",
    "# for i in range(MC_Bukalapak.shape[0]):\n",
    "#     promo = MC_Bukalapak['Promo'][i]\n",
    "#     start = MC_Bukalapak['Start Date'][i]\n",
    "#     end = MC_Bukalapak['End Date'][i]+ timedelta(days=1)\n",
    "#     SKU = MC_Bukalapak['SKU'][i]\n",
    "#     diskon = MC_Bukalapak['Diskon'][i]\n",
    "#     if '(S)' in str(SKU):\n",
    "#         temp = Bukalapak[Bukalapak['SKU'].astype(str) == str(SKU)]\n",
    "#     else :\n",
    "#         temp = Bukalapak[Bukalapak['Real SKU'].astype(str) == str(SKU)]\n",
    "#     temp = temp[temp['True datetime'] >= start]\n",
    "#     temp = temp[temp['True datetime'] < end]\n",
    "#     temp['Promo'] = promo\n",
    "#     temp['Discount MC'] = diskon\n",
    "#     forstok_all['Promo'][temp.index] = promo\n",
    "#     forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "# print(\"Marketing Calendar FBL\")\n",
    "# iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 26 July.xlsx')\n",
    "\n",
    "# MC_Lazada = pd.DataFrame()\n",
    "\n",
    "# for i in iterator.sheet_names:\n",
    "#     temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 26 July.xlsx', sheet_name = i)\n",
    "#     temp = temp.drop(0)\n",
    "#     MC_Lazada = MC_Lazada.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "# MC_Lazada['Start Date'] = pd.to_datetime(MC_Lazada['Start Date'])\n",
    "# MC_Lazada['End Date'] = pd.to_datetime(MC_Lazada['End Date'])\n",
    "\n",
    "# MC_Lazada = MC_Lazada.dropna(subset = ['Promo'])\n",
    "# MC_Lazada = MC_Lazada.reset_index(drop = True)\n",
    "\n",
    "# Lazada = forstok_all[forstok_all['Channel'] == 'FBL']\n",
    "\n",
    "# for i in range(MC_Lazada.shape[0]):\n",
    "#     promo = MC_Lazada['Promo'][i]\n",
    "#     start = MC_Lazada['Start Date'][i]\n",
    "#     end = MC_Lazada['End Date'][i]+ timedelta(days=1)\n",
    "#     SKU = MC_Lazada['SKU'][i]\n",
    "#     diskon = MC_Lazada['Diskon'][i]\n",
    "#     if '(S)' in str(SKU):\n",
    "#         temp = Lazada[Lazada['SKU'].astype(str) == str(SKU)]\n",
    "#     else :\n",
    "#         temp = Lazada[Lazada['Real SKU'].astype(str) == str(SKU)]\n",
    "#     temp = temp[temp['True datetime'] >= start]\n",
    "#     temp = temp[temp['True datetime'] < end]\n",
    "#     temp['Promo'] = promo\n",
    "#     temp['Discount MC'] = diskon\n",
    "#     forstok_all['Promo'][temp.index] = promo\n",
    "#     forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "# forstok_all_final = forstok_all.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "if not magento_scrape: \n",
    "    print(\"Starting Magento\")\n",
    "\n",
    "    # Download the file using Selenium here\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    print('Opening Chrome')\n",
    "    driver = webdriver.Chrome(\"D:\\Masterdata\\chromedriver.exe\",options=options)\n",
    "    driver.get(\"https://nutrimart.co.id/backoffice\")\n",
    "    print('Login Magento')\n",
    "    username = driver.find_element_by_id(\"username\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"andra\")\n",
    "    password = driver.find_element_by_id(\"login\")\n",
    "    password.send_keys(\"andra123\")\n",
    "\n",
    "    print('Go To Sales Form')\n",
    "    time.sleep(5)\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "    driver.find_element_by_xpath(\"//button[@class = 'action-login action-primary']\").click()\n",
    "    time.sleep(5)\n",
    "    WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"menu-magento-sales-sales\"]'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"menu-magento-sales-sales\"]/div/ul/li[2]/ul/li[2]/div/ul/li[1]/a').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"profile_id\"]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"profile_id\"]/optgroup[2]/option[2]').click()\n",
    "#     driver.find_element_by_xpath('//*[@id=\"profile_id\"]/optgroup[2]/option').click()\n",
    "    \n",
    "\n",
    "    start_date = datetime.today() - timedelta(days=14)\n",
    "    end_date = datetime.today()\n",
    "    date = start_date.strftime('%d %b %Y') + '-' + end_date.strftime('%d %b %Y')\n",
    "\n",
    "    print('Input Date')\n",
    "    date_from = driver.find_element_by_name('daterange_from')\n",
    "    date_from.clear()\n",
    "    date_from.send_keys(start_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "    date_to = driver.find_element_by_name('daterange_to')\n",
    "    date_to.clear()\n",
    "    date_to.send_keys(end_date.strftime('%m/%d/%Y'))\n",
    "    print('Download Magento')\n",
    "    driver.find_element_by_xpath('//*[@id=\"export_button\"]').click()\n",
    "\n",
    "    time.sleep(120)\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        magento_name = change.pop()\n",
    "    else:\n",
    "        print(\"More than one file or no file downloaded\")\n",
    "    \n",
    "    \n",
    "    # data_magento = pd.read_csv(r\"D:\\Masterdata\\Input Data\\export_sales_detailed_report_318150.csv\", sep = ',', index_col = False)\n",
    "    # data_magento = pd.read_csv(r\"D:\\Masterdata\\magentosementara6(2).csv\")\n",
    "    data_magento = pd.read_csv('Input Data/' + magento_name, sep = ',', index_col = False)\n",
    "    magento_scrape = True\n",
    "else :\n",
    "    data_magento = pd.read_csv('Input Data/' + magento_name, sep = ',', index_col = False)\n",
    "    \n",
    "if not magentoUser_scrape:\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"profile_id\"]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"profile_id\"]/optgroup[2]/option[1]').click()\n",
    "\n",
    "    start_date = datetime.today() - timedelta(days=17)\n",
    "    end_date = datetime.today()\n",
    "    date = start_date.strftime('%d %b %Y') + '-' + end_date.strftime('%d %b %Y')\n",
    "\n",
    "    date_from = driver.find_element_by_name('daterange_from')\n",
    "    date_from.clear()\n",
    "    date_from.send_keys(start_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "    date_to = driver.find_element_by_name('daterange_to')\n",
    "    date_to.clear()\n",
    "    date_to.send_keys(end_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"export_button\"]').click()\n",
    "    time.sleep(60)\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        magentouser_name = change.pop()\n",
    "        print(file_name)\n",
    "    else:\n",
    "        print(\"More than one file or no file downloaded\")\n",
    "        print(change)\n",
    "    driver.quit()\n",
    "    #\n",
    "    \n",
    "    # data_magentoUser2 = pd.read_csv(r\"D:\\Masterdata\\Input Data\\export_318137.csv\", sep = ',', index_col = False)\n",
    "    data_magentoUser2 = pd.read_csv('Input Data/' + magentouser_name, sep = ',', index_col = False)\n",
    "    for i in range(data_magentoUser2.shape[1]):\n",
    "        data_magentoUser2 = data_magentoUser2.rename(columns={ data_magentoUser2.columns[i] : data_magentoUser2.columns[i].replace(\"    \",\" \")})\n",
    "    magentoUser_scrape = True\n",
    "else :\n",
    "    data_magentoUser2 = pd.read_csv('Input Data/' + magentouser_name, sep = ',', index_col = False)\n",
    "    for i in range(data_magentoUser2.shape[1]):\n",
    "        data_magentoUser2 = data_magentoUser2.rename(columns={ data_magentoUser2.columns[i] : data_magentoUser2.columns[i].replace(\"    \",\" \")})\n",
    "\n",
    "data_SKU = pd.read_excel(r\"D:\\Masterdata\\SKU_File\\data_SKU.xlsx\")\n",
    "\n",
    "s = requests.Session()\n",
    "s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "with open(r\"D:\\Masterdata\\SKU_File\\Master tatanama.xlsx\", 'wb') as output:\n",
    "    output.write(r.content)\n",
    "\n",
    "if os.path.isfile(r\"D:\\Masterdata\\SKU_File\\Master tatanama.xlsx\") :    \n",
    "    SKU_append = pd.read_excel(r\"D:\\Masterdata\\SKU_File\\Master tatanama.xlsx\")\n",
    "    SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "to_excel = data_SKU.to_excel(r\"D:\\Masterdata\\SKU_File\\data_SKU.xlsx\", index = False)\n",
    "\n",
    "\n",
    "# Import library\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Import data\n",
    "start_time = time.time()\n",
    "print(\"Import Data ====== 1/10\")\n",
    "# data_magento = pd.read_excel(r'magento_new.xls')\n",
    "data_magentoUser = pd.read_excel('All Data\\data_magentoUser_2020.xlsx', index_col = False)\n",
    "data_magentoUser = data_magentoUser[~data_magentoUser['Sales Order Id'].astype(str).isin(data_magentoUser2['Sales Order Id'].astype(str))]\n",
    "data_magentoUser = data_magentoUser.append(data_magentoUser2, ignore_index = True, sort = False)\n",
    "magento_pure = data_magento.copy()\n",
    "\n",
    "list_skumiss = []\n",
    "\n",
    "# Formatting Magento\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Formatting Data ====== 2/10\")\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "if set(['Qty. Ordered\"', 'Qty. Shipped\"']).issubset(data_magento.columns):\n",
    "    data_magento = data_magento.rename(columns={'Qty. Ordered\"' : 'Qty. Ordered', \n",
    "                                            'Qty. Shipped\"' : 'Qty. Shipped'})\n",
    "if \"Manufacturer\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Manufacturer\"], axis=1)\n",
    "if \"Item Cost\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Item Cost\"], axis=1)\n",
    "if \"Package Name\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Package Name\"], axis=1)\n",
    "if \"Tax Refunded\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Tax Refunded\"], axis=1)\n",
    "if \"Catalog Name Rule\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Catalog Name Rule\"], axis=1)\n",
    "if \"Order date\" in data_magento.columns:\n",
    "    data_magento[\"Order date\"] = pd.to_datetime(data_magento[\"Order date\"], errors = 'coerce')\n",
    "if \"Customer Email\" in data_magento.columns:\n",
    "    data_magento[\"Customer Email\"] = data_magento[\"Customer Email\"].replace(regex = r'\"', value=\"\")\n",
    "if \"Qty. Ordered\" in data_magento.columns:\n",
    "    data_magento['Qty. Ordered'] = data_magento['Qty. Ordered'].fillna(0)\n",
    "    if \"Qty. Invoiced\" in data_magento.columns:\n",
    "        data_magento['Qty. Invoiced'] = data_magento['Qty. Invoiced'].fillna(0)\n",
    "    if \"Qty. Shipped\" in data_magento.columns:\n",
    "        data_magento['Qty. Shipped'] = data_magento['Qty. Shipped'].fillna(0)\n",
    "    if \"Qty. Refunded\" in data_magento.columns:\n",
    "        data_magento['Qty. Refunded'] = data_magento['Qty. Refunded'].fillna(0)\n",
    "    if \"Item Price\" in data_magento.columns:\n",
    "        data_magento['Item Price'] = data_magento['Item Price'].fillna(0)\n",
    "    if \"Subtotal\" in data_magento.columns:\n",
    "        data_magento['Subtotal'] = data_magento['Subtotal'].fillna(0)\n",
    "    if \"Discounts\" in data_magento.columns:\n",
    "        data_magento['Discounts'] = data_magento['Discounts'].fillna(0)\n",
    "    if \"Invoiced\" in data_magento.columns:\n",
    "        data_magento['Invoiced'] = data_magento['Invoiced'].fillna(0)\n",
    "    if \"Tax Invoiced\" in data_magento.columns:\n",
    "        data_magento['Tax Invoiced'] = data_magento['Tax Invoiced'].fillna(0)\n",
    "    if \"Voucher Amount\" in data_magento.columns:\n",
    "        data_magento[data_magento['Voucher Amount'].astype(str).str.isdigit()]['Voucher Amount'] = data_magento[data_magento['Voucher Amount'].fillna(0).astype(str).str.isdigit()]['Voucher Amount'].astype(float).div(10000)\n",
    "    if \"Discount Poin Reward\" in data_magento.columns:\n",
    "        data_magento['Discount Poin Reward'] = data_magento['Discount Poin Reward'].fillna(0)\n",
    "    if \"Discount Product\" in data_magento.columns:\n",
    "        data_magento['Discount Product'] = data_magento['Discount Product'].fillna(0)\n",
    "if \"Tax\" in data_magento.columns:\n",
    "    data_magento['Tax'] = data_magento['Tax'].astype(np.float32)\n",
    "if \"Total\" in data_magento.columns:\n",
    "    data_magento['Total'] = data_magento['Total'].astype(np.float32)\n",
    "if \"Total incl. Tax\" in data_magento.columns:\n",
    "    data_magento['Total incl. Tax'] = pd.to_numeric(data_magento['Total incl. Tax'], errors = 'coerce').astype(np.float32)\n",
    "if \"Invoiced incl. Tax\" in data_magento.columns:\n",
    "    data_magento['Invoiced incl. Tax'] = data_magento['Invoiced incl. Tax'].astype(np.float32)\n",
    "if \"Refunded\" in data_magento.columns:\n",
    "    data_magento['Refunded'] = data_magento['Refunded'].astype(np.float32)\n",
    "if \"Refunded incl. Tax\" in data_magento.columns:\n",
    "    data_magento['Refunded incl. Tax'] = data_magento['Refunded incl. Tax'].astype(np.float32)\n",
    "if \"Ship Date\" in data_magento.columns:\n",
    "    data_magento['Ship Date'] = data_magento['Ship Date'].astype(str).str.replace('false', '')\n",
    "\n",
    "# Customer Information Filling  \n",
    "for i in range(data_magentoUser.shape[1]):\n",
    "    data_magentoUser = data_magentoUser.rename(columns={ data_magentoUser.columns[i] : data_magentoUser.columns[i].replace(\"    \",\" \")})\n",
    "\n",
    "for i in range(data_magento.shape[0]):\n",
    "    if str(data_magento[\"Customer Group\"][i]) == 'nan':\n",
    "        if data_magento[\"Order #\"][i] in data_magentoUser[\"Sales Order Id\"].values:\n",
    "            data_magento[\"Customer Name\"][i] = data_magentoUser[\"Shipping Name\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Customer Group\"][i] = \"Not Logged In\"\n",
    "            data_magento[\"Country\"][i] = data_magentoUser[\"Shipping Country\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Region\"][i] = data_magentoUser[\"Shipping Province\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"City\"][i] = data_magentoUser[\"Shipping City\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Zip Code\"][i] = data_magentoUser[\"Shipping Zip\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Address\"][i] = data_magentoUser[\"Shipping Address1\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Phone\"][i] = data_magentoUser[\"Shipping Phone\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "\n",
    "indeks = data_magento[data_magento['Phone'].isnull()].index.to_list()\n",
    "data_magento['Phone Condition'] = np.nan\n",
    "data_magento['Phone Condition'][indeks] = 'X'\n",
    "\n",
    "data_magentoUser['Sales Order Id'] = data_magentoUser['Sales Order Id'].astype(str)\n",
    "data_magento['Order #'] = data_magento['Order #'].astype(str)\n",
    "\n",
    "temp2 = data_magento.merge(data_magentoUser[['Sales Order Id', 'AWB', 'Shipping Cost', 'Shipping Address1', 'Shipping City', 'Shipping Province', 'Shipping Phone', 'Shipping Courier']].drop_duplicates('Sales Order Id'), how = 'left', left_on = 'Order #', right_on = 'Sales Order Id').set_index(data_magento.index)\n",
    "\n",
    "data_magento['Shipping'] = np.nan\n",
    "data_magento['AWB'] = np.nan\n",
    "data_magento['Shipping Courier'] = np.nan\n",
    "\n",
    "data_magento['Shipping'][temp2.index] = temp2['Shipping Cost']\n",
    "data_magento['AWB'][temp2.index] = temp2['AWB']\n",
    "data_magento['Shipping Courier'][temp2.index] = temp2['Shipping Courier']\n",
    "\n",
    "\n",
    "# Phone formatting\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].fillna(0.0)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\" \",\"\")\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"-\",\"\")\n",
    "temp = data_magento[\"Phone\"].astype(str).str.split(\",\", expand = True)\n",
    "data_magento[\"Phone\"] = temp[0]\n",
    "temp = data_magento[\"Phone\"].astype(str).str.split(\"/\", expand = True)\n",
    "data_magento[\"Phone\"] = temp[0]\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+620\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^620\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^8\", \"08\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^21\", \"021\", regex = True)\n",
    "\n",
    "\n",
    "data_magento['Shipping Address1'] = np.nan\n",
    "data_magento['Shipping City'] = np.nan\n",
    "data_magento['Shipping Province'] = np.nan\n",
    "data_magento['Shipping Phone'] = np.nan\n",
    "\n",
    "# data_magento['Shipping Address1'][temp2.index] = temp2['Shipping Address1']\n",
    "# data_magento['Shipping City'][temp2.index] = temp2['Shipping City']\n",
    "# data_magento['Shipping Province'][temp2.index] = temp2['Shipping Province']\n",
    "# data_magento['Shipping Phone'][temp2.index] = temp2['Shipping Phone']\n",
    "\n",
    "\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].fillna(0.0)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\" \",\"\")\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"-\",\"\")\n",
    "temp = data_magento[\"Shipping Phone\"].astype(str).str.split(\",\", expand = True)\n",
    "data_magento[\"Shipping Phone\"] = temp[0]\n",
    "temp = data_magento[\"Shipping Phone\"].astype(str).str.split(\"/\", expand = True)\n",
    "data_magento[\"Shipping Phone\"] = temp[0]\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+620\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^620\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^8\", \"08\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^21\", \"021\", regex = True)\n",
    "\n",
    "# Master tatanama\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Fulfilling SKU ====== 3/10\")\n",
    "\n",
    "data_magento['SKU'] = data_magento['SKU'].astype(str).str.split('-').str[0]\n",
    "indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "\n",
    "skuhd = data_magento[data_magento['SKU'].astype(str).str.contains('hd', case = False)]\n",
    "skushopee = data_magento[data_magento['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).isin(skuhd['SKU'].astype(str))]\n",
    "\n",
    "skuhd = skuhd.reset_index(drop = True)\n",
    "skushopee = skushopee.reset_index(drop = True)\n",
    "data_magento = data_magento.reset_index(drop = True)\n",
    "\n",
    "indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "for i in indeks:\n",
    "    if data_magento['Product Name'][i].lower() in data_SKU['Nama Produk'].str.lower().values:\n",
    "        data_magento['SKU'][i] = data_SKU['SKU'].loc[data_SKU['Nama Produk'].str.lower() == str(data_magento['Product Name'][i]).lower()].values[0]\n",
    "\n",
    "list_alias = []\n",
    "list_alias_name = []\n",
    "for colname in data_SKU.columns:\n",
    "    if 'Alias SKU' in colname:\n",
    "        list_alias.append(colname)\n",
    "    if 'Alias Nama' in colname:\n",
    "        list_alias_name.append(colname)\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias:\n",
    "        if str(data_magento['SKU'][i]) in data_SKU[j].astype(str).values:\n",
    "            idx = data_SKU[str(data_magento['SKU'][i]) == data_SKU[j].astype(str)].index.to_list()\n",
    "            for k in idx:\n",
    "                if str(data_magento['SKU'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "                    data_magento['SKU'][i] = data_SKU['SKU'][k]\n",
    "\n",
    "indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias_name:\n",
    "        if str(data_magento['Product Name'][i]).lower() in data_SKU[j].astype(str).str.lower().values:\n",
    "            data_magento['SKU'][i] = data_SKU['SKU'].loc[str(data_magento['Product Name'][i]).lower() == data_SKU[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'WRP Everyday Low Fat Milk Coklat 4 Pillow Bag']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Kitchen Vietnamese Coffee Latte (12 Sch)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Raspberry Pumpkin (24 pcs)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Raspberry Pumpkin (1 pc)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Kitchen Thai Tea Latte (12 Sch)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Greek Yogurt Blueberry (24 Pcs)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Greek Yogurt Blueberry']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Lychee Spinach (24 Pcs)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Lychee Spinach (1 pc)']\n",
    "\n",
    "\n",
    "\n",
    "data_magento['SKU'] = data_magento['SKU'].astype(str).str.replace('7300281P24', '7300281')\n",
    "\n",
    "data_magento = data_magento[~data_magento['Product Name'].astype(str).str.contains('JANGAN DIORDER INI TESTING')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('7300851')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0301002006')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0302004002')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0301002005P24')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0301002005')]\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Listing SKU Missing ====== 4/10\")   \n",
    "idx = data_magento[['SKU']][data_magento['SKU'].isnull()].drop_duplicates().index.to_list()\n",
    "idx = idx + data_magento[['SKU', 'Product Name']][~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx = list(dict.fromkeys(idx))\n",
    "idx_s = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx_s = list(dict.fromkeys(idx_s))\n",
    "idx_hd = skuhd[~skuhd['SKU'].astype(str).str.replace('hd','',case = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx_hd = list(dict.fromkeys(idx_hd))\n",
    "\n",
    "to_excel = data_magento.to_excel(r'magento_new.xls', index = False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "if len(idx) != 0 or len(idx_s) != 0 or len(idx_hd) != 0:\n",
    "    print('SKU is missing')\n",
    "    alert = data_magento.iloc[idx, ][['SKU', 'Product Name']].drop_duplicates()\n",
    "    alert = alert.append(skushopee.iloc[idx_s][['SKU', 'Product Name']].drop_duplicates(), ignore_index = True, sort = False)\n",
    "    alert['SKU Valid'] = np.nan\n",
    "    to_excel = alert.to_excel('ALERT_MAGENTO_SKU_MISSING.xlsx')\n",
    "    print(\"Some SKU Missing Please Complete It ====== 5/10\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "    # start TLS for security \n",
    "    s.starttls() \n",
    "\n",
    "    # Authentication \n",
    "    s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = \"ALERT SKU MAGENTO MISSING\"\n",
    "\n",
    "\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "    <head></head>\n",
    "    <body>\n",
    "        {0}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\".format(alert.to_html())\n",
    "\n",
    "    part1 = MIMEText(html, 'html')\n",
    "    msg.attach(part1)\n",
    "\n",
    "    # sending the mail \n",
    "    s.sendmail(\"automationnfi@gmail.com\", \"andra.miftah@nutrifood.co.id\", msg.as_string()) \n",
    "\n",
    "    # terminating the session \n",
    "    s.quit()\n",
    "else :\n",
    "    print(\"Preparing Appending Magento to Masterdata\")\n",
    "    print(\"Filling Brand ====== 5/10\")  \n",
    "    data_magento = data_magento.append(skushopee, ignore_index = True, sort = False)\n",
    "    data_magento = data_magento.reset_index(drop = True)\n",
    "\n",
    "    data_magento['SKU'] = data_magento['SKU'].astype(str)\n",
    "    data_magento['Product Name'] = data_magento['Product Name'].astype(str)\n",
    "    data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "    data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "    data_magento = data_magento.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "    temp = data_magento[data_magento['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_magento[data_magento['Real SKU'].isnull()].index.to_list()\n",
    "    data_magento['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_magento['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    temp = data_magento[data_magento['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_magento[data_magento['Real SKU'].isnull()].index.to_list()\n",
    "    data_magento['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_magento['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    data_magento['Real SKU'] = data_magento['Real SKU'].astype(str)\n",
    "    data_magento = data_magento.merge(data_SKU[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    data_magento = data_magento.drop(['SKU_y'], axis = 1)\n",
    "    data_magento = data_magento.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Unbundling ====== 6/10\")\n",
    "    list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "    data_magento = data_magento.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    data_magento = data_magento.drop(['SKU_y'], axis = 1)\n",
    "    data_magento = data_magento.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    indeks = data_magento[data_magento['Brand'] == 'Bundle'].index.to_list()\n",
    "    data_magento['Bundle Flag'] = np.nan\n",
    "    data_magento['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Filling Date ====== 7/10\")\n",
    "    data_magento['Date'] = np.nan\n",
    "    data_magento['Month'] = np.nan\n",
    "    data_magento['Year'] = np.nan\n",
    "\n",
    "    for i in range(data_magento.shape[0]):\n",
    "        if int(data_magento['Order date'][i].strftime('%d')) <= 12:\n",
    "            data_magento['Date'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "            data_magento['Month'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "            data_magento['Year'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "        else :\n",
    "            data_magento['Date'][i] = pd.to_datetime(data_magento['Order date'][i]).day\n",
    "            data_magento['Month'][i] = pd.to_datetime(data_magento['Order date'][i]).month_name()\n",
    "            data_magento['Year'][i] = pd.to_datetime(data_magento['Order date'][i]).year\n",
    "\n",
    "\n",
    "    quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "            ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "    data_magento = data_magento.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "    data_magento = data_magento.drop(['Bulan'], axis = 1)\n",
    "    data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "            {'Bulan' : 'January' , 'Number': 1},\n",
    "            {'Bulan' : 'February' , 'Number': 2},\n",
    "            {'Bulan' : 'March' , 'Number': 3},\n",
    "            {'Bulan' : 'April' , 'Number': 4},\n",
    "            {'Bulan' : 'May' , 'Number': 5},\n",
    "            {'Bulan' : 'June', 'Number': 6},\n",
    "            {'Bulan' : 'July' , 'Number': 7},\n",
    "            {'Bulan' : 'August', 'Number' : 8},\n",
    "            {'Bulan' : 'September', 'Number' : 9},\n",
    "            {'Bulan' : 'October' , 'Number': 10},\n",
    "            {'Bulan' : 'November' , 'Number': 11}])\n",
    "    temp = data_magento.copy()\n",
    "    temp['Day'] = temp['Date']\n",
    "    temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "    temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "    data_magento['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "    data_magento['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "    data_magento['Channel'] = 'Nutrimart'\n",
    "    data_magento['Store'] = 'Nutrimart'\n",
    "    data_magento['Selling Price'] = data_magento['Item Price']\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Pricing\")\n",
    "    data_magento = data_magento.merge(data_SKU[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(data_magento.index)\n",
    "    data_magento = data_magento.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "    data_magento['Price List NFI'] = pd.to_numeric(data_magento['Price List NFI']).astype(int)\n",
    "    data_magento['Harga Cost'] = pd.to_numeric(data_magento['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "    data_magento['Qty. Invoiced'] = pd.to_numeric(data_magento['Qty. Invoiced']).astype(int)\n",
    "    data_magento['Total Net'] = data_magento['Price List NFI'] * data_magento['Qty. Invoiced']\n",
    "    data_magento['Total Harga Cost'] = data_magento['Harga Cost'] * data_magento['Qty. Invoiced']\n",
    "\n",
    "    data_magento = data_magento.drop('SKU_y', axis = 1)\n",
    "    data_magento = data_magento.reset_index(drop = True)\n",
    "    data_magento['Order #'] = data_magento['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "    list_bundle = data_magento[data_magento['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "    list_nobundle = data_magento[data_magento['Bundle Name'].notnull()]\n",
    "    list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "    list_nobundle\n",
    "\n",
    "    data_magento['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "    data_magento['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "    temp = data_magento[data_magento['Bundle Name'].notnull()]\n",
    "    temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "    temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "    temp['Selling Price'] = temp['Subtotal'] / temp['Qty. Invoiced']\n",
    "\n",
    "    data_magento['Total'][temp.index] = temp['Total'].fillna(0).astype(int)\n",
    "    data_magento['Subtotal'][temp.index] = temp['Subtotal'].fillna(0).astype(int)\n",
    "    data_magento['Selling Price'][temp.index] = temp['Selling Price'].fillna(0).astype(int)\n",
    "\n",
    "    print(\"Filling Location\")\n",
    "    data_magento['Kecamatan'] = np.nan\n",
    "    data_magento['Kelurahan'] = np.nan\n",
    "#             data_magento = data_magento.rename(columns = {'Shipping City' : 'City', 'Shipping Province' : 'Region'})\n",
    "\n",
    "    indeks = data_magento[data_magento['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "        data_magento['City'][indeks] = data_magento['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kelurahan'][indeks] = data_magento['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        data_magento['City'][indeks] = data_magento['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kelurahan'][indeks] = data_magento['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['City'] = temp['City'].astype(str).str.lower()\n",
    "    city['All City'] = city['All City'].astype(str).str.lower()\n",
    "    temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "    indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "    data_magento['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "    province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "    province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "    temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "    indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "    data_magento['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp = temp[temp['Region'].isnull()]\n",
    "    temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "    data_magento['Region'][temp.index] = temp['Region']\n",
    "\n",
    "    district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "    district['All District'] = district['All District'].astype(str).str.lower()\n",
    "    temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "    indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "    data_magento['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "    indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "    data_magento['City'][indeks] = np.nan\n",
    "\n",
    "    indeks = data_magento[data_magento['Shipping City'].astype(str).str.contains('/')]['Shipping City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Shipping City'][indeks] = data_magento['Shipping City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['Shipping City'].astype(str).str.contains(',')]['Shipping City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Shipping City'][indeks] = data_magento['Shipping City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Shipping City'] = temp['Shipping City'].astype(str).str.lower()\n",
    "    city['All City'] = city['All City'].astype(str).str.lower()\n",
    "    temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'Shipping City', right_on = 'All City').set_index(temp.index)\n",
    "    indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "    data_magento['Shipping City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "    province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Shipping Province'] = temp['Shipping Province'].astype(str).str.lower()\n",
    "    province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "    temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Shipping Province', right_on = 'All Province').set_index(temp.index)\n",
    "    indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "    data_magento['Shipping Province'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp = temp[temp['Shipping Province'].isnull()]\n",
    "    temp['Shipping Province'] = temp.merge(master_map, how = 'left', left_on = 'Shipping City', right_on = 'City').set_index(temp.index)['Shipping Province']\n",
    "    data_magento['Shipping Province'][temp.index] = temp['Shipping Province']\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp2 = temp[['Shipping Province', 'Shipping City']].merge(master_map, how = 'left', left_on = 'Shipping City', right_on = 'City')\n",
    "    indeks = temp2[temp2['Shipping Province'] != temp2['Province']][temp2[temp2['Shipping Province'] != temp2['Province']]['Shipping City'].notnull()].index.to_list()\n",
    "    data_magento['Shipping City'][indeks] = np.nan\n",
    "    data_magento['Warehouse Name'] = 'Primary Warehouse'\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    list_of_files = glob.glob('Clean Data/*.csv')\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "    data_all = pd.read_csv(latest_file, sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "    data_all = data_all[data_all['Store Type'] != 'Retail Online']\n",
    "\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('=\"', '', regex = False)\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('\"', '', regex = False)\n",
    "\n",
    "    lmen_store = forstok_all[forstok_all['Channel'] == 'L-Men Store Blibli']\n",
    "    forstok_all = forstok_all[forstok_all['Channel'] != 'L-Men Store Blibli']\n",
    "\n",
    "    lmen_store = lmen_store[~lmen_store['Order #'].astype(str).isin(data_all['Order #'].astype(str))]\n",
    "    lmen_store['Sales Order ID'] = lmen_store['Sales Order ID'].fillna(lmen_store['No. Order Item L-Men Blibli'])\n",
    "    ornum = lmen_store[['Order #', 'Sales Order ID']].drop_duplicates('Order #')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": str(os.getcwd())  + '/Input Data',\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(\"https://seller.blibli.com/sign-in\")\n",
    "\n",
    "\n",
    "    username = driver.find_element_by_id(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"novita.vidianti@nutrifood.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_id(\"password\")\n",
    "    password.send_keys(\"Mengejarcu4n\")\n",
    "\n",
    "    driver.find_element_by_id(\"sign-in\").click()\n",
    "    time.sleep(5)\n",
    "    #             WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'close-announcement-button'))).click()\n",
    "    #             WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'remind-me-later-button'))).click()\n",
    "    #     WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'nav-wrapper-ORDER'))).click()\n",
    "    #     driver.find_element_by_id(\"sub-nav-item-0\").click()\n",
    "    driver.get(\"https://seller.blibli.com/MTA/order/summary\")\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn-primary-mta'))).click()\n",
    "    driver.find_element_by_id(\"semuaFilter\").click()\n",
    "\n",
    "    ornum['Phone'] = np.nan\n",
    "    ornum['Email'] = np.nan\n",
    "    ornum['Address'] = np.nan\n",
    "\n",
    "    for i in ornum.index:\n",
    "        orderNo = ornum['Order #'][i]\n",
    "        orderItemNo = int(pd.to_numeric(ornum['Sales Order ID'][i]))\n",
    "        link = \"https://merchant.blibli.com/MTA/neo/order/order-detail/\" + \"?orderNo=\" + str(orderNo) + \"&orderItemNo=\" + str(orderItemNo)\n",
    "        driver.get(link)\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"customer-phone\"]/div/span')))\n",
    "        hp = driver.find_elements_by_xpath('//*[@id=\"customer-phone\"]/div/span')[0].text\n",
    "        if len(driver.find_elements_by_xpath('//*[@id=\"customer-email\"]/span')) != 0:\n",
    "            email = driver.find_elements_by_xpath('//*[@id=\"customer-email\"]/span')[0].text\n",
    "            ornum['Email'][i] = email\n",
    "        address = driver.find_elements_by_xpath('//*[@id=\"alamat-pengiriman\"]//div//p')[0].text\n",
    "        ornum['Phone'][i] = hp\n",
    "        ornum['Address'][i] = address\n",
    "\n",
    "    driver.quit()\n",
    "    if len(ornum) != 0:\n",
    "        tes = ornum.copy()\n",
    "        tes['Real Address'] = tes['Address'].str.split('\\n', expand = True)[1].str.strip()\n",
    "        tes['Kelurahan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[0].str.strip()\n",
    "        tes['Kecamatan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[1].str.strip()\n",
    "        tes['City'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[0].str.strip()\n",
    "        tes['Region'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[1].str.strip()\n",
    "        tes['Zip Code'] = tes['Address'].str.split('\\n', expand = True)[5].str.strip()\n",
    "\n",
    "        lmen_store['Order #'] = lmen_store['Order #'].astype(str)\n",
    "        tes['Order #'] = tes['Order #'].astype(str)\n",
    "        lmen_store = lmen_store.merge(tes[['Order #', 'Phone', 'Email', 'Real Address', 'Kelurahan', 'Kecamatan', 'City', 'Region', 'Zip Code']].drop_duplicates('Order #'), how = 'left', on = 'Order #')\n",
    "\n",
    "        indeks = lmen_store[lmen_store['Phone_y'].notnull()].index.to_list()\n",
    "        lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "        lmen_store['Customer Email'][indeks] = lmen_store['Email'][indeks]\n",
    "        lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "        lmen_store['Region_x'][indeks] = lmen_store['Region_y'][indeks]\n",
    "        lmen_store['City_x'][indeks] = lmen_store['City_y'][indeks]\n",
    "        lmen_store['Kecamatan_x'][indeks] = lmen_store['Kecamatan_y'][indeks]\n",
    "        lmen_store['Kelurahan_x'][indeks] = lmen_store['Kelurahan_y'][indeks]\n",
    "        lmen_store['Zip Code_x'][indeks] = lmen_store['Zip Code_y'][indeks]\n",
    "        lmen_store['Address'][indeks] = lmen_store['Real Address'][indeks]\n",
    "\n",
    "        lmen_store = lmen_store.drop(['Phone_y', 'Email', 'Region_y', 'City_y', 'Kecamatan_y', 'Kelurahan_y', 'Real Address', 'Zip Code_y'], axis = 1)\n",
    "        lmen_store = lmen_store.rename(columns = {'Phone_x' : 'Phone', 'Region_x' : 'Region', 'City_x' : 'City', 'Kecamatan_x' : 'Kecamatan', 'Kelurahan_x' : 'Kelurahan', 'Zip Code_x' : 'Zip Code'})\n",
    "\n",
    "    forstok_all = forstok_all.append(lmen_store, ignore_index = True, sort = False)\n",
    "\n",
    "    indeks = data_all[data_all['Channel'] == 'L-Men Store Blibli'].index.to_list()\n",
    "    data_all['Store'][indeks] = 'Blibli'\n",
    "\n",
    "    data_all = data_all[~data_all['Order #'].astype(str).isin(forstok_all['Order #'].astype(str))]\n",
    "    data_all = data_all[~data_all['Order #'].astype(str).isin(data_magento['Order #'].astype(str))]\n",
    "    data_all = data_all.append(forstok_all, ignore_index = True, sort = False)\n",
    "    data_all = data_all.append(data_magento, ignore_index = True, sort = False)\n",
    "    data_all['Brand'] = data_all['Brand'].astype(str).str.replace('Tropicana Slim', 'TS')\n",
    "\n",
    "    indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "    data_all['Qty. Invoiced'][indeks] = data_all['Qty. Shipped'][indeks]\n",
    "    data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "    indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "    data_all['Qty. Invoiced'][indeks] = data_all['Qty. Ordered'][indeks]\n",
    "    data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "\n",
    "    #             data_SKU['Brand Temp'] = np.nan\n",
    "    #             for i in range(len(data_SKU)):\n",
    "    #                 if data_SKU['Brand'][i] == 'Bonus Produk':\n",
    "    #                     if 'hilo' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                         brand = 'HiLo'\n",
    "    #                     elif 'tropicana' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                         brand = 'TS'\n",
    "    #                     elif 'l-men' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                         brand = 'L-Men'\n",
    "    #                     elif \"w'dank\" in data_SKU['Nama Produk'][i].lower():\n",
    "    #                         brand = \"W'dank\"\n",
    "    #                     elif 'nutrisari' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                         brand = 'NS'\n",
    "    #                     elif 'ts ' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                         brand = 'TS'\n",
    "    #                     data_SKU['Brand Temp'][i] = brand\n",
    "    #             data_SKU['Brand Temp'] = data_SKU['Brand Temp'].fillna(data_SKU['Brand'])\n",
    "\n",
    "    #             data_SKU['List Brand'] = np.nan\n",
    "    #             for i in range(len(data_SKU)):\n",
    "    #                 list_brand = []\n",
    "    #                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "    #                     col_SKU = [x for x in data_SKU.columns if 'SKU Produk' in x]\n",
    "    #                     for j in col_SKU:\n",
    "    #                         if str(data_SKU[j][i]) != 'nan' and str(data_SKU[j][i]) != '0':\n",
    "    #                             brand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Brand Temp'].values[0]\n",
    "    #                             if brand == 'Gimmick' : \n",
    "    #                                 if 'voucher' in data_SKU['Nama Produk'][i].lower() or 'saldo' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'Voucher'\n",
    "    #                                 elif 'pouch' in data_SKU['Nama Produk'][i].lower() or 'bag ' in data_SKU['Nama Produk'][i].lower() or 'tas ' in data_SKU['Nama Produk'][i].lower() or 'totebag' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'Bag'\n",
    "    #                                 elif 'bottle' in data_SKU['Nama Produk'][i].lower() or 'gelas ' in data_SKU['Nama Produk'][i].lower() or 'shaker' in data_SKU['Nama Produk'][i].lower() or 'tumblr' in data_SKU['Nama Produk'][i].lower() or 'tumbler' in data_SKU['Nama Produk'][i].lower() or 'botol' in data_SKU['Nama Produk'][i].lower() or 'thumbler' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'Tumblr'\n",
    "    #                                 elif 'lunch' in data_SKU['Nama Produk'][i].lower() or 'tupper' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'Lunch Box'\n",
    "    #                                 elif 'emoney' in data_SKU['Nama Produk'][i].lower() or 'e-money' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'E-Money'\n",
    "    #                                 elif 'magnet' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'Magnet'\n",
    "    #                                 elif 'masker' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'Masker'\n",
    "    #                                 elif 'spatula' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'Spatula'\n",
    "    #                                 elif 'nivea' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'Nivea'\n",
    "    #                                 elif 'card ' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'Card'\n",
    "    #                                 elif 'mug' in data_SKU['Nama Produk'][i].lower():\n",
    "    #                                     brand = 'Mug'\n",
    "    #                             list_brand.append(brand)\n",
    "    #                 data_SKU['List Brand'][i] = list_brand\n",
    "\n",
    "    #             for i in range(len(data_SKU)):\n",
    "    #                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "    #                     list_brand = list(dict.fromkeys(data_SKU['List Brand'][i]))\n",
    "    #                     sum_brand = sum([1 for x in list_brand if x in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]])\n",
    "    #                     if sum_brand == 1:\n",
    "    #                         list_brand = ' + '.join(list_brand)\n",
    "    #                     else :\n",
    "    #                         not_brand = [x for x in list_brand if x not in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]]\n",
    "    #                         if len(not_brand) == 0:\n",
    "    #                             list_brand = 'Cross Brand'\n",
    "    #                         else :\n",
    "    #                             list_brand = 'Cross Brand + ' + ' + '.join(not_brand)\n",
    "    #                     data_SKU['Sub Brand'][i] = list_brand\n",
    "    #             temp = data_all[data_all['Brand'] == 'Bundle']\n",
    "    #             temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "    #             data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "    #             data_all['Sub Brand'][temp.index] = temp.merge(data_SKU[['SKU', 'Sub Brand']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(temp.index)['Sub Brand_y']\n",
    "\n",
    "\n",
    "    import re \n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.split(';', expand = True)[0]\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('.0','', regex = False)\n",
    "    non_phone = data_all[~data_all['Phone'].astype(str).str.isnumeric()]['Phone'].unique()\n",
    "    for i in non_phone:\n",
    "        index = data_all[data_all['Phone'].astype(str) == str(i)].index.to_list()\n",
    "        if str(i) != 'nan' and str(i) != '':\n",
    "            phone = re.sub(\"[^0-9]\", \"\", i)\n",
    "            if phone[0] == '8':\n",
    "                phone = '0' + phone\n",
    "            data_all['Phone'][index] = phone\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('^628', '08', regex = True)\n",
    "    data_all['Phone'] = data_all['Phone'].apply('=\"{}\"'.format)\n",
    "    data_all['Shipping Phone'] = data_all['Shipping Phone'].apply('=\"{}\"'.format)\n",
    "    indeks = data_all[data_all['City'] == 'nan'].index.to_list()\n",
    "    data_all['City'][indeks] = np.nan\n",
    "\n",
    "    indeks = data_all[data_all['Region'] == 'nan'].index.to_list()\n",
    "    data_all['Region'][indeks] = np.nan\n",
    "\n",
    "    indeks = data_all[data_all['Channel'] == 'FBL'].index.to_list()\n",
    "    data_all['Warehouse Name'][indeks] = 'Lazada Warehouse'\n",
    "\n",
    "    indeks = data_all[data_all['Warehouse Name'] == 'Lazada Warehouse'].index.to_list()\n",
    "    data_all['Channel'][indeks] = 'FBL'\n",
    "\n",
    "    print(\"Read Data Settlement\")\n",
    "    #     data_set = pd.read_csv(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Settlement\\test.csv')\n",
    "    #     data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "    #     data_set['channelorderid'] = data_set['channelorderid'].astype(str)\n",
    "\n",
    "    #     temp_set = data_all.merge(data_set[['channelorderid', 'nominal', 'btlcost', 'gs', 'commfee', 'fullfee']].drop_duplicates('channelorderid'), how = 'left', left_on = 'Order #', right_on = 'channelorderid').set_index(data_all.index)\n",
    "    #     if 'nominal' not in data_all.columns:\n",
    "    #         data_all['nominal'] = np.nan\n",
    "    #         data_all['btlcost'] = np.nan\n",
    "    #         data_all['gs'] = np.nan\n",
    "    #         data_all['commfee'] = np.nan\n",
    "    #         data_all['fullfee'] = np.nan\n",
    "    #         temp_set = temp_set[temp_set['Bundle Flag'] == 'nan']\n",
    "    #         temp_set['nominal'] = temp_set['nominal'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "    #         temp_set['btlcost'] = temp_set['btlcost'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "    #         temp_set['gs'] = temp_set['gs'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "    #         temp_set['commfee'] = temp_set['commfee'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "    #         temp_set['fullfee'] = temp_set['fullfee'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "    #         temp_set = temp_set[temp_set['nominal'].notnull()]\n",
    "    #         data_all['nominal'][temp_set.index] = temp_set['nominal']\n",
    "    #         data_all['btlcost'][temp_set.index] = temp_set['btlcost']\n",
    "    #         data_all['gs'][temp_set.index] = temp_set['gs']\n",
    "    #         data_all['commfee'][temp_set.index] = temp_set['commfee']\n",
    "    #         data_all['fullfee'][temp_set.index] = temp_set['fullfee']\n",
    "    #     else :\n",
    "    #         temp_set = temp_set[temp_set['Bundle Flag'].isnull()]\n",
    "    #         temp_set['nominal_y'] = temp_set['nominal_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "    #         temp_set['btlcost_y'] = temp_set['btlcost_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "    #         temp_set['gs_y'] = temp_set['gs_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "    #         temp_set['commfee_y'] = temp_set['commfee_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "    #         temp_set['fullfee_y'] = temp_set['fullfee_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "    #         temp_set = temp_set[temp_set['nominal_y'].notnull()]\n",
    "    #         data_all['nominal'][temp_set.index] = temp_set['nominal_y']\n",
    "    #         data_all['btlcost'][temp_set.index] = temp_set['btlcost_y']\n",
    "    #         data_all['gs'][temp_set.index] = temp_set['gs_y']\n",
    "    #         data_all['commfee'][temp_set.index] = temp_set['commfee_y']\n",
    "    #         data_all['fullfee'][temp_set.index] = temp_set['fullfee_y']\n",
    "\n",
    "    #     print(\"Export Data All\")\n",
    "    #     for i in data_all.columns[data_all.columns.get_loc('nominal'):]:\n",
    "    #         data_all[i] = pd.to_numeric(data_all[i], errors = 'coerce').fillna(0).astype(int)\n",
    "\n",
    "    temp = data_all.copy()\n",
    "    temp = temp.rename(columns = {'Date' : 'Day'})\n",
    "    temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "    temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "    temp['Hour'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.hour\n",
    "    temp['Minute'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.minute\n",
    "    temp['Second'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.second\n",
    "    data_all['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "    data_all['Hour'] = temp['Hour']\n",
    "\n",
    "    from datetime import datetime\n",
    "\n",
    "    print('Input Forstok Date')\n",
    "    start_date = datetime.today() - timedelta(days=(diff_date+4))###sebelumnya14\n",
    "    end_date = datetime.today()\n",
    "    date = start_date.strftime('%Y-%m-%d') + '-' + end_date.strftime('%Y-%m-%d')\n",
    "    print(date)\n",
    "\n",
    "\n",
    "    print('Opening Chrome')\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "    print('Login Forstok')\n",
    "    username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"andra.miftah@nutrifood.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "    password.send_keys(\"nutrimart1234\")\n",
    "\n",
    "    driver.find_element_by_name(\"commit\").click()\n",
    "    \n",
    "    ##### komen 6 juli 2022\n",
    "#     datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.ID, 'history_date')))\n",
    "#     datefield.click()\n",
    "\n",
    "#     driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#     if start_date.month == end_date.month:\n",
    "#         text = \"//div[@class='drp-calendar right']//td[@class = 'available' or @class='weekend available' or @class='in-range available' or @class = 'weekend in-range available'][text() = \" + str(start_date.day) + \"]\"\n",
    "#     else :\n",
    "#         text = \"//div[@class='drp-calendar left']//td[@class = 'available' or @class='weekend available' or @class='in-range available' or @class = 'weekend in-range available'][text() = \" + str(start_date.day) + \"]\"\n",
    "#     driver.find_element_by_xpath(text).click()\n",
    "#     text = \"//div[@class='drp-calendar right']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "#     driver.find_element_by_xpath(text).click()\n",
    "#     time.sleep(2)\n",
    "#     driver.find_element_by_class_name('applyBtn').click()\n",
    "#     driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "#     time.sleep(15)\n",
    "#     WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'export-button'))).click()\n",
    "#     driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#     time.sleep(2)\n",
    "#     WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'group_by_'))).click()\n",
    "#     driver.find_element(By.NAME, 'button').click()\n",
    "#     time.sleep(5)\n",
    "#     driver.quit()\n",
    "    #### komen 6 juli 2022\n",
    "    \n",
    "    #### kode timo 6 juli forstok ganti layout\n",
    "    datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH,'//*[@class=\"sc-iybRtq jRqWsV\"]')))\n",
    "    datefield.click()\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    pilih=0\n",
    "    while pilih < 3:\n",
    "        if start_date.month == end_date.month:\n",
    "            text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "        else :\n",
    "            text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "        time.sleep(10)\n",
    "        text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "        time.sleep(10)\n",
    "        pilih=pilih+1\n",
    "    driver.find_element_by_xpath('//*[@type=\"button\" and contains(text(),\"Apply\")]').click()\n",
    "    # driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "    time.sleep(15)\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[1]\"))).click()\n",
    "    driver.find_element_by_xpath('//span[text()=\"Sales Order\"]').click()\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[2]\"))).click()\n",
    "    # driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    time.sleep(2)\n",
    "\n",
    "    driver.quit()\n",
    "    #### kode timo 6 juli forstok ganti layout\n",
    "    \n",
    "    #             driver = webdriver.Chrome()\n",
    "    #             driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "    #             username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "    #             username.clear()\n",
    "    #             username.send_keys(\"andra.miftah@nutrifood.co.id\")\n",
    "\n",
    "    #             password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "    #             password.send_keys(\"nutrimart1234\")\n",
    "\n",
    "    #             driver.find_element_by_name(\"commit\").click()\n",
    "\n",
    "    #             datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[2]/section/div')))\n",
    "    #             datefield.click()\n",
    "\n",
    "    #             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    #             if start_date.month != end_date.month:\n",
    "    #                 text = \"//*[normalize-space(text()) = '\" + str(start_date.strftime('%B')) + \"']\"\n",
    "    #                 driver.find_element_by_xpath(text).click()\n",
    "    #             text = \"//*[normalize-space(text()) = '\" + str(start_date.strftime('%B')) + \"']\" + \"/../..//*[normalize-space(text()) = '\" + str(start_date.day) + \"']\"\n",
    "    #             driver.find_element_by_xpath(text).click()\n",
    "    #             text = \"//*[normalize-space(text()) = '\" + str(end_date.strftime('%B')) + \"']/../..//td[not(contains(@class, 'otherMonth'))]//*[normalize-space(text()) = '\" + str(end_date.day) + \"']\"\n",
    "    #             driver.find_element_by_xpath(text).click()\n",
    "\n",
    "    #             driver.find_element_by_xpath('//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[2]/section/section/aside/div/button[2]').click()\n",
    "    #             driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "    #             time.sleep(15)\n",
    "    #             WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[1]/button'))).click()\n",
    "    #             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    #             time.sleep(2)\n",
    "    #             driver.find_element(By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[2]/section[1]/div/div[1]/label').click()\n",
    "    #             driver.find_element(By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[2]/section[2]/button').click()\n",
    "    #             time.sleep(15)\n",
    "    #             driver.quit()\n",
    "\n",
    "    print('Forstok Downloaded')\n",
    "\n",
    "    print('Download Data SKU')\n",
    "    # Import library\n",
    "\n",
    "    import time\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import math\n",
    "\n",
    "    import smtplib \n",
    "    from email.mime.text import MIMEText\n",
    "    from email.mime.application import MIMEApplication\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from smtplib import SMTP\n",
    "    import smtplib\n",
    "    import sys\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('Waiting to Download Forstok')\n",
    "    s = requests.Session()\n",
    "    r = s.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "    data = {'dashboard_user_email' : 'andra.miftah@nutrifood.co.id', \"dashboard_user_password\" : 'nutrimart1234'}\n",
    "    r = s.post(\"https://www.forstok.com/dashboard/users/login\", data = data)\n",
    "\n",
    "    text = 'https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/nutrifood--forstok-sales_orders-version_1-' + date + '.xls'\n",
    "    print(text)\n",
    "    while True:\n",
    "        r = s.get(text)\n",
    "        print('Waiting to Download Forstok')\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print(r.status_code)\n",
    "            with open('Input Data/Forstok_new_input.xls', 'wb') as output:\n",
    "                output.write(r.content)\n",
    "            break\n",
    "        else :\n",
    "            time.sleep(60)\n",
    "\n",
    "    with open('Input Data/nutrifood--forstok-sales_orders-' + date + '.xls', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    orstat_forstok = pd.read_excel(r'Input Data/Forstok_new_input.xls')\n",
    "    orstat_forstok['Date'] = np.nan\n",
    "    orstat_forstok['Month'] = np.nan\n",
    "    orstat_forstok['Year'] = np.nan\n",
    "\n",
    "    orstat_forstok['Order Date'] = pd.to_datetime(orstat_forstok['Order Date'])\n",
    "    for i in range(orstat_forstok.shape[0]):\n",
    "        if int(orstat_forstok['Order Date'][i].strftime('%d')) <= 12:\n",
    "            orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "            orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "            orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "        else :\n",
    "            orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).day\n",
    "            orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).month_name()\n",
    "            orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).year\n",
    "\n",
    "    temp = orstat_forstok.copy()\n",
    "    temp['Day'] = temp['Date']\n",
    "    temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "    temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "    orstat_forstok['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "    temp['Hour'] = pd.to_datetime(orstat_forstok['Order Date']).dt.hour\n",
    "    temp['Minute'] = pd.to_datetime(orstat_forstok['Order Date']).dt.minute\n",
    "    temp['Second'] = pd.to_datetime(orstat_forstok['Order Date']).dt.second\n",
    "    orstat_forstok['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "    print(\"Update Order Status\")\n",
    "    date_min  = orstat_forstok['True datetime'].min()\n",
    "    orstat_forstok = orstat_forstok[['Sales Order ID','Status']].drop_duplicates('Sales Order ID')\n",
    "    shopee_bp = data_all[data_all['Customer Name'] == 'Shopee Brand Portal']\n",
    "    data_all = data_all[data_all['Customer Name'] != 'Shopee Brand Portal']\n",
    "    temp_all = data_all[data_all['True datetime'] >= pd.to_datetime(date_min)][~data_all[data_all['True datetime'] >= pd.to_datetime(date_min)]['Channel'].isin(['Nutrimart', 'L-Men Store Blibli', 'Order Online', 'Order Online Jakarta', 'Order Online Surabaya'])]\n",
    "    orstat_forstok['Sales Order ID'] = orstat_forstok['Sales Order ID'].astype(str)\n",
    "    temp_all['Sales Order ID'] = temp_all['Sales Order ID'].astype(str)\n",
    "    temp_all = temp_all.merge(orstat_forstok, how = 'left', on = 'Sales Order ID')\n",
    "    temp_all['Status'] = temp_all['Status'].fillna('Canceled')\n",
    "    temp_all['Order Status'] = temp_all['Status']\n",
    "    temp_all = temp_all.drop('Status', axis = 1)\n",
    "    data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "    temp_all['Order #'] = temp_all['Order #'].astype(str)\n",
    "    data_all = data_all[~data_all['Order #'].isin(temp_all['Order #'])]\n",
    "    data_all = data_all.append(temp_all, ignore_index = True, sort = False)\n",
    "    data_all = data_all.append(shopee_bp, ignore_index = True, sort = False)\n",
    "    print(\"Export Master Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Data Settlement\n",
      "Input Forstok Date\n",
      "2022-06-23-2022-07-07\n",
      "Opening Chrome\n",
      "Login Forstok\n",
      "Forstok Downloaded\n",
      "Download Data SKU\n",
      "Waiting to Download Forstok\n",
      "https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/nutrifood--forstok-sales_orders-version_1-2022-06-23-2022-07-07.xls\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:405: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update Order Status\n",
      "Export Master Data\n"
     ]
    }
   ],
   "source": [
    "username = driver.find_element_by_id(\"email\")\n",
    "username.clear()\n",
    "username.send_keys(\"novita.vidianti@nutrifood.co.id\")\n",
    "\n",
    "password = driver.find_element_by_id(\"password\")\n",
    "password.send_keys(\"Mengejarcu4n\")\n",
    "\n",
    "driver.find_element_by_id(\"sign-in\").click()\n",
    "time.sleep(5)\n",
    "#             WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'close-announcement-button'))).click()\n",
    "#             WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'remind-me-later-button'))).click()\n",
    "#     WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'nav-wrapper-ORDER'))).click()\n",
    "#     driver.find_element_by_id(\"sub-nav-item-0\").click()\n",
    "driver.get(\"https://seller.blibli.com/MTA/order/summary\")\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn-primary-mta'))).click()\n",
    "driver.find_element_by_id(\"semuaFilter\").click()\n",
    "\n",
    "ornum['Phone'] = np.nan\n",
    "ornum['Email'] = np.nan\n",
    "ornum['Address'] = np.nan\n",
    "\n",
    "for i in ornum.index:\n",
    "    orderNo = ornum['Order #'][i]\n",
    "    orderItemNo = int(pd.to_numeric(ornum['Sales Order ID'][i]))\n",
    "    link = \"https://merchant.blibli.com/MTA/neo/order/order-detail/\" + \"?orderNo=\" + str(orderNo) + \"&orderItemNo=\" + str(orderItemNo)\n",
    "    driver.get(link)\n",
    "    WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"customer-phone\"]/div/span')))\n",
    "    hp = driver.find_elements_by_xpath('//*[@id=\"customer-phone\"]/div/span')[0].text\n",
    "    if len(driver.find_elements_by_xpath('//*[@id=\"customer-email\"]/span')) != 0:\n",
    "        email = driver.find_elements_by_xpath('//*[@id=\"customer-email\"]/span')[0].text\n",
    "        ornum['Email'][i] = email\n",
    "    address = driver.find_elements_by_xpath('//*[@id=\"alamat-pengiriman\"]//div//p')[0].text\n",
    "    ornum['Phone'][i] = hp\n",
    "    ornum['Address'][i] = address\n",
    "\n",
    "driver.quit()\n",
    "if len(ornum) != 0:\n",
    "    tes = ornum.copy()\n",
    "    tes['Real Address'] = tes['Address'].str.split('\\n', expand = True)[1].str.strip()\n",
    "    tes['Kelurahan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[0].str.strip()\n",
    "    tes['Kecamatan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[1].str.strip()\n",
    "    tes['City'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[0].str.strip()\n",
    "    tes['Region'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[1].str.strip()\n",
    "    tes['Zip Code'] = tes['Address'].str.split('\\n', expand = True)[5].str.strip()\n",
    "\n",
    "    lmen_store['Order #'] = lmen_store['Order #'].astype(str)\n",
    "    tes['Order #'] = tes['Order #'].astype(str)\n",
    "    lmen_store = lmen_store.merge(tes[['Order #', 'Phone', 'Email', 'Real Address', 'Kelurahan', 'Kecamatan', 'City', 'Region', 'Zip Code']].drop_duplicates('Order #'), how = 'left', on = 'Order #')\n",
    "\n",
    "    indeks = lmen_store[lmen_store['Phone_y'].notnull()].index.to_list()\n",
    "    lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "    lmen_store['Customer Email'][indeks] = lmen_store['Email'][indeks]\n",
    "    lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "    lmen_store['Region_x'][indeks] = lmen_store['Region_y'][indeks]\n",
    "    lmen_store['City_x'][indeks] = lmen_store['City_y'][indeks]\n",
    "    lmen_store['Kecamatan_x'][indeks] = lmen_store['Kecamatan_y'][indeks]\n",
    "    lmen_store['Kelurahan_x'][indeks] = lmen_store['Kelurahan_y'][indeks]\n",
    "    lmen_store['Zip Code_x'][indeks] = lmen_store['Zip Code_y'][indeks]\n",
    "    lmen_store['Address'][indeks] = lmen_store['Real Address'][indeks]\n",
    "\n",
    "    lmen_store = lmen_store.drop(['Phone_y', 'Email', 'Region_y', 'City_y', 'Kecamatan_y', 'Kelurahan_y', 'Real Address', 'Zip Code_y'], axis = 1)\n",
    "    lmen_store = lmen_store.rename(columns = {'Phone_x' : 'Phone', 'Region_x' : 'Region', 'City_x' : 'City', 'Kecamatan_x' : 'Kecamatan', 'Kelurahan_x' : 'Kelurahan', 'Zip Code_x' : 'Zip Code'})\n",
    "\n",
    "forstok_all = forstok_all.append(lmen_store, ignore_index = True, sort = False)\n",
    "\n",
    "indeks = data_all[data_all['Channel'] == 'L-Men Store Blibli'].index.to_list()\n",
    "data_all['Store'][indeks] = 'Blibli'\n",
    "\n",
    "data_all = data_all[~data_all['Order #'].astype(str).isin(forstok_all['Order #'].astype(str))]\n",
    "data_all = data_all[~data_all['Order #'].astype(str).isin(data_magento['Order #'].astype(str))]\n",
    "data_all = data_all.append(forstok_all, ignore_index = True, sort = False)\n",
    "data_all = data_all.append(data_magento, ignore_index = True, sort = False)\n",
    "data_all['Brand'] = data_all['Brand'].astype(str).str.replace('Tropicana Slim', 'TS')\n",
    "\n",
    "indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "data_all['Qty. Invoiced'][indeks] = data_all['Qty. Shipped'][indeks]\n",
    "data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "data_all['Qty. Invoiced'][indeks] = data_all['Qty. Ordered'][indeks]\n",
    "data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "\n",
    "#             data_SKU['Brand Temp'] = np.nan\n",
    "#             for i in range(len(data_SKU)):\n",
    "#                 if data_SKU['Brand'][i] == 'Bonus Produk':\n",
    "#                     if 'hilo' in data_SKU['Nama Produk'][i].lower():\n",
    "#                         brand = 'HiLo'\n",
    "#                     elif 'tropicana' in data_SKU['Nama Produk'][i].lower():\n",
    "#                         brand = 'TS'\n",
    "#                     elif 'l-men' in data_SKU['Nama Produk'][i].lower():\n",
    "#                         brand = 'L-Men'\n",
    "#                     elif \"w'dank\" in data_SKU['Nama Produk'][i].lower():\n",
    "#                         brand = \"W'dank\"\n",
    "#                     elif 'nutrisari' in data_SKU['Nama Produk'][i].lower():\n",
    "#                         brand = 'NS'\n",
    "#                     elif 'ts ' in data_SKU['Nama Produk'][i].lower():\n",
    "#                         brand = 'TS'\n",
    "#                     data_SKU['Brand Temp'][i] = brand\n",
    "#             data_SKU['Brand Temp'] = data_SKU['Brand Temp'].fillna(data_SKU['Brand'])\n",
    "\n",
    "#             data_SKU['List Brand'] = np.nan\n",
    "#             for i in range(len(data_SKU)):\n",
    "#                 list_brand = []\n",
    "#                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "#                     col_SKU = [x for x in data_SKU.columns if 'SKU Produk' in x]\n",
    "#                     for j in col_SKU:\n",
    "#                         if str(data_SKU[j][i]) != 'nan' and str(data_SKU[j][i]) != '0':\n",
    "#                             brand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Brand Temp'].values[0]\n",
    "#                             if brand == 'Gimmick' : \n",
    "#                                 if 'voucher' in data_SKU['Nama Produk'][i].lower() or 'saldo' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'Voucher'\n",
    "#                                 elif 'pouch' in data_SKU['Nama Produk'][i].lower() or 'bag ' in data_SKU['Nama Produk'][i].lower() or 'tas ' in data_SKU['Nama Produk'][i].lower() or 'totebag' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'Bag'\n",
    "#                                 elif 'bottle' in data_SKU['Nama Produk'][i].lower() or 'gelas ' in data_SKU['Nama Produk'][i].lower() or 'shaker' in data_SKU['Nama Produk'][i].lower() or 'tumblr' in data_SKU['Nama Produk'][i].lower() or 'tumbler' in data_SKU['Nama Produk'][i].lower() or 'botol' in data_SKU['Nama Produk'][i].lower() or 'thumbler' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'Tumblr'\n",
    "#                                 elif 'lunch' in data_SKU['Nama Produk'][i].lower() or 'tupper' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'Lunch Box'\n",
    "#                                 elif 'emoney' in data_SKU['Nama Produk'][i].lower() or 'e-money' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'E-Money'\n",
    "#                                 elif 'magnet' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'Magnet'\n",
    "#                                 elif 'masker' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'Masker'\n",
    "#                                 elif 'spatula' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'Spatula'\n",
    "#                                 elif 'nivea' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'Nivea'\n",
    "#                                 elif 'card ' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'Card'\n",
    "#                                 elif 'mug' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                     brand = 'Mug'\n",
    "#                             list_brand.append(brand)\n",
    "#                 data_SKU['List Brand'][i] = list_brand\n",
    "\n",
    "#             for i in range(len(data_SKU)):\n",
    "#                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "#                     list_brand = list(dict.fromkeys(data_SKU['List Brand'][i]))\n",
    "#                     sum_brand = sum([1 for x in list_brand if x in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]])\n",
    "#                     if sum_brand == 1:\n",
    "#                         list_brand = ' + '.join(list_brand)\n",
    "#                     else :\n",
    "#                         not_brand = [x for x in list_brand if x not in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]]\n",
    "#                         if len(not_brand) == 0:\n",
    "#                             list_brand = 'Cross Brand'\n",
    "#                         else :\n",
    "#                             list_brand = 'Cross Brand + ' + ' + '.join(not_brand)\n",
    "#                     data_SKU['Sub Brand'][i] = list_brand\n",
    "#             temp = data_all[data_all['Brand'] == 'Bundle']\n",
    "#             temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "#             data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "#             data_all['Sub Brand'][temp.index] = temp.merge(data_SKU[['SKU', 'Sub Brand']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(temp.index)['Sub Brand_y']\n",
    "\n",
    "\n",
    "import re \n",
    "data_all['Phone'] = data_all['Phone'].astype(str).str.split(';', expand = True)[0]\n",
    "data_all['Phone'] = data_all['Phone'].astype(str).str.replace('.0','', regex = False)\n",
    "non_phone = data_all[~data_all['Phone'].astype(str).str.isnumeric()]['Phone'].unique()\n",
    "for i in non_phone:\n",
    "    index = data_all[data_all['Phone'].astype(str) == str(i)].index.to_list()\n",
    "    if str(i) != 'nan' and str(i) != '':\n",
    "        phone = re.sub(\"[^0-9]\", \"\", i)\n",
    "        if phone[0] == '8':\n",
    "            phone = '0' + phone\n",
    "        data_all['Phone'][index] = phone\n",
    "data_all['Phone'] = data_all['Phone'].astype(str).str.replace('^628', '08', regex = True)\n",
    "data_all['Phone'] = data_all['Phone'].apply('=\"{}\"'.format)\n",
    "data_all['Shipping Phone'] = data_all['Shipping Phone'].apply('=\"{}\"'.format)\n",
    "indeks = data_all[data_all['City'] == 'nan'].index.to_list()\n",
    "data_all['City'][indeks] = np.nan\n",
    "\n",
    "indeks = data_all[data_all['Region'] == 'nan'].index.to_list()\n",
    "data_all['Region'][indeks] = np.nan\n",
    "\n",
    "indeks = data_all[data_all['Channel'] == 'FBL'].index.to_list()\n",
    "data_all['Warehouse Name'][indeks] = 'Lazada Warehouse'\n",
    "\n",
    "indeks = data_all[data_all['Warehouse Name'] == 'Lazada Warehouse'].index.to_list()\n",
    "data_all['Channel'][indeks] = 'FBL'\n",
    "\n",
    "print(\"Read Data Settlement\")\n",
    "#     data_set = pd.read_csv(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Settlement\\test.csv')\n",
    "#     data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "#     data_set['channelorderid'] = data_set['channelorderid'].astype(str)\n",
    "\n",
    "#     temp_set = data_all.merge(data_set[['channelorderid', 'nominal', 'btlcost', 'gs', 'commfee', 'fullfee']].drop_duplicates('channelorderid'), how = 'left', left_on = 'Order #', right_on = 'channelorderid').set_index(data_all.index)\n",
    "#     if 'nominal' not in data_all.columns:\n",
    "#         data_all['nominal'] = np.nan\n",
    "#         data_all['btlcost'] = np.nan\n",
    "#         data_all['gs'] = np.nan\n",
    "#         data_all['commfee'] = np.nan\n",
    "#         data_all['fullfee'] = np.nan\n",
    "#         temp_set = temp_set[temp_set['Bundle Flag'] == 'nan']\n",
    "#         temp_set['nominal'] = temp_set['nominal'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#         temp_set['btlcost'] = temp_set['btlcost'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#         temp_set['gs'] = temp_set['gs'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#         temp_set['commfee'] = temp_set['commfee'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#         temp_set['fullfee'] = temp_set['fullfee'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#         temp_set = temp_set[temp_set['nominal'].notnull()]\n",
    "#         data_all['nominal'][temp_set.index] = temp_set['nominal']\n",
    "#         data_all['btlcost'][temp_set.index] = temp_set['btlcost']\n",
    "#         data_all['gs'][temp_set.index] = temp_set['gs']\n",
    "#         data_all['commfee'][temp_set.index] = temp_set['commfee']\n",
    "#         data_all['fullfee'][temp_set.index] = temp_set['fullfee']\n",
    "#     else :\n",
    "#         temp_set = temp_set[temp_set['Bundle Flag'].isnull()]\n",
    "#         temp_set['nominal_y'] = temp_set['nominal_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#         temp_set['btlcost_y'] = temp_set['btlcost_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#         temp_set['gs_y'] = temp_set['gs_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#         temp_set['commfee_y'] = temp_set['commfee_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#         temp_set['fullfee_y'] = temp_set['fullfee_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#         temp_set = temp_set[temp_set['nominal_y'].notnull()]\n",
    "#         data_all['nominal'][temp_set.index] = temp_set['nominal_y']\n",
    "#         data_all['btlcost'][temp_set.index] = temp_set['btlcost_y']\n",
    "#         data_all['gs'][temp_set.index] = temp_set['gs_y']\n",
    "#         data_all['commfee'][temp_set.index] = temp_set['commfee_y']\n",
    "#         data_all['fullfee'][temp_set.index] = temp_set['fullfee_y']\n",
    "\n",
    "#     print(\"Export Data All\")\n",
    "#     for i in data_all.columns[data_all.columns.get_loc('nominal'):]:\n",
    "#         data_all[i] = pd.to_numeric(data_all[i], errors = 'coerce').fillna(0).astype(int)\n",
    "\n",
    "temp = data_all.copy()\n",
    "temp = temp.rename(columns = {'Date' : 'Day'})\n",
    "temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "temp['Hour'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.hour\n",
    "temp['Minute'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.minute\n",
    "temp['Second'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.second\n",
    "data_all['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "data_all['Hour'] = temp['Hour']\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "print('Input Forstok Date')\n",
    "start_date = datetime.today() - timedelta(days=(diff_date+4))###sebelumnya14\n",
    "end_date = datetime.today()\n",
    "date = start_date.strftime('%Y-%m-%d') + '-' + end_date.strftime('%Y-%m-%d')\n",
    "print(date)\n",
    "\n",
    "\n",
    "print('Opening Chrome')\n",
    "driver = webdriver.Chrome()\n",
    "driver.fullscreen_window()\n",
    "driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "print('Login Forstok')\n",
    "username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "username.clear()\n",
    "username.send_keys(\"andra.miftah@nutrifood.co.id\")\n",
    "\n",
    "password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "password.send_keys(\"nutrimart1234\")\n",
    "\n",
    "driver.find_element_by_name(\"commit\").click()\n",
    "\n",
    "##### komen 6 juli 2022\n",
    "#     datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.ID, 'history_date')))\n",
    "#     datefield.click()\n",
    "\n",
    "#     driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#     if start_date.month == end_date.month:\n",
    "#         text = \"//div[@class='drp-calendar right']//td[@class = 'available' or @class='weekend available' or @class='in-range available' or @class = 'weekend in-range available'][text() = \" + str(start_date.day) + \"]\"\n",
    "#     else :\n",
    "#         text = \"//div[@class='drp-calendar left']//td[@class = 'available' or @class='weekend available' or @class='in-range available' or @class = 'weekend in-range available'][text() = \" + str(start_date.day) + \"]\"\n",
    "#     driver.find_element_by_xpath(text).click()\n",
    "#     text = \"//div[@class='drp-calendar right']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "#     driver.find_element_by_xpath(text).click()\n",
    "#     time.sleep(2)\n",
    "#     driver.find_element_by_class_name('applyBtn').click()\n",
    "#     driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "#     time.sleep(15)\n",
    "#     WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'export-button'))).click()\n",
    "#     driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#     time.sleep(2)\n",
    "#     WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'group_by_'))).click()\n",
    "#     driver.find_element(By.NAME, 'button').click()\n",
    "#     time.sleep(5)\n",
    "#     driver.quit()\n",
    "#### komen 6 juli 2022\n",
    "\n",
    "#### kode timo 6 juli forstok ganti layout\n",
    "datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH,'//*[@class=\"sc-iybRtq jRqWsV\"]')))\n",
    "datefield.click()\n",
    "driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "pilih=0\n",
    "while pilih < 3:\n",
    "    if start_date.month == end_date.month:\n",
    "        text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "    else :\n",
    "        text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "    driver.find_element_by_xpath(text).click()\n",
    "    time.sleep(10)\n",
    "    text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "    driver.find_element_by_xpath(text).click()\n",
    "    time.sleep(10)\n",
    "    pilih=pilih+1\n",
    "driver.find_element_by_xpath('//*[@type=\"button\" and contains(text(),\"Apply\")]').click()\n",
    "# driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "time.sleep(15)\n",
    "driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[1]\"))).click()\n",
    "driver.find_element_by_xpath('//span[text()=\"Sales Order\"]').click()\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[2]\"))).click()\n",
    "# driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "time.sleep(2)\n",
    "\n",
    "driver.quit()\n",
    "#### kode timo 6 juli forstok ganti layout\n",
    "\n",
    "#             driver = webdriver.Chrome()\n",
    "#             driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "#             username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "#             username.clear()\n",
    "#             username.send_keys(\"andra.miftah@nutrifood.co.id\")\n",
    "\n",
    "#             password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "#             password.send_keys(\"nutrimart1234\")\n",
    "\n",
    "#             driver.find_element_by_name(\"commit\").click()\n",
    "\n",
    "#             datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[2]/section/div')))\n",
    "#             datefield.click()\n",
    "\n",
    "#             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#             if start_date.month != end_date.month:\n",
    "#                 text = \"//*[normalize-space(text()) = '\" + str(start_date.strftime('%B')) + \"']\"\n",
    "#                 driver.find_element_by_xpath(text).click()\n",
    "#             text = \"//*[normalize-space(text()) = '\" + str(start_date.strftime('%B')) + \"']\" + \"/../..//*[normalize-space(text()) = '\" + str(start_date.day) + \"']\"\n",
    "#             driver.find_element_by_xpath(text).click()\n",
    "#             text = \"//*[normalize-space(text()) = '\" + str(end_date.strftime('%B')) + \"']/../..//td[not(contains(@class, 'otherMonth'))]//*[normalize-space(text()) = '\" + str(end_date.day) + \"']\"\n",
    "#             driver.find_element_by_xpath(text).click()\n",
    "\n",
    "#             driver.find_element_by_xpath('//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[2]/section/section/aside/div/button[2]').click()\n",
    "#             driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "#             time.sleep(15)\n",
    "#             WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[1]/button'))).click()\n",
    "#             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#             time.sleep(2)\n",
    "#             driver.find_element(By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[2]/section[1]/div/div[1]/label').click()\n",
    "#             driver.find_element(By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[2]/section[2]/button').click()\n",
    "#             time.sleep(15)\n",
    "#             driver.quit()\n",
    "\n",
    "print('Forstok Downloaded')\n",
    "\n",
    "print('Download Data SKU')\n",
    "# Import library\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib \n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "\n",
    "print('Waiting to Download Forstok')\n",
    "s = requests.Session()\n",
    "r = s.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "data = {'dashboard_user_email' : 'andra.miftah@nutrifood.co.id', \"dashboard_user_password\" : 'nutrimart1234'}\n",
    "r = s.post(\"https://www.forstok.com/dashboard/users/login\", data = data)\n",
    "\n",
    "text = 'https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/nutrifood--forstok-sales_orders-version_1-' + date + '.xls'\n",
    "print(text)\n",
    "while True:\n",
    "    r = s.get(text)\n",
    "    print('Waiting to Download Forstok')\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        print(r.status_code)\n",
    "        with open('Input Data/Forstok_new_input.xls', 'wb') as output:\n",
    "            output.write(r.content)\n",
    "        break\n",
    "    else :\n",
    "        time.sleep(60)\n",
    "\n",
    "with open('Input Data/nutrifood--forstok-sales_orders-' + date + '.xls', 'wb') as output:\n",
    "    output.write(r.content)\n",
    "\n",
    "orstat_forstok = pd.read_excel(r'Input Data/Forstok_new_input.xls')\n",
    "orstat_forstok['Date'] = np.nan\n",
    "orstat_forstok['Month'] = np.nan\n",
    "orstat_forstok['Year'] = np.nan\n",
    "\n",
    "orstat_forstok['Order Date'] = pd.to_datetime(orstat_forstok['Order Date'])\n",
    "for i in range(orstat_forstok.shape[0]):\n",
    "    if int(orstat_forstok['Order Date'][i].strftime('%d')) <= 12:\n",
    "        orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "        orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "        orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "    else :\n",
    "        orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).day\n",
    "        orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).month_name()\n",
    "        orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).year\n",
    "\n",
    "temp = orstat_forstok.copy()\n",
    "temp['Day'] = temp['Date']\n",
    "temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "orstat_forstok['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "temp['Hour'] = pd.to_datetime(orstat_forstok['Order Date']).dt.hour\n",
    "temp['Minute'] = pd.to_datetime(orstat_forstok['Order Date']).dt.minute\n",
    "temp['Second'] = pd.to_datetime(orstat_forstok['Order Date']).dt.second\n",
    "orstat_forstok['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "print(\"Update Order Status\")\n",
    "date_min  = orstat_forstok['True datetime'].min()\n",
    "orstat_forstok = orstat_forstok[['Sales Order ID','Status']].drop_duplicates('Sales Order ID')\n",
    "shopee_bp = data_all[data_all['Customer Name'] == 'Shopee Brand Portal']\n",
    "data_all = data_all[data_all['Customer Name'] != 'Shopee Brand Portal']\n",
    "temp_all = data_all[data_all['True datetime'] >= pd.to_datetime(date_min)][~data_all[data_all['True datetime'] >= pd.to_datetime(date_min)]['Channel'].isin(['Nutrimart', 'L-Men Store Blibli', 'Order Online', 'Order Online Jakarta', 'Order Online Surabaya'])]\n",
    "orstat_forstok['Sales Order ID'] = orstat_forstok['Sales Order ID'].astype(str)\n",
    "temp_all['Sales Order ID'] = temp_all['Sales Order ID'].astype(str)\n",
    "temp_all = temp_all.merge(orstat_forstok, how = 'left', on = 'Sales Order ID')\n",
    "temp_all['Status'] = temp_all['Status'].fillna('Canceled')\n",
    "temp_all['Order Status'] = temp_all['Status']\n",
    "temp_all = temp_all.drop('Status', axis = 1)\n",
    "data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "temp_all['Order #'] = temp_all['Order #'].astype(str)\n",
    "data_all = data_all[~data_all['Order #'].isin(temp_all['Order #'])]\n",
    "data_all = data_all.append(temp_all, ignore_index = True, sort = False)\n",
    "data_all = data_all.append(shopee_bp, ignore_index = True, sort = False)\n",
    "print(\"Export Master Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[(data_all['Store']=='Tokopedia')&(data_all['Year']==2022)&(data_all['Month']=='April')&\n",
    "         ~(data_all['Order Status'].str.contains('cancel',case=False))&(data_all['Bundle Name'].isnull())].groupby(['Year','Month','Date','Store'])[['Total']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_magento[~data_magento['SKU'].isin(data_SKU['SKU'])]['Product Name'].unique()\n",
    "data_magento[~data_magento['SKU'].isin(data_SKU['SKU'])]['SKU'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run-5\n",
    "indeks = data_all[data_all['Qty. Invoiced'].isnull()].index.to_list()\n",
    "data_all['Qty. Invoiced'][indeks] = 0\n",
    "data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##run-6\n",
    "order_online_cond = False\n",
    "shopee_scrap = False\n",
    "shopee_done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##run-7\n",
    "order_online_jatim = False\n",
    "order_online_jkt = False\n",
    "order_online_jateng = False\n",
    "order_online_bali = False\n",
    "order_online_makasar = False\n",
    "order_online_samarinda = False\n",
    "order_online_medan = False\n",
    "order_online_lampung = False\n",
    "order_online_pekanbaru = False\n",
    "order_online_banjarmasin = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_online_jatim\n",
      "--- 228.54512333869934 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 228.7740135192871 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:587: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n",
      "order_online_jkt\n",
      "--- 400.1143662929535 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 400.194051027298 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1562: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n",
      "order_online_jateng\n",
      "--- 559.2115216255188 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 559.3312005996704 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:2440: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n",
      "order_online_bali\n",
      "--- 684.8477492332458 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 684.9283745288849 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:3266: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n",
      "order_online_makasar\n",
      "--- 786.2813766002655 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 786.3660955429077 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:4072: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n",
      "order_online_medan\n",
      "--- 872.9673836231232 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 873.0620532035828 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:4885: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n",
      "order_online_samarinda\n",
      "--- 964.9496514797211 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 965.0343267917633 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:5695: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n",
      "order_online_lampung\n",
      "--- 1092.3975992202759 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 1092.569610118866 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:6499: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n",
      "order_online_pekanbaru\n",
      "--- 1194.9710190296173 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 1195.0244252681732 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:7306: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n",
      "order_online_banjarmasin\n",
      "--- 1284.180836200714 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 1284.2204778194427 seconds ---\n",
      "Filling Date ====== 7/10\n",
      "Filling Location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8111: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbundling\n",
      "Pricing\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "if not order_online_jatim:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_jatim')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "    \n",
    "    time.sleep(30)\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customer@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"jatimhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(10)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(60)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#     data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Surabaya.csv')\n",
    "    product_order = pd.read_csv(r'Input Data/orderonline_products_Surabaya.csv')\n",
    "    \n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    \n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 'L-Men Hi Protein 2 Go Chocolate (24 pcs)', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch')\n",
    "#     indeks = data_order[data_order['product'].astype(str).str.contains('L-Men Hi Protein 2 Go Chocolate 24 pcs')].index.to_list()\n",
    "#     data_order['Quantity'][indeks] = 1\n",
    "                        \n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate (12sch)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria (40 sch)', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 Sch)', 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Cincau 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sunflower Oil 946 ml', 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Lose Weight Chocolate Cereal 300gr\", 118800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Platinum Choco Latte Dus 6 sch\", 80000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 pcs)\", 264000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 10500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Gain Mass Banana 225gr\", 61000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate 12 sch\", 105600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo Chocolate Taro (10 sch)\", 14700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - W'Dank Empon Empon 10 Sachet Renceng\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(FREE) W'Dank Empon-Empon 10 sch\", 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Chocolate 1000 gr\", 136400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-MEN Gain Mass Taro 225 gr\", 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Whey Daily Dark Chocolate 250gr\", 49500]], columns = ['title', 'price']), ignore_index = True, sort = False)                                        \n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo Es Ketan Hitam 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Honey 500gr\", 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Vanilla 750gr\", 102300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "#     product_order = product_order.append(pd.DataFrame([[\"Hilo Es Ketan Hitam 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)', 52000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Sweetener Jahe 50 sch\", 38500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Korean Garlic Butter Cookies 5 Sch\", 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sambal Terasi 200 gr', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2', 107800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)', 67500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate 12 sch', 105600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Crunch BBQ Beef (20gr)', 9900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Avocado Coffee 4 Sch x 2', 24200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 28900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 20700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Cocopandan 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Shirataki Noodles 71gr', 28100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Saus Tiram 200ml', 39600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Noodles 71gr', 14200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Saus Tiram 200ml', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim White Coffee (4sch)', 17600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hampers Idul Fitri Tropicana Slim', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Takjil HiLo Dessert', 67500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ramadhan NutriSari 2021', 60000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Kehangatan WDank - Ramadhan Edition', 60000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Platinum Kacang Hijau 800g', 275000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - SUGAR FREE', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Whey Advanced Cappuccino 250gr', 79200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Minyak Kanola 946ml - 100% Pure Canola Oil - Free Korean Garlic Butter Cookies 1 sch', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Minyak Kanola 946ml', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(EACH)Tropicana Slim Korean Garlic Butter Cookies - Sampling', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Platinum Ketan Hitam 800g (25g protein / serving) - Suplemen Tinggi Whey Protein Rendah Lemak', 302500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Whey Advanced Choco Vanilla 500gr', 148500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Susu Skim Chocolate 500gr - Bantu Turunkan Kolesterol', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Cafe Latte 10 Sachet 14gr - Kopi Susu Nikmat Tanpa Gula Pasir', 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Platinum Choco Latte 800gr (25gr protein)', 302500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Susu Skim Plain 1000gr - Bantu Turunkan Kolesterol', 180400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Susu Skim Coffee 500gr - Bantu Turunkan Kolesterol', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - HiLo Active Es Teler 175gr', 38000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Es Teler 175gr', 19000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Apel Jeruk 40 Sachet', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Teen Popcorn Caramel 500 gram x 2', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch', 57800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Rose Vanilla 50 sch', 28900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Chocolate 500gr', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Coffee 500gr', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml - [Free] Tropicana Slim Shirataki Noodles 71gr', 83500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 750g Susu Tinggi Kalsium Lebih Rendah Lemak - [FREE] HiLo Active Ketan Hitam 175g', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim DIABTX (100 sch) - [FREE] Tropicana Slim Avocado Coffee 4 Sch', 76000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Original 1kg', 187700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs', 22600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak Jeruk Bali 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD)', 5650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Mayonnaise 200 g x 2', 34800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Mayonnaise 200 g - Bantu Dukung Hidup Sehat', 17400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Chocolate 1000 gr', 115500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: L-Men Daily Popcorn Caramel 250gr x 2', 78200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml', 83500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Daily Popcorn Caramel 250gr', 39100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 - HiLo Gold Sweet Potato 500 gram', 73200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Jeje Si Jeli', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Asin 200 ml', 24600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Sweet Potato 500 gram', 73200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) HiLo Gold Sweet Potato 500 gram', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE HiLo Joint Plus 140gr', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Joint Plus Orange 140 gram', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) HiLo Joint Plus Orange 140 gram', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Korean Goguma Cookies (5 Sch) x 2', 32200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Mba Nana Si Penuh Pesona', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Popcorn Caramel 500gr', 68600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 1000 gr', 141900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Special Bundle - Tropicana Slim Sweetener Rose Vanilla & Tropicana Slim Korean Goguma Cookies', 55000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 6850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 6850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Rose Vanilla 50 sch', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Andaliman 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Tape Ketan 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Plain 1000 gr', 128200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Mas Kaka yang Banyak Akal', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo School Strawberry Cheesecake 500 gram x 2', 110600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Strawberry Cheesecake 500 gram', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Joint Plus Orange 140 gram x 2', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla Vegiberi 750gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Kurma Pack (4R)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Jeju [40 Sachet]', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak (4R)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Nipis (40 sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Lemon (40 Sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea (10 sch)', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml (4pcs)', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Swiss Chocolate (10 sch) Renceng', 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Teen Coffee Tiramisu Ready To Drink Susu UHT [4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Teen Chocolate Ready To Drink Susu [4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Vanilla Vegiberi Ready To Drink Susu [200ml/4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea 40 sch', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Yuzu Orange 40 sch', 46200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Manis 500gr', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Gold Sweet Potato 500 gram x 2', 105600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Andaliman 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Sweet Potato 500 gram', 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Tape Ketan 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim DIABTX (100 sch)', 76100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Nutty Chocolate Cookies 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Markisa (40 Sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Madu Jeruk (40sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari NUTRI C1000 Jeruk 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Chocolate 500gr', 61800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bajigur (10 sch)\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener I Sweet', 21700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Kacang Hijau 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - Lokalate Kopi Tape Ketan 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Classic Refill 500gr', 98400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Fiber Pro Plain 500gr', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Vanilla Caramel 500gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim High Fiber High Calcium Milk Chocolate 500gr', 112100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - Lokalate Kopi Andaliman 10 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Almond Milk Coconut 200gr x 2', 70000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Almond Milk Coconut 200gr', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Yoghurt Smoothie Bowl Strawberry (8 sch)', 62900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bandrek 10 sachet Renceng\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Chocolate Candy (10 sch)\", 18300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102500320 (CI160)\", 72160]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102500336 (CS)\", 45100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Jeruk Maroko (40 Sch) FREE Lokalate Andaliman (10 Sch)\", 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Jeruk Peras Refill 500 gr\", 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Maroko (40 sch)\", 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(FREE) Lokalate Kopi Andaliman 10 Sachet\", 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack:HiLo Teen Strawberry Milkshake 500g x 2\", 100000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Strawberry Milkshake 500g\", 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Chocolate Ready To Drink (4 tetrapack)\", 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School RTD Coklat 200ml\", 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Sirup Leci 750ml\", 30900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Mango Smoothie 200ml (4 Pcs)\", 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari RTD Jeruk Madu 200 ml (4 tetrapack)\", 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari RTD Mango Smoothie 200 ml\", 6900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari RTD Jeruk Madu 200 ml\", 5750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Active Chocolate 750gr\", 89200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate x 4 pcs\", 38400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate\", 9600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey 50 sachet', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack - Tropicana Slim Klepon Cookies (5 Sch) - Snack Bebas Gula, 100 Kalori', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Klepon Cookies (5 Sch)', 16700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Platinum Swiss Chocolate 420gr', 91500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 250g (Health & Green Science Competition)', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Shirataki Rice 72 g', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Rice 72 g', 25000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Nipis Jahe 40 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Vanilla 500gr', 65200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Yoghurt Banana 250gr', 38400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['TS SHIRATAKI RICE RASA NASI UDUK 24PX72G', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Cotton Candy 500g', 62500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Kuwud Nipis', 37500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea Refill 500 gram', 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea Ready to Drink 200ml x 4pcs', 23600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo RTD Thai Tea 200ml', 5900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo School Bubble Gum 500g', 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) HiLo School RTD Coklat 200ML', 6270]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 49500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim BROWNIES  Instant Powder Cake Mix 230 g', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Caramel Latte 500g', 50500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Avocado Chocolate (10 Sch)', 127160]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Bundle - HiLo Teen Taro 500gr & HiLo Teen Strawberry Milkshake 500g', 11400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 63600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Strawberry Milkshake 500g', 63600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)Bundle L-Men Platinum Ketan Hitam 800g & L-Men Platinum Kacang Hijau 800g', 314600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)L-Men Platinum Ketan Hitam 800g ', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)L-Men Platinum Kacang Hijau 800g', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)Twinpack: L-Men Platinum Kacang Hijau 800g', 314600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)L-Men Platinum Kacang Hijau 800g', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Ketan Hitam 500g - Powder Drink Tinggi Kalsium', 44000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Biscuit Caramel 500gr', 65000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Plain (Original) 500gr', 77800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lemon Tea 500 gram', 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Pisang Bakar 10 sch', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Pisang Bakar Epe 10 sch', 8750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Bubble Gum 500g', 80100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack/B1G1 HiLo Multigrain Original 500g', 176000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Multigrain Original 500g', 88000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Lemon-C (25 sch)', 25200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Belgian Chocolate (10 sch)', 49200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Chocolate Polos 10's\", 12000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo White Chocolate (10 Sch)', 12000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Cookies Paket Hampers Idul Fitri Parcel Lebaran', 131600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Banana 10 sch', 12000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese Cookies', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Nutty Chocolate Cookies 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Garlic Butter Cookies 5 Sch', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Klepon Cookies (5 Sch)', 21500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Gift - Paper Bag Ramadhan Tropicana Slim', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Pisang Ijo 10 Sch x 2 pcs', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Mangga 500gr', 132700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 - Tropicana Slim Mint Cocoa - Minuman Cokelat Mint Nikmat Tanpa Gula Pasir', 20000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE L-Men Lose Weight Mango Sticky Rice 300gr', 145200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE Tropicana Slim Susu Low Fat Macchiato Coffee 500gr', 143000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Diabetamil Milk Vanilla 150 gram', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 30900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-MEN PLANTPROTEIN OGURA 6Dx216G', 103900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr - Near ED', 16150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Choco Series Paket Hampers Idul Fitri Parcel Lebaran', 139600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 104800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 115500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Vanilla 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 86650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Pisang Ijo 10 Sch', 14300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Soy Latte - Kopi Plant Based Rendah Gula', 36900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Mint Cocoa 4 Sachet', 20000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Taro 500g x 2 pcs', 133900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Alpukat 500 gram - Tinggi Vitamin A Lebih Rendah Gula', 44400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea Refill 500g', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Soy Latte - Kopi Susu Kacang Bebas Gula', 36900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Unnamed: 0' : 'SKU', 'ref.1' : 'product', 'Pricelist Nutrimart' : 'Price List NFI', 'Harga jua Homdel' : 'Harga Display'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip()\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "    product_order['title'] = product_order['title'].astype(str)\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "#     data_order = data_order[~data_order['product'].astype(str).isin(['2102500336 (CS)'])]\n",
    "#     data_order = data_order.reset_index(drop = True)\n",
    "    \n",
    "#     data_order = data_order[~data_order['product'].astype(str).isin(['2102500320 (CI160)'])]\n",
    "#     data_order = data_order.reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    \n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Surabaya'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    #     for i in range(data_order.shape[0]):\n",
    "    #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    #         else :\n",
    "    #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "        indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "        temp = data_order.iloc[indeks].copy()\n",
    "        product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "#         if len(product) != 0:\n",
    "#             temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "#             data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        index = order_all[order_all['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        order_all['SKU'][index] = '2306592173'\n",
    "        order_all['Real SKU'][index] = '2306592173'\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Price' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "        \n",
    "        \n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500320 (CI160)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        \n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "        \n",
    "        order_all['Selling Price'] = order_all['Regular Price'].astype(int)\n",
    "        \n",
    "        data_SKU3 = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "        data_SKU3 = data_SKU3.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "        data_SKU3['SKU'] = data_SKU3['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "        data_SKU3 = data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0'][data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0']['Harga Coret'].notnull()]\n",
    "        data_SKU3['product'] = data_SKU3['product'].str.strip()\n",
    "        data_SKU3 = data_SKU3.reset_index(drop = True)\n",
    "        \n",
    "        for i in range(data_SKU3.shape[0]):\n",
    "            if data_SKU3['SKU'][i] in order_all['SKU'].values:\n",
    "                indeks = order_all[order_all['SKU'].astype(str) == i].index.to_list()\n",
    "                order_all['Regular Price'][indeks] = data_SKU3['Harga Display'][i]\n",
    "                order_all['Selling Price'][indeks] = data_SKU3['Harga Coret'][i]\n",
    "        \n",
    "        \n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Order Online Surabaya Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "         'Product Name',\n",
    "         'Customer Name',\n",
    "         'Phone',\n",
    "         'Address',\n",
    "         'Region',\n",
    "         'City',\n",
    "         'Zip Code',\n",
    "         'payment_status',\n",
    "         'Regular Price',\n",
    "         'Shipping Courier',\n",
    "         'Shipping Cost',\n",
    "         'Subtotal',\n",
    "         'Qty. Invoiced',\n",
    "         'SKU',\n",
    "         'Order #',\n",
    "         'Invoice Number',\n",
    "         'Shipping Name',\n",
    "         'Shipping Address2',\n",
    "         'Country',\n",
    "         'AWB',\n",
    "         'Channel',\n",
    "         'Order date',\n",
    "         'Real SKU',\n",
    "         'Real Nama Produk',\n",
    "         'Brand',\n",
    "         'Sub Brand',\n",
    "         'Parent Item',\n",
    "         'Parent SKU',\n",
    "         'Produk 1',\n",
    "         'SKU Produk 1',\n",
    "         'PCS Produk 1',\n",
    "         'Price List NFI 1',\n",
    "         'Subtotal Produk 1',\n",
    "         'Harga Display 1',\n",
    "         'Harga Cost 1',\n",
    "         'Harga Organik 1',\n",
    "         'Produk 2',\n",
    "         'SKU Produk 2',\n",
    "         'PCS Produk 2',\n",
    "         'Price List NFI 2',\n",
    "         'Subtotal Produk 2',\n",
    "         'Harga Display 2',\n",
    "         'Harga Cost 2',\n",
    "         'Harga Organik 2',\n",
    "         'Produk 3',\n",
    "         'SKU Produk 3',\n",
    "         'PCS Produk 3',\n",
    "         'Price List NFI 3',\n",
    "         'Subtotal Produk 3',\n",
    "         'Harga Display 3',\n",
    "         'Harga Cost 3',\n",
    "         'Harga Organik 3',\n",
    "         'Produk 4',\n",
    "         'SKU Produk 4',\n",
    "         'PCS Produk 4',\n",
    "         'Price List NFI 4',\n",
    "         'Subtotal Produk 4',\n",
    "         'Harga Display 4',\n",
    "         'Harga Cost 4',\n",
    "         'Harga Organik 4',\n",
    "         'Produk 5',\n",
    "         'SKU Produk 5',\n",
    "         'PCS Produk 5',\n",
    "         'Price List NFI 5',\n",
    "         'Subtotal Produk 5',\n",
    "         'Harga Display 5',\n",
    "         'Harga Cost 5',\n",
    "         'Harga Organik 5',\n",
    "         'Produk 6',\n",
    "         'SKU Produk 6',\n",
    "         'PCS Produk 6',\n",
    "         'Price List NFI 6',\n",
    "         'Subtotal Produk 6',\n",
    "         'Harga Display 6',\n",
    "         'Harga Cost 6',\n",
    "         'Harga Organik 6',\n",
    "         'Produk 7',\n",
    "         'SKU Produk 7',\n",
    "         'PCS Produk 7',\n",
    "         'Price List NFI 7',\n",
    "         'Subtotal Produk 7',\n",
    "         'Harga Display 7',\n",
    "         'Harga Cost 7',\n",
    "         'Harga Organik 7',\n",
    "         'Bundle Flag',\n",
    "         'Date',\n",
    "         'Month',\n",
    "         'Year',\n",
    "         'Quarter',\n",
    "         'Week',\n",
    "         'True datetime',\n",
    "         'Total',\n",
    "         'Price List NFI',\n",
    "         'Total Net',\n",
    "         'Selling Price',\n",
    "         'Kecamatan',\n",
    "         'Kelurahan',\n",
    "         'Bundle Name',\n",
    "         'Harga Cost',\n",
    "         'Total Harga Cost',\n",
    "         'Seller Discount',\n",
    "         'Shipping',\n",
    "         'Promo',\n",
    "         'Discount MC',\n",
    "         'Warehouse Name',\n",
    "         'Customer Email',\n",
    "         'Order Status',\n",
    "         'Payment Channel',\n",
    "         'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_jatim = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_jkt:\n",
    "    import pandas as pd \n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_jkt')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"nutrimart.nfi@gmail.com\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"sumselhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(20)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "    product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch')\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Unnamed: 0' : 'SKU', 'ref.1' : 'product', 'Pricelist Nutrimart' : 'Price List NFI', 'Harga jua Homdel' : 'Harga Display'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip()\n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 264000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate (12sch)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 33000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria (40 sch)', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml', 82000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)', 94000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 Sch)', 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Platinum Choco Latte Dus 6 sch\", 80000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 104000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 75000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 42500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Es Cincau 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 180400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo Es Ketan Hitam 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Nipis (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Lemon (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Sweet Mango (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate 12 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Crunch BBQ Beef (20gr)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Chocolate Taro (10 sch)', 11000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Markisa (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)', 67500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Avocado Coffee 4 Sch x 2', 18200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Cocopandan 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sambal Terasi 200 gr', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lemon Tea 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Vanilla 750gr', 102300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo RTD Kacang Hijau 200ml (6pcs)', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Chocolate 250gr', 29150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Milky Orange (40sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 28900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)', 52000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Vanilla 500gr', 66000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Jahe 50 sch', 38500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Gold Plain (Original) 750gr\", 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Vanilla Vegiberi 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal 300gr', 104500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Honey 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Garlic Butter Cookies 5 Sch', 20400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 211200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-MEN Gain Mass Taro 225 gr', 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Chocolate 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sunflower Oil 946 ml', 57200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Whey Daily Dark Chocolate 250gr\", 49500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Vanilla 200gr', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Chocolate 1000 gr', 136400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - W'Dank Empon Empon 10 Sachet Renceng\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Banana 225gr', 60500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo RTD Kacang Hijau 200 ml', 4950]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate', 8800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(FREE) W'Dank Empon-Empon 10 sch\", 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Khusus Homdel - HiLo Chocolate Banana 10 sch', 11000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Strawberry 40 Sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Vanila Vegiberi 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Saus Tiram 200ml', 39600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Shirataki Noodles 71gr', 28100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Vanila Vegiberi 200ml', 6100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Saus Tiram 200ml', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Noodles 71gr', 14100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari American Sweet Orange (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Kurma Pack (4R)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Milky Orange (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Chocolate (10 sch)', 11000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Swiss Chocolate (10 sch) Renceng', 16500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Leci 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Sweet Guava (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Hilo - Lebaran Edition', 56100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ramadhan NutriSari 7 Rasa (7 x 10 sch)', 294000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Peras (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Lebaran Tropicana Slim', 96300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Lokalate untuk Sobatku - Idul Fitri Edition', 54120]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - SUGAR FREE', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Florida Orange (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo RTD Milky Brown Sugar 200 ml', 4950]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Belgian Chocolate (10 sch)', 41800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Mangga Gandaria (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Asin 200 ml', 23650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Apel Jeruk 40 Sachet', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Minyak Jagung 1lt', 69300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Coffee Tiramisu 200ml (6pcs) - Ready to Drink', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Madu Jeruk 40'sachet (4 Renceng)\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen RTD Coffee Tiramisu 200ml', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Chocolate 500gr', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Mayonnaise 200 g x 2', 34800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs', 22600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Mayonnaise 200 g - Bantu Dukung Hidup Sehat', 17400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD)', 5650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Baru! NutriSari NUTRI C1000 Jeruk 40 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: L-Men Daily Popcorn Caramel 250gr x 2', 78300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Daily Popcorn Caramel 250gr', 39150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE HiLo Joint Plus 140gr', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak Jeruk Bali 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False) \n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Tape Ketan 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False) \n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Korean Goguma Cookies (5 Sch) x 2', 32200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 6850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Andaliman 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Plain 1000 gr', 128200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Mas Kaka yang Banyak Akal', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla Vegiberi 500gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Vanilla Caramel 500gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari NUTRI C1000 Jeruk 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Joint Plus Orange 140 gram x 2', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Popcorn Caramel 500 gram - Susu Tinggi Kalsium Lebih Rendah Lemak', 68600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo School Strawberry Cheesecake 500 gram x 2', 110600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Yuzu Orange 40 sch', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Jeju [40 Sachet]', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Strawberry Cheesecake 500 gram', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Andaliman 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Masak Sehat', 125000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200ml', 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Santan 5 sachet', 15400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Tape Ketan 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml (4pcs)', 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml', 5750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ngemil Sehat', 125000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 21200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD)', 7500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - SUGAR FREE', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese Cookies', 21200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['2102900319 (D)', 82500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['2102500336 (classic stick)', 46900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Maroko (40 Sch) FREE Lokalate Andaliman (10 Sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Nutty Chocolate Cookies 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak (4R)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Maroko (40 sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Andaliman 10 Sachet', 13600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 750gr', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Yoghurt Smoothie Bowl Strawberry (8 sch)', 62900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate Ready To Drink (4 tetrapack)', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Teen Chocolate Ready To Drink Susu [4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Coklat 200ml', 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen RTD Coklat 200ml', 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Almond Milk Coconut 200gr x 2', 70000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate x 4 pcs', 38400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Almond Milk Coconut 200gr', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate', 9600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea Ready to Drink 200ml x 4pcs', 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo RTD Thai Tea 200ml', 5750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bajigur (10 sch)\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bandrek 10 sachet Renceng\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Milky Brown Sugar Ready To Drink 200ml (4 Tetrapack)', 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Vanilla Vegiberi Ready To Drink Susu [200ml/4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo RTD Milky Brown Sugar 200 ml\", 5725]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School RTD Vanila Vegiberi 200ml\", 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Chocolate Candy (10 sch)\", 18300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102500320 (CI160)\", 72160]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 1000 gr', 141900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack: Tropicana Slim Klepon Cookies (5 Sch)', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Klepon Cookies (5 Sch)', 16700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Nipis Jahe 40 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Shirataki Rice 72 g', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Rice 72 g', 25000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Leci 750ml', 30900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Mango Smoothie 200ml (4 Pcs)', 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari RTD Mango Smoothie 200 ml', 6900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Es Teler 175gr', 26300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Platinum Swiss Chocolate 420gr', 91500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Kuwud Nipis', 37500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Classic Refill 500gr', 104100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Bundle - HiLo Teen Taro 500gr & HiLo Teen Strawberry Milkshake 500g', 127200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo School Bubble Gum 500g', 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HILO ALMOND MILK COCONUT 12DX200G', 51500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 80100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) HiLo School RTD Coklat 200ML', 6900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Strawberry Milkshake 500g', 75500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener I Sweet', 25200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Pisang Bakar 10 sch', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Pisang Bakar Epe 10 sch', 8750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla Vegiberi 750gr', 116700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Coffee Milk Pillow Bag (2 sch)', 10300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea Refill 500 gram', 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Cookies Paket Hampers Idul Fitri Parcel Lebaran', 131600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Lemon-C (25 sch)', 25200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim High Fiber High Calcium Milk Chocolate 500gr', 116700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lemon Tea 500 gram', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Peras Refill 500 gr', 37800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['LOKALATE KOPI PISANG BAKAR EPE', 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 - Tropicana Slim Mint Cocoa - Minuman Cokelat Mint Nikmat Tanpa Gula Pasir', 20000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Es Pisang Ijo 10 Sch x 2 pcs', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ '(Near ED)L-Men Platinum Kacang Hijau 800g', 158750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'L-Men Platinum Choco Latte 800 gr - Near ED', 164500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'NutriSari RTD Jeruk Madu 200 ml', 6000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'NutriSari Jeruk Manis 500gr', 38100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'L-Men Gain Mass Mangga 500gr', 133900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Avocado Chocolate (10 Sch)', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo White Chocolate (10 Sch)', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Diabetamil Milk Vanilla 150 gram', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Buy 1 Get 1 FREE Tropicana Slim Susu Low Fat Macchiato Coffee 500gr', 143000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Active Chocolate 1000 gr', 121200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Joint Plus Orange 140 gram', 38700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Teen Biscuit Caramel 500gr', 65000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Active Caramel Latte 500g', 65800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12DX500G', 76200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo School Bubble Gum 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "    product_order['title'] = product_order['title'].astype(str)\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    indeks\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Jakarta'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    #     for i in range(data_order.shape[0]):\n",
    "    #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    #         else :\n",
    "    #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "        indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "        temp = data_order.iloc[indeks].copy()\n",
    "        product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "#             if len(product) != 0:\n",
    "#                 temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "#                 data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        index = order_all[order_all['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        order_all['SKU'][index] = '2306592173'\n",
    "        order_all['Real SKU'][index] = '2306592173'\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Price' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'].isin([\n",
    "#             '2102500336 (classic stick)', '2102500336 (CS)', '2102900319 (D)'\n",
    "#         ])].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        order_all = order_all.reset_index()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        #order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        \n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Regular Price'].astype(int)\n",
    "\n",
    "        data_SKU3 = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "        data_SKU3 = data_SKU3.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "        data_SKU3['SKU'] = data_SKU3['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "        data_SKU3 = data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0'][data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0']['Harga Coret'].notnull()]\n",
    "        data_SKU3['product'] = data_SKU3['product'].str.strip()\n",
    "        data_SKU3 = data_SKU3.reset_index(drop = True)\n",
    "\n",
    "        for i in range(data_SKU3.shape[0]):\n",
    "            if data_SKU3['SKU'][i] in order_all['SKU'].values:\n",
    "                indeks = order_all[order_all['SKU'].astype(str) == i].index.to_list()\n",
    "                order_all['Regular Price'][indeks] = data_SKU3['Harga Display'][i]\n",
    "                order_all['Selling Price'][indeks] = data_SKU3['Harga Coret'][i]\n",
    "\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "        \n",
    "        order_all_append['True datetime'] = pd.to_datetime(order_all_append['True datetime'])\n",
    "\n",
    "        indeks = order_all_append[\n",
    "            (order_all_append['True datetime'] > pd.to_datetime('2021-02-28')) &\n",
    "            (order_all_append['Channel'] == 'Order Online Jakarta')\n",
    "        ].index.to_list()\n",
    "\n",
    "        order_all_append['Channel'][indeks] = 'Order Online Sumsel'\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_jkt = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_jateng:\n",
    "            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_jateng')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customer1@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"jatenghomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(15)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name), error_bad_lines=False, engine=\"python\")\n",
    "    \n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "#     data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Tropicana Slim Oat Drink 190 ml \\(RTD\\) x 4 pcs$', 'Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs (x1)')\n",
    "    data_order=data_order[data_order['product']!=\"2102500336 (CS)\"]\n",
    "    data_order=data_order.reset_index(drop=True)\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    product = product[product[0] != 'nan']\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"Rtd\", \"RTD\").str.replace('Turmeric 180gr', 'Turmeric (6 sch)').str.replace('L-Men Gainmass Taro 225gr', 'L-Men Gain Mass Taro 225 gr').str.replace('L-Men Lose Weight Chocolate Cereal (12sch)', 'L-Men Lose Weight Chocolate Cereal 300gr').str.replace(' (+kaos)', ' (+Kaos)', regex = False).str.replace('40 sch', '40sch', regex = False).str.replace('Coklat', 'Chocolate', regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"Rtd\", \"RTD\").str.replace('Turmeric 180gr', 'Turmeric (6 sch)').str.replace('L-Men Gainmass Taro 225gr', 'L-Men Gain Mass Taro 225 gr').str.replace('L-Men Lose Weight Chocolate Cereal (12sch)', 'L-Men Lose Weight Chocolate Cereal 300gr').str.replace(' (+kaos)', ' (+Kaos)', regex = False).str.replace('40 sch', '40sch', regex = False).str.replace('Coklat', 'Chocolate', regex = False)\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Platinum Swiss Chocolate 420gr', 91500, 91500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim White Coffee (4 sch)', 21200, 18400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-MEN Gain Mass Taro 225 gr', 58300, 58300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500ml', 85800, 85800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Peras Refill 500gr', 34300, 34300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500gr', 125800, 125800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Manis Refill 500gr', 37800, 37800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Roasted Sesame Mayonnaise 200g - Bantu Dukung Hidup Sehat', 22900, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Shirataki Rice 72 g', 50000, 50000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Nipis Jahe 40 Sachet', 62500, 35000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Chocolate 250g (Health & green Science Competition)', 38300, 38300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Kacang Hijau Ready to Drink 200ml (4 tetrapack)', 22900, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Shirataki Noodles 71gr', 9700, 9700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Kacang Hijau 200 ml', 2850, 2850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Brown Sugar 200 ml', 2550, 2550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HILO TEEN STRAWBERRY MILKSHAKEÂ\\xa0 12Dx500G', 66800, 66800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Cocopandan 40sch', 21300, 21300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Lemon Tea (40sch)', 42600, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Mayonnaise 200 g', 11450, 11450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Caramel Latte 500g', 95000, 50500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Cotton Candy 500g', 88400, 62500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Oat Drink 190ml (RTD)', 9999, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo school Bubble Gum 500g', 154000, 92400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 59400, 59400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 237600, 199000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 59400, 49500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230g - Bantu Dukung Hidup Sehat', 59400, 59400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HILO ALMOND MILK COCONUT 12Dx200G', 51500, 51500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Bubble Gum 500g', 80100, 80100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Lemon Tea 500 gram', 42000, 34300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Teen Biscuit Caramel 500gr', 92400, 65000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE L-Men Lose Weight Mango Sticky Rice 300gr', 290400, 145200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 - Tropicana Slim Mint Cocoa - Minuman Cokelat Mint Nikmat Tanpa Gula Pasir', 40000, 20000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Es Pisang Ijo 10 sch x 2 pcs', 35000, 17500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NuTrilogi Seri Mas Kaka yang Banyak Akal', 70000, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE Tropicana Slim Susu Low Fat Macchiato Coffee 500gr', 257400, 143000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Lokalate Kopi Pisang Bakar 10 sch', 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Choco Series Paket Hampers Idul Fitri Parcel Lebaran', 185300, 139600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Brownies Instant Powder Cake Mix 230g - Bantu Dukung Hidup Sehat', 31200, 31200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Soy Latte - Kopi Plant Based Rendah Gula', 81800, 36900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 75000, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Taro 500gr - Khusus Homdel', 80800, 40400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Jeruk Madu 200 ml (4 tetrapack)', 24000, 24000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Bandrek 10 sachet Renceng - Khusus Homdel\", 17300, 8650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Empon-Empon 10 sch - Khusus Homdel\", 15000, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g\", 161600, 80800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 500 gram - Tinggi Vitamin A Lebih Rendah Gula\", 59400, 44400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "#     product_order = product_order.append(pd.DataFrame([['HiLo school Chocolate 250g (Health & green Science Competition)', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Jateng'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102900319 (D)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500320 (CI160)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "        \n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "        \n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        #order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "        \n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "        \n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_jateng = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_bali:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_bali')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customerbali@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"balihomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "    time.sleep(15)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    time.sleep(5)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(15)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\")\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\")\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 500gr', 38300, 38300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)Tropicana Slim Extra Virgin Olive Oil 500 ml', 42900, 42900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Active Vanilla 500gr', 32600, 32600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Gold Plain (Original) 500gr', 36600, 36600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Teen Chocolate 750gr', 55500, 55500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 750gr', 55500, 55500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Gain Mass Chocolate 500gr', 62900, 62900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Platinum Choco 800 gr - Near ED', 157300, 157300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Teen Chocolate 500gr', 38300, 38300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Brown Sugar 200 ml', 2574, 2574]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Thai Tea 200ml - Near ED', 2860, 2860]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "#     s = requests.Session()\n",
    "#     s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "#     s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "#     r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "#     with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "#         output.write(r.content)\n",
    "\n",
    "#     if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "#         SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "#         SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "#         data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "#         data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "#     to_excel = data_SKU2.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Bali'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_bali = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_makasar :\n",
    "                    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_makasar')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customermakassar@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"makassarhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(20)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"Tropicana Slim Goldenmil Vanilla Turmeric 180gr\", 'Tropicana Slim Goldenmil Vanilla Turmeric (6 sch)')\n",
    "    data_order['product'] = data_order['product'].str.replace(\"NutriSari Mango Smoothie Ready to Drink Jus 200ml (6pcs)\", 'NutriSari Mango Smoothie 200ml (6pcs)', regex = False)\n",
    "    \n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    # data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    \n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    \n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Makassar'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500318 (CI)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "        \n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_makasar = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_medan:\n",
    "                        \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_medan')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customermedan@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"medanhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Tropicana Slim Oat Drink 190 ml \\(RTD\\) x 4 pcs$', 'Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs (x1)')\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men', case = False).str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"NutriSari Jeruk Nipis 40'sachet (4 Renceng)\", 'NutriSari Jeruk Nipis (40 sch)', regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"Tropicana Slim Sweetener Honey 50 sachet\", 'Tropicana Slim Sweetener Honey (50sch)', regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Teen Coklat 250gr\", 'HiLo Teen Chocolate 250gr', regex = False)\n",
    "    data_order.loc[data_order['product']=='HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12Dx500G','product']=\"HiLo Teen Strawberry Milkshake 500gr\"\n",
    "    \n",
    "\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men', case = False).str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Medan'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102900319 (D)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500320 (CI160)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "       \n",
    "        \n",
    "        \n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        #order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_medan = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_samarinda:\n",
    "                            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_samarinda')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customersamarinda@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"samarindahomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Samarinda'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "        data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_samarinda = True\n",
    "        \n",
    "if not order_online_lampung:\n",
    "                            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_lampung')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customerlampung@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"lampunghomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "    time.sleep(15)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[7]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch').str.replace('6 tetrapack', '6 Tetrapack').str.replace(\"Diabetx 100s\", \"Diabtx (100 sch)\").str.replace(\"Alpukat 10's\", \"Alpukat (10sch)\").str.replace(\"Kawista 10 sch\", \"Kawista (10sch)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch').str.replace('6 tetrapack', '6 Tetrapack').str.replace(\"Diabetx 100s\", \"Diabtx (100 sch)\").str.replace(\"Alpukat 10's\", \"Alpukat (10sch)\").str.replace(\"Kawista 10 sch\", \"Kawista (10sch)\")\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Lampung'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "#         data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_lampung = True\n",
    "        \n",
    "\n",
    "        \n",
    "if not order_online_pekanbaru:\n",
    "                            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_pekanbaru')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customerpekanbaru@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"pekanbaruhomdel1\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "    time.sleep(15)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(25)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order.loc[data_order['product']=='HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12Dx500G','product']=\"HiLo Teen Strawberry Milkshake 500gr\"\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "#     product.loc[product[1].isnull(),1]=\"1)\"\n",
    "    product.loc[product[0]==\"HiLo Teen Taro 500gr\",1]=\"1)\"\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "    data_order.loc[data_order['product']=='HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12Dx500G','product']=\"HiLo Teen Strawberry Milkshake 500gr\"\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Pekanbaru'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "#         data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_pekanbaru = True\n",
    "        # order_online_cond = True\n",
    "if not order_online_banjarmasin:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_banjarmasin')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"D:\\Masterdata\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"banjarmasinpromosi.nhd2022@gmail.com\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"nhdcuan\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "    time.sleep(15)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(25)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "    #         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "    #             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    #     product.loc[product[1].isnull(),1]=\"1)\"\n",
    "    product.loc[product[0]==\"HiLo Teen Taro 500gr\",1]=\"1)\"\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Banjarmasin'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "    #         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "    #         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "    #         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "    #         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "    #         data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_banjarmasin = True\n",
    "        order_online_cond = True\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_order['product'][indeks].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[(data_all['Channel']==\"Order Online Lampung\")&(data_all['Year']==2022)&(data_all['Month']=='February')][['Year','Month','Date','Order #','Real Nama Produk','Total Net','Total Net Before PPN']]#['Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[(data_all['Store']=='Order Online')&(data_all['Channel']=='Order Online Banjarmasin')]#['Channel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_order[data_order['SKU'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['Store'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lokalate Kopi Berondong 500 gram - Tinggi Vitamin A Lebih Rendah Gula'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_all[order_all['Regular Price'].isnull()]['Product Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_all[order_all['Harga Coret'].isnull()].drop_duplicates('Product Name')['Product Name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for n in [order_online_jatim,order_online_jkt,\n",
    "          order_online_jateng,order_online_bali,\n",
    "          order_online_makasar,order_online_samarinda,\n",
    "          order_online_medan,order_online_lampung,\n",
    "          order_online_pekanbaru,order_online_banjarmasin]:\n",
    "    print (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data_all.columns:\n",
    "#     print(i)\n",
    "    \n",
    "data_all.groupby(['Store','Warehouse Name'])['Order #'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_online_cond\n",
    "# shopee_scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_online_cond = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = data_all_aft_order.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopee_scrap#= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_name=['Brand_Portal-Business_Insights---Product_Analysis---Product_Performance-2021.12.21_2021.12.21(1).xlsx',\n",
    "                 'Brand_Portal-Business_Insights---Product_Analysis---Product_Performance-2021.12.20_2021.12.20(3).xlsx',\n",
    "                 'Brand_Portal-Business_Insights---Product_Analysis---Product_Performance-2021.12.19_2021.12.19(4).xlsx',\n",
    "                 'Brand_Portal-Business_Insights---Product_Analysis---Product_Performance-2021.12.18_2021.12.18(4).xlsx']\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_name #= ['Brand_Portal-Business_Insights---Product_Analysis---Product_Performance-2021.09.25_2021.09.25.xlsx', 'Brand_Portal-Business_Insights---Product_Analysis---Product_Performance-2021.09.24_2021.09.24.xlsx', 'Brand_Portal-Business_Insights---Product_Analysis---Product_Performance-2021.09.23_2021.09.23(2).xlsx', 'Brand_Portal-Business_Insights---Product_Analysis---Product_Performance-2021.09.22_2021.09.22(2).xlsx', 'Brand_Portal-Business_Insights---Product_Analysis---Product_Performance-2021.09.21_2021.09.21(2).xlsx', 'Brand_Portal-Business_Insights---Product_Analysis---Product_Performance-2021.09.26_2021.09.26.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if order_online_cond :\n",
    "#     temp = data_all[data_all['Store'] == 'Order Online'].copy()\n",
    "#     temp['Selling Price'] = temp['Regular Price']\n",
    "#     temp['Subtotal'] = temp['Regular Price'].fillna(0).astype(str).str.strip().str.replace(',','').astype(float).astype(int) * temp['Qty. Invoiced']\n",
    "#     temp['Total'] = temp['Regular Price'].fillna(0).astype(str).str.strip().str.replace(',','').astype(float).astype(int) * temp['Qty. Invoiced']\n",
    "\n",
    "#     data_all = data_all[data_all['Store'] != 'Order Online']\n",
    "#     data_all = data_all.append(temp, ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'D:\\Masterdata\\SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU.to_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    if not shopee_scrap:\n",
    "        before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "        profile = webdriver.FirefoxProfile()\n",
    "        profile.set_preference(\"browser.download.dir\",os.getcwd() + str('\\\\Input Data'));\n",
    "        profile.set_preference(\"browser.download.folderList\",2);\n",
    "        profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/csv,application/excel,application/vnd.msexcel,application/vnd.ms-excel,text/anytext,text/comma-separated-values,text/csv,application/vnd.ms-excel,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet,application/octet-stream\");\n",
    "        profile.set_preference(\"browser.download.manager.showWhenStarting\",False);\n",
    "        profile.set_preference(\"browser.helperApps.neverAsk.openFile\",\"application/csv,application/excel,application/vnd.msexcel,application/vnd.ms-excel,text/anytext,text/comma-separated-values,text/csv,application/vnd.ms-excel,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet,application/octet-stream\");\n",
    "        profile.set_preference(\"browser.helperApps.alwaysAsk.force\", False);\n",
    "        profile.set_preference(\"browser.download.manager.useWindow\", False);\n",
    "        profile.set_preference(\"browser.download.manager.focusWhenStarting\", False);\n",
    "        profile.set_preference(\"browser.download.manager.alertOnEXEOpen\", False);\n",
    "        profile.set_preference(\"browser.download.manager.showAlertOnComplete\", False);\n",
    "        profile.set_preference(\"browser.download.manager.closeWhenDone\", True);\n",
    "        profile.set_preference(\"pdfjs.disabled\", True);\n",
    "\n",
    "        driver = webdriver.Firefox(firefox_profile= profile)\n",
    "\n",
    "\n",
    "        # driver.fullscreen_window()\n",
    "        driver.get(\"https://brandportal.shopee.com/seller/login\")\n",
    "\n",
    "        driver.set_context(\"chrome\")\n",
    "        win = driver.find_element_by_tag_name(\"html\")\n",
    "        win.send_keys(Keys.CONTROL + \"-\")\n",
    "        win.send_keys(Keys.CONTROL + \"-\")\n",
    "        win.send_keys(Keys.CONTROL + \"-\")\n",
    "        win.click()\n",
    "\n",
    "        driver.set_context(\"content\")\n",
    "        username = driver.find_element_by_id(\"email\")\n",
    "        username.clear()\n",
    "        username.send_keys(\"muhammad.diko@nutrifood.co.id\")\n",
    "\n",
    "        password = driver.find_element_by_id(\"password\")\n",
    "        password.send_keys(\"IDnutrimart%1\")\n",
    "        password.click()\n",
    "\n",
    "        driver.find_element_by_class_name(\"ant-btn\").click()\n",
    "\n",
    "        time.sleep(15) \n",
    "#         driver.find_element_by_xpath('//*[@id=\"Product Analysis$Menu\"]/li').click()\n",
    "        driver.find_element_by_xpath('/html/body/div/section/section/aside/div/ul/li[2]/ul/li').click()\n",
    "\n",
    "        all_file_name = []\n",
    "\n",
    "        for i in range(2,7):\n",
    "            before = os.listdir(os.getcwd() + '/Input Data')\n",
    "#             driver.find_element_by_xpath('//*[@id=\"Product Analysis$Menu\"]/li').click()\n",
    "            driver.find_element_by_xpath('/html/body/div/section/section/aside/div/ul/li[2]/ul/li').click()\n",
    "    \n",
    "            time.sleep(10) \n",
    "            date = (datetime.today()-timedelta(days = i)).strftime('%Y-%m-%d')\n",
    "            datefield = driver.find_element_by_xpath('/html/body/div[1]/section/section/section/main/div/div[2]/div/div[2]/div/div/div[1]/div[5]/span')\n",
    "            datefield.click()\n",
    "            time.sleep(2) \n",
    "            from selenium.webdriver.common.action_chains import ActionChains\n",
    "            men_menu = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH, \"/html/body/div[2]/div/div/div/div[1]/div[5]/div\")))\n",
    "            ActionChains(driver).move_to_element(men_menu).perform()\n",
    "            driver.find_element_by_xpath(\"/html/body/div[2]/div/div/div/div[1]/div[5]/div\").click()\n",
    "            print(str(date))\n",
    "            xpath_date = '//*[@title=\"' + str(date) + '\"]'\n",
    "        #             print(len(driver.find_elements_by_xpath(xpath_date)))\n",
    "            if len(driver.find_elements_by_xpath(xpath_date)) != 0:\n",
    "                driver.find_element_by_xpath(xpath_date).click()\n",
    "            else :\n",
    "                driver.find_element_by_xpath('/html/body/div[2]/div/div/div/div[2]/div/div/div[1]/button[2]').click()\n",
    "                driver.find_element_by_xpath(xpath_date).click()\n",
    "            time.sleep(5)\n",
    "            submit = driver.find_element_by_xpath('/html/body/div[1]/section/section/section/main/div/div[2]/div/div/div/div/div[2]/button[2]')\n",
    "            submit.click()\n",
    "            time.sleep(5)\n",
    "            driver.find_element_by_xpath('/html/body/div[1]/section/section/section/main/div/div[2]/div/div/div/div/div[2]/button[3]').click()\n",
    "            time.sleep(25)\n",
    "            after = os.listdir(os.getcwd() + '/Input Data')\n",
    "            change = set(after) - set(before)\n",
    "            if len(change) == 1:\n",
    "                file_name = change.pop()\n",
    "            else:\n",
    "                print(\"More than one file or no file downloaded\")\n",
    "            all_file_name.append(file_name)\n",
    "\n",
    "        time.sleep(5) \n",
    "        before = os.listdir(os.getcwd() + '/Input Data')\n",
    "        datefield = driver.find_element_by_xpath('/html/body/div[1]/section/section/section/main/div/div[2]/div/div[2]/div/div/div[1]/div[5]/span')\n",
    "        datefield.click()\n",
    "\n",
    "        from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "        men_menu = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, \"/html/body/div[2]/div/div/div/div[1]/div[1]\")))\n",
    "        ActionChains(driver).move_to_element(men_menu).perform()\n",
    "\n",
    "        time.sleep(5)\n",
    "        driver.find_element_by_xpath(\"/html/body/div[2]/div/div/div/div[1]/div[1]\").click()\n",
    "\n",
    "        time.sleep(5)\n",
    "        submit = driver.find_element_by_xpath('/html/body/div[1]/section/section/section/main/div/div[2]/div/div/div/div/div[2]/button[2]')\n",
    "        submit.click()\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        driver.find_element_by_xpath('/html/body/div[1]/section/section/section/main/div/div[2]/div/div/div/div/div[2]/button[3]').click()\n",
    "\n",
    "        time.sleep(15)\n",
    "        after = os.listdir(os.getcwd() + '/Input Data')\n",
    "        change = set(after) - set(before)\n",
    "        if len(change) == 1:\n",
    "            file_name = change.pop()\n",
    "        else:\n",
    "            print(\"More than one file or no file downloaded\")\n",
    "\n",
    "        all_file_name.append(file_name)\n",
    "        shopee_scrap = True\n",
    "    \n",
    "    \n",
    "    print(all_file_name)\n",
    "    shopee = pd.DataFrame()\n",
    "\n",
    "    for i in all_file_name:\n",
    "        print(i)\n",
    "        temp = pd.read_excel(r'Input Data/' + str(i), sheet_name = 'Product Performance Item Level')\n",
    "        if '(' in i :\n",
    "            date = pd.to_datetime(str(i).split('(')[-2].split('_')[-1].replace('.xlsx',''))\n",
    "        else :\n",
    "            date = pd.to_datetime(str(i).split('_')[-1].replace('.xlsx',''))\n",
    "        temp['Order Date'] = date\n",
    "        temp['Paid Date'] = date\n",
    "        shopee = shopee.append(temp, ignore_index = True, sort = False)\n",
    "   \n",
    "    sku_shopee = pd.read_excel(r'SKU_File/shopee_sku_mapping.xlsx')\n",
    "    shopee['Real SKU'] = np.nan\n",
    "    shopee['Real SKU'] = shopee.merge(sku_shopee[['item ID Shopee', 'real sku']].drop_duplicates('item ID Shopee'), how = 'left', left_on = 'Product ID', right_on = 'item ID Shopee')['real sku']\n",
    "\n",
    "    shopee = shopee[shopee['Gross Units Sold'] != 0]\n",
    "    shopee = shopee[shopee['Name'] != '[Gift] Beras Mawar Jaya 1kg']\n",
    "    shopee = shopee[shopee['Name'] != '[Special Promo] Minyak 1 lt']\n",
    "    cond_miss = False\n",
    "    if len(shopee) != 0:\n",
    "        miss = shopee[shopee['Real SKU'].isnull()]\n",
    "        miss_append = shopee[~shopee['Real SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]\n",
    "        miss  = miss.append(miss_append, ignore_index = True, sort = False)\n",
    "        if len(miss) > 0:\n",
    "            print('Alert SKU Missing')\n",
    "            miss[['URL', 'Product ID', 'Name']].drop_duplicates().to_excel(r'Alert Shopee Missing.xlsx')\n",
    "            cond_miss = True\n",
    "        else :\n",
    "            shopee['Sales Order ID'] = 'Shopee Brand Portal'\n",
    "            shopee['Channel Order ID'] = 'Shopee Brand Portal'\n",
    "            shopee['Customer Name'] = 'Shopee Brand Portal'\n",
    "#             shopee['Order Date'] = date\n",
    "#             shopee['Paid Date'] = date\n",
    "            shopee['Status'] = 'Delivered'\n",
    "            shopee['Channel'] = \"Shopee\"\n",
    "            shopee['Store'] = \"Shopee\"\n",
    "            shopee['Currency Code'] = \"IDR\"\n",
    "            shopee['Warehouse Name'] = 'Shopee Warehouse'\n",
    "            shopee['Net Sales(Rp)'] = shopee['Net Sales(Rp)'].astype(float)\n",
    "            shopee['Net Units Sold'] = shopee['Net Units Sold'].astype(float)\n",
    "            shopee['Regular Price'] = shopee['Net Sales(Rp)'] / shopee['Net Units Sold']\n",
    "            shopee['Selling Price'] = shopee['Net Sales(Rp)'] / shopee['Net Units Sold']\n",
    "            shopee['Sub Total'] = shopee['Net Sales(Rp)']\n",
    "            shopee['Gross Sales'] = shopee['Net Sales(Rp)']\n",
    "            shopee['Shopee Order'] = shopee['Net Orders']\n",
    "            shopee['Shopee Cust'] = shopee['Net # of Unique Buyers']\n",
    "\n",
    "            shopee = shopee.rename(columns = {'Real SKU' : 'SKU', 'Name' : 'Item Name',  'Net Units Sold' : 'Quantity'})\n",
    "\n",
    "            shopee_master = shopee.copy()\n",
    "            shopee_master = shopee_master[['Sales Order ID', 'Channel Order ID', 'Customer Name', 'Order Date', 'Paid Date','Status','Channel', 'Store', 'Currency Code', 'Warehouse Name', 'Regular Price', 'Selling Price',\n",
    "                          'Sub Total', 'Gross Sales', 'SKU', 'Item Name', 'Quantity', 'Shopee Order', 'Shopee Cust']]\n",
    "\n",
    "            print(\"Filling Brand ====== 5/10\")\n",
    "            shopee_master['SKU'] = shopee_master['SKU'].astype(str)\n",
    "            shopee_master['Item Name'] = shopee_master['Item Name'].astype(str)\n",
    "            data_SKU['Real SKU'] = data_SKU['SKU']\n",
    "            data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "            shopee_master = shopee_master.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "            shopee_master['Real SKU'] = shopee_master['Real SKU'].astype(str)\n",
    "            shopee_master = shopee_master.merge(data_SKU[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "            shopee_master = shopee_master.drop(['SKU_y'], axis = 1)\n",
    "            shopee_master = shopee_master.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "\n",
    "            print(\"Unbundling ====== 6/10\")        \n",
    "            # Forstok Unbundling    \n",
    "            list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "            shopee_master = shopee_master.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "            list_pcs = [x for x in shopee_master.columns if 'PCS' in x]\n",
    "            for i in list_pcs:\n",
    "                shopee_master[i] = shopee_master[i] * shopee_master['Quantity']\n",
    "            shopee_master = shopee_master.drop(['SKU_y'], axis = 1)\n",
    "            shopee_master = shopee_master.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "            indeks = shopee_master[shopee_master['Brand'] == 'Bundle'].index.to_list()\n",
    "            shopee_master['Bundle Flag'] = np.nan\n",
    "            shopee_master['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "            indeks = shopee_master[shopee_master['Brand'] == 'Bundle'][shopee_master[shopee_master['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "            shopee_master['SKU Produk 1'][indeks] = '(S)' + shopee_master['SKU Produk 1'][indeks].astype(str)\n",
    "            shopee_master['SKU Produk 2'][indeks] = '(S)' + shopee_master['SKU Produk 2'][indeks].astype(str)\n",
    "            shopee_master['SKU Produk 3'][indeks] = '(S)' + shopee_master['SKU Produk 3'][indeks].astype(str)\n",
    "            shopee_master['SKU Produk 4'][indeks] = '(S)' + shopee_master['SKU Produk 4'][indeks].astype(str)\n",
    "            shopee_master['SKU Produk 5'][indeks] = '(S)' + shopee_master['SKU Produk 5'][indeks].astype(str)\n",
    "            shopee_master['SKU Produk 6'][indeks] = '(S)' + shopee_master['SKU Produk 6'][indeks].astype(str)\n",
    "            shopee_master['SKU Produk 7'][indeks] = '(S)' + shopee_master['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "\n",
    "            print(\"Filling Date ====== 7/10\")\n",
    "            shopee_master['Date'] = np.nan\n",
    "            shopee_master['Month'] = np.nan\n",
    "            shopee_master['Year'] = np.nan\n",
    "\n",
    "            for i in range(shopee_master.shape[0]):\n",
    "#                 if int(shopee_master['Order Date'][i].strftime('%d')) < 12:\n",
    "#                     shopee_master['Date'][i] = pd.to_datetime(shopee_master['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "#                     shopee_master['Month'][i] = pd.to_datetime(shopee_master['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "#                     shopee_master['Year'][i] = pd.to_datetime(shopee_master['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "#                 else :\n",
    "                shopee_master['Date'][i] = pd.to_datetime(shopee_master['Order Date'][i]).day\n",
    "                shopee_master['Month'][i] = pd.to_datetime(shopee_master['Order Date'][i]).month_name()\n",
    "                shopee_master['Year'][i] = pd.to_datetime(shopee_master['Order Date'][i]).year\n",
    "\n",
    "            quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                    ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "            shopee_master = shopee_master.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "            shopee_master = shopee_master.drop(['Bulan'], axis = 1)\n",
    "            data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                    {'Bulan' : 'January' , 'Number': 1},\n",
    "                    {'Bulan' : 'February' , 'Number': 2},\n",
    "                    {'Bulan' : 'March' , 'Number': 3},\n",
    "                    {'Bulan' : 'April' , 'Number': 4},\n",
    "                    {'Bulan' : 'May' , 'Number': 5},\n",
    "                    {'Bulan' : 'June', 'Number': 6},\n",
    "                    {'Bulan' : 'July' , 'Number': 7},\n",
    "                    {'Bulan' : 'August', 'Number' : 8},\n",
    "                    {'Bulan' : 'September', 'Number' : 9},\n",
    "                    {'Bulan' : 'October' , 'Number': 10},\n",
    "                    {'Bulan' : 'November' , 'Number': 11}])\n",
    "            temp = shopee_master.copy()\n",
    "            temp['Day'] = temp['Date']\n",
    "            temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "            temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "            shopee_master['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "            temp['Hour'] = pd.to_datetime(shopee_master['Order Date']).dt.hour\n",
    "            temp['Minute'] = pd.to_datetime(shopee_master['Order Date']).dt.minute\n",
    "            temp['Second'] = pd.to_datetime(shopee_master['Order Date']).dt.second\n",
    "            shopee_master['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "            shopee_all = shopee_master.copy()\n",
    "            shopee_all['Total'] = shopee_all['Sub Total']\n",
    "            shopee_all['Price List NFI'] = np.nan\n",
    "            shopee_all['Total Net'] = np.nan\n",
    "\n",
    "            shopee_all = shopee_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                    'Status' : 'Order Status',\n",
    "                                                    'Order Date' : 'Order date',\n",
    "                                                    'Item Name' :'Product Name',\n",
    "                                                    'Bundle Name' : 'Bundle',\n",
    "                                                    'Shipping Country' : 'Country',\n",
    "                                                    'Shipping Province' : 'Region',\n",
    "                                                    'Shipping City' : 'City',\n",
    "                                                    'Shipping Zip' : 'Zip Code',\n",
    "                                                    'Shipping Address1' : 'Address',\n",
    "                                                    'Shipping Phone' : 'Phone',\n",
    "                                                    'Quantity' : 'Qty. Invoiced',\n",
    "                                                    'Item Price' : 'Regular Price',\n",
    "                                                    'Sub Total' : 'Subtotal'})\n",
    "\n",
    "            data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "            data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "            print(\"Unbundling\")\n",
    "            data_bundle1 = shopee_all[~shopee_all['Produk 1'].isnull()]\n",
    "            data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "            data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "            data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "            data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "            data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "            data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "            data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "            data_bundle2 = shopee_all[~shopee_all['Produk 2'].isnull()]\n",
    "            data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "            data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "            data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "            data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "            data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "            data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "            data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "            data_bundle3 = shopee_all[~shopee_all['Produk 3'].isnull()]\n",
    "            data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "            data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "            data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "            data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "            data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "            data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "            data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "            data_bundle4 = shopee_all[~shopee_all['Produk 4'].isnull()]\n",
    "            data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "            data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "            data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "            data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "            data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "            data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "            data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "            data_bundle5 = shopee_all[~shopee_all['Produk 5'].isnull()]\n",
    "            data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "            data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "            data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "            data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "            data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "            data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "            data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "            data_bundle6 = shopee_all[~shopee_all['Produk 6'].isnull()]\n",
    "            data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "            data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "            data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "            data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "            data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "            data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "            data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "            data_bundle7 = shopee_all[~shopee_all['Produk 7'].isnull()]\n",
    "            data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "            data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "            data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "            data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "            data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "            data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "            data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "            data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "            data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "            data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "            data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "            temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "            temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "            temp = temp.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "            indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "            data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "            data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "            data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "            data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "            data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "            data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "            print(\"Pricing\")\n",
    "            shopee_all = shopee_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "            shopee_all = shopee_all.merge(data_SKU[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(shopee_all.index)\n",
    "            shopee_all['Price List NFI_x'] = shopee_all['Price List NFI_x'].fillna(shopee_all['Price List NFI_y'])\n",
    "            shopee_all =  shopee_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "            shopee_all = shopee_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "            shopee_all['Price List NFI'] = pd.to_numeric(shopee_all['Price List NFI']).astype(int)\n",
    "            shopee_all['Harga Cost'] = pd.to_numeric(shopee_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "            shopee_all['Qty. Invoiced'] = pd.to_numeric(shopee_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "            shopee_all['Total Net'] = shopee_all['Price List NFI'] * shopee_all['Qty. Invoiced']\n",
    "            shopee_all['Total Harga Cost'] = shopee_all['Harga Cost'] * shopee_all['Qty. Invoiced']\n",
    "\n",
    "            shopee_all = shopee_all.reset_index(drop = True)\n",
    "            shopee_all['Order #'] = shopee_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "            list_bundle = shopee_all[shopee_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "            list_nobundle = shopee_all[shopee_all['Bundle Name'].notnull()]\n",
    "            list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "            list_nobundle\n",
    "\n",
    "            shopee_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "            shopee_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "            temp = shopee_all[shopee_all['Bundle Name'].notnull()]\n",
    "            temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "            temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "            temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "            shopee_all['Total'][temp.index] = temp['Total']\n",
    "            shopee_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "            shopee_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "            shopee_all['Order #'] = shopee_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "            shopee_all['True datetime'] = pd.to_datetime(shopee_all['True datetime'])\n",
    "            shopee_all['Promo'] = np.nan\n",
    "            shopee_all['Discount MC'] = np.nan\n",
    "\n",
    "    if not cond_miss:\n",
    "        temp = data_all[data_all['Order #'] == 'Shopee Brand Portal']\n",
    "        temp = temp.reset_index()\n",
    "        temp = temp[['Order #', 'Year', 'Month', 'Date', 'level_0']].merge(shopee_all[['Order #', 'Year', 'Month', 'Date']].drop_duplicates(['Year', 'Month', 'Date']), how = 'inner', on = ['Year', 'Month', 'Date']).set_index('level_0')\n",
    "\n",
    "        indeks = temp.index.to_list()\n",
    "        data_all = data_all.drop(indeks, axis = 0)\n",
    "        data_all = data_all.append(shopee_all, ignore_index = True, sort = False)\n",
    "        shopee_done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopee[shopee['Real SKU'].isnull()][['Product ID', 'Name', 'URL']].drop_duplicates().values\n",
    "miss[['URL', 'Product ID', 'Name']].drop_duplicates('Name').to_excel(r'Alert Shopee Miss.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[data_all['Store']=='Shopee']['True datetime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['True datetime'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nubi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nubi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nubi = pd.read_csv(\"D:\\Downloads\\Main_Sheet_(timo)_(2)_data(14).csv\")\n",
    "data_nubi[\"Year of Invoice Date SO\"].max()\n",
    "# data_nubi.head(5)\n",
    "data_nubi2=pd.read_csv(\"D:\\Downloads\\Main_Sheet_(timo)_(2)_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_nubi[data_nubi['Customer SO Group Area'].str.contains('ECOM RETAIL')]['Customer SO Group Area'].unique()\n",
    "# data_nubi[['Customer SO Group Area','Customer SO Parent Desc','Customer SO Desc']].drop_duplicates()\n",
    "baru=data_nubi2[data_nubi2['Customer SO Group Area'].str.contains('ECOM RETAIL')]['Customer SO Group Area'].unique()\n",
    "\n",
    "# data_nubi[(data_nubi['Customer SO Group Area'].str.contains('ECOM RETAIL'))]['Customer SO Group Area'].unique()\n",
    "# data_nubi[['Customer SO Group Area','Customer SO Parent Desc','Customer SO Desc']].drop_duplicates()\n",
    "data_nubi[(data_nubi['Customer SO Group Area'].str.contains('ECOM RETAIL'))&\n",
    "           ~(data_nubi['Customer SO Group Area'].isin(baru))]['Customer SO Group Area'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nubi2[data_nubi2['Customer SO Group Area'].str.contains('EMOS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nubi2[data_nubi2['Customer SO Group Area'].str.contains('ECOM RETAIL')]['Customer SO Group Area'].unique()\n",
    "data_nubi2[data_nubi2['Customer SO Group Area'].str.contains('BAYI NINJA')][['Year of Invoice Date SO','Month of Invoice Date SO']].drop_duplicates()#['Customer SO Group Area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nubi2[(data_nubi2[\"Year of Invoice Date SO\"]==2022)&(data_nubi2[\"Month of Invoice Date SO\"]=='June')][\"Day of Invoice Date SO\"].max()\n",
    "# data_nubi[(data_nubi[\"Year of Invoice Date SO\"]==2022)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Date ====== 7/10\n",
      "Filling Brand ====== 5/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:45: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Store</th>\n",
       "      <th>Currency Code</th>\n",
       "      <th>Warehouse Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Category</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Real SKU</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Sub Brand</th>\n",
       "      <th>Parent Item</th>\n",
       "      <th>Parent SKU</th>\n",
       "      <th>Price List NFI</th>\n",
       "      <th>Total</th>\n",
       "      <th>Total Net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sales Order ID, Order #, Customer Name, Order date, Paid Date, Order Status, Channel, Store, Currency Code, Warehouse Name, Regular Price, Selling Price, Subtotal, Gross Sales, SKU, Product Name, Qty. Invoiced, Date, Month, Year, True datetime, Week, Brand, Category, Quarter, Real SKU, Real Nama Produk, Sub Brand, Parent Item, Parent SKU, Price List NFI, Total, Total Net]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "data_all = data_all[data_all['Store Type'] != 'Retail Online']\n",
    "data_nubi = pd.read_csv(r\"D:\\Downloads\\Main_Sheet_(timo)_(2)_data.csv\")\n",
    "# data_nubi = data_nubi[~data_nubi['Customer SO Group Area'].astype(str).str.contains('E-COM')]\n",
    "# data_nubi = data_nubi[~data_nubi['Customer SO Group Area'].astype(str).str.contains('ECOM')]\n",
    "data_nubi = data_nubi[data_nubi['Customer SO Group Area'].astype(str).str.contains('ECOM RETAIL')]\n",
    "\n",
    "data_SKU = pd.read_excel(r'D:\\Masterdata\\SKU_File\\data_SKU.xlsx')\n",
    "\n",
    "# miss = data_nubi[~data_nubi['Product Code'].astype(str).isin(data_SKU['SKU'].astype(str))]\n",
    "data_nubi['Sales Order ID'] = 'Nubi -' + data_nubi['Customer SO Parent Desc'].astype(str)\n",
    "data_nubi['Channel Order ID'] = 'Nubi -' + data_nubi['Customer SO Parent Desc'].astype(str)\n",
    "data_nubi['Customer Name'] = 'Nubi Retail Online'\n",
    "\n",
    "print(\"Filling Date ====== 7/10\")\n",
    "\n",
    "data_nubi['Date'] = data_nubi['Day of Invoice Date SO']\n",
    "data_nubi['Month'] = data_nubi['Month of Invoice Date SO']\n",
    "data_nubi['Year'] = data_nubi['Year of Invoice Date SO']\n",
    "\n",
    "quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "        ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "data_nubi = data_nubi.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "data_nubi = data_nubi.drop(['Bulan'], axis = 1)\n",
    "data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "        {'Bulan' : 'January' , 'Number': 1},\n",
    "        {'Bulan' : 'February' , 'Number': 2},\n",
    "        {'Bulan' : 'March' , 'Number': 3},\n",
    "        {'Bulan' : 'April' , 'Number': 4},\n",
    "        {'Bulan' : 'May' , 'Number': 5},\n",
    "        {'Bulan' : 'June', 'Number': 6},\n",
    "        {'Bulan' : 'July' , 'Number': 7},\n",
    "        {'Bulan' : 'August', 'Number' : 8},\n",
    "        {'Bulan' : 'September', 'Number' : 9},\n",
    "        {'Bulan' : 'October' , 'Number': 10},\n",
    "        {'Bulan' : 'November' , 'Number': 11}])\n",
    "temp = data_nubi.copy()\n",
    "temp['Day'] = temp['Date']\n",
    "temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "data_nubi['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "data_nubi['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "\n",
    "data_nubi['Order Date'] = data_nubi['Day of Invoice Date SO']\n",
    "data_nubi['Paid Date'] = data_nubi['Day of Invoice Date SO']\n",
    "data_nubi['Status'] = 'Delivered'\n",
    "data_nubi['Channel'] = data_nubi['Customer SO Parent Desc']\n",
    "data_nubi['Store'] = data_nubi['Customer SO Group Area']\n",
    "data_nubi['Currency Code'] = \"IDR\"\n",
    "data_nubi['Warehouse Name'] = data_nubi['Customer SO Desc']\n",
    "data_nubi['Regular Price'] = data_nubi['Sales Value Netto SO'] / data_nubi['Sales Qty SO']\n",
    "data_nubi['Store Type'] = 'Retail Online'\n",
    "\n",
    "indeks = data_nubi[data_nubi['Regular Price'].isnull()].index.to_list()\n",
    "data_nubi['Regular Price'][indeks] = 0\n",
    "\n",
    "data_nubi['Selling Price'] = data_nubi['Sales Value Netto SO'] / data_nubi['Sales Qty SO']\n",
    "indeks = data_nubi[data_nubi['Selling Price'].isnull()].index.to_list()\n",
    "data_nubi['Selling Price'][indeks] = 0\n",
    "\n",
    "indeks = data_nubi[data_nubi['Sales Qty SO'] == 0].index.to_list()\n",
    "data_nubi['Selling Price'][indeks] = 0\n",
    "data_nubi['Regular Price'][indeks] = 0\n",
    "\n",
    "indeks = data_nubi[data_nubi['Sales Value Netto SO'] == 0].index.to_list()\n",
    "data_nubi['Selling Price'][indeks] = 0\n",
    "data_nubi['Regular Price'][indeks] = 0\n",
    "\n",
    "data_nubi['Sub Total'] = data_nubi['Sales Value Netto SO']\n",
    "data_nubi['Gross Sales'] = data_nubi['Sales Value Netto SO']\n",
    "\n",
    "data_nubi = data_nubi.rename(columns = {'Item Group Code' : 'SKU', 'Item Group' : 'Item Name', 'Sales Qty SO' : 'Quantity'})\n",
    "\n",
    "data_nubi = data_nubi[['Sales Order ID', 'Channel Order ID', 'Customer Name', 'Order Date', 'Paid Date','Status','Channel', 'Store', 'Currency Code', 'Warehouse Name', 'Regular Price', 'Selling Price',\n",
    "              'Sub Total', 'Gross Sales', 'SKU', 'Item Name', 'Quantity', 'Date', 'Month', 'Year', 'True datetime', \"Week\", 'Brand', 'Category']]\n",
    "\n",
    "data_nubi['Order Date'] = data_nubi['True datetime']\n",
    "data_nubi['Quarter'] = pd.to_datetime(data_nubi['True datetime']).dt.quarter\n",
    "\n",
    "print(\"Filling Brand ====== 5/10\")\n",
    "data_nubi['SKU'] = data_nubi['SKU'].astype(str)\n",
    "data_nubi['Item Name'] = data_nubi['Item Name'].astype(str)\n",
    "data_SKU['Real SKU'] = data_SKU['SKU']\n",
    "data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "# data_SKU['Price List NFI']=data_SKU['Price List NFI']*1.1/1.11 ###masih 10 % yaaa\n",
    "\n",
    "data_nubi = data_nubi.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "data_nubi['Real SKU'] = data_nubi['Real SKU'].astype(str)\n",
    "data_nubi = data_nubi.merge(data_SKU[['SKU', 'Sub Brand', 'Parent Item', 'Parent SKU','Price List NFI']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "data_nubi['Parent Item'] = data_nubi['Parent Item'].fillna(data_nubi['Item Name'])\n",
    "data_nubi = data_nubi.drop(['SKU_y'], axis = 1)\n",
    "data_nubi = data_nubi.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "indeks = data_nubi[data_nubi['Real SKU'].astype(str) == 'nan'].index.to_list()\n",
    "data_nubi['Real SKU'][indeks] = data_nubi['SKU'][indeks]\n",
    "\n",
    "indeks = data_nubi[data_nubi['Real Nama Produk'].astype(str) == 'nan'].index.to_list()\n",
    "data_nubi['Real Nama Produk'][indeks] = data_nubi['Item Name'][indeks]\n",
    "\n",
    "data_nubi['Sub Brand'] = data_nubi['Category']\n",
    "\n",
    "data_nubi['Total'] = data_nubi['Sub Total']\n",
    "data_nubi['Total Net'] = np.nan\n",
    "\n",
    "data_nubi = data_nubi.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                        'Status' : 'Order Status',\n",
    "                                        'Order Date' : 'Order date',\n",
    "                                        'Item Name' :'Product Name',\n",
    "                                        'Bundle Name' : 'Bundle',\n",
    "                                        'Shipping Country' : 'Country',\n",
    "                                        'Shipping Province' : 'Region',\n",
    "                                        'Shipping City' : 'City',\n",
    "                                        'Shipping Zip' : 'Zip Code',\n",
    "                                        'Shipping Address1' : 'Address',\n",
    "                                        'Shipping Phone' : 'Phone',\n",
    "                                        'Quantity' : 'Qty. Invoiced',\n",
    "                                        'Item Price' : 'Regular Price',\n",
    "                                        'Sub Total' : 'Subtotal'})\n",
    "\n",
    "\n",
    "\n",
    "# data_nubi['Price List NFI'] = data_nubi['Selling Price'] * 1.1\n",
    "temp = data_nubi[data_nubi['Price List NFI'].isnull()]\n",
    "skuoff=pd.read_excel('item gk tau harga.xlsx')\n",
    "skuoff=skuoff[['Real SKU','Price List NFI']]\n",
    "skuoff['Real SKU']=skuoff['Real SKU'].astype(str)#.info()\n",
    "display(temp[~temp['Real SKU'].isin(skuoff['Real SKU'].unique())])\n",
    "temp=temp.merge(skuoff,how='left',on='Real SKU').rename(columns=({'Price List NFI_y':'Price List NFI'}))\n",
    "data_nubi=data_nubi[data_nubi['Price List NFI'].notnull()].append(temp)\n",
    "\n",
    "\n",
    "data_nubi['Price List NFI'] = pd.to_numeric(data_nubi['Price List NFI']).astype(int)\n",
    "data_nubi['Qty. Invoiced'] = pd.to_numeric(data_nubi['Qty. Invoiced']).fillna(0).astype(int)\n",
    "\n",
    "data_nubi['Total Net'] = data_nubi['Price List NFI'] * data_nubi['Qty. Invoiced']\n",
    "\n",
    "data_nubi = data_nubi.reset_index(drop = True)\n",
    "\n",
    "data_nubi['True datetime'] = pd.to_datetime(data_nubi['True datetime'])\n",
    "data_nubi['Promo'] = np.nan\n",
    "data_nubi['Discount MC'] = np.nan\n",
    "data_nubi['Store Type'] = 'Retail Online'\n",
    "\n",
    "for i in data_nubi['Brand'].unique():\n",
    "    indeks = data_nubi[data_nubi['Brand'] == i].index.to_list()\n",
    "    if i == 'NUTRISARI':\n",
    "        data_nubi['Brand'][indeks] = 'NS'\n",
    "    elif i == 'HI LO':\n",
    "        data_nubi['Brand'][indeks] = 'HiLo'\n",
    "        \n",
    "temp = data_nubi[data_nubi['Store'] == 'WARUNG PINTAR DISTRIBUSI - BOGOR, PT'].copy()\n",
    "data_nubi = data_nubi[data_nubi['Store'] != 'WARUNG PINTAR DISTRIBUSI - BOGOR, PT']\n",
    "\n",
    "temp['Store'] = 'WARUNG PINTAR'\n",
    "temp['Channel'] = 'WARUNG PINTAR DISTRIBUSI, PT'\n",
    "temp['Warehouse Name'] = 'WARUNG PINTAR DISTRIBUSI - BOGOR, PT'\n",
    "\n",
    "data_nubi = data_nubi.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "indeks = data_nubi[data_nubi['Store'] == 'SHOPEE'].index.to_list()\n",
    "data_nubi['Store'][indeks] = 'Shopee Sell-In'\n",
    "\n",
    "# data_all = data_all.append(data_nubi, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nubi.to_excel(f\"D:\\Masterdata\\data_nubi\\data_nubi_{str(date.today())}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ini run\n",
    "data_all['Store'] = data_all['Store'].astype(str).str.replace('JD Indonesia - Nutrimart', 'JD Indonesia', regex = False)\n",
    "\n",
    "data_all = data_all[data_all['Store'].isin(['JD Indonesia', 'Lazada', 'Bukalapak', 'Blibli', 'Tokopedia',\n",
    "       'Shopee', 'Elevenia', 'Nutrimart', 'Order Online','Aladin Mall','TikTok'])]\n",
    "data_all = data_all.append(data_nubi, ignore_index = True, sort = False)\n",
    "\n",
    "indeks = data_all[data_all['Store'].isin(['JD Indonesia', 'Lazada', 'Bukalapak', 'Blibli', 'Tokopedia',\n",
    "       'Shopee', 'Elevenia','Aladin Mall','TikTok'])].index.to_list()\n",
    "data_all['Store Type'][indeks] = 'Marketplace'\n",
    "\n",
    "indeks = data_all[data_all['Store'].isin(['Nutrimart', 'Order Online'])].index.to_list()\n",
    "data_all['Store Type'][indeks] = 'Organic'\n",
    "\n",
    "indeks = data_all[data_all['Order #'].astype(str).str.contains('Nubi')].index.to_list()\n",
    "data_all['Store Type'][indeks] = 'Retail Online'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ini run juga\n",
    "indeks = data_all[data_all['Product Name'] == 'L-Men Bar Crunchy Chocolate (12sch)'].index.to_list()\n",
    "data_all['Real Nama Produk'][indeks] = 'L-Men Bar Crunchy Chocolate 12sch'\n",
    "data_all['Parent Item'][indeks] = 'L-Men Bar Crunchy Chocolate (12 Sch)'\n",
    "data_all['Brand'][indeks] = 'L-Men'\n",
    "data_all['Sub Brand'][indeks] = 'L-MEN POWDER'\n",
    "data_all['Real SKU'][indeks] = '2306592173'\n",
    "data_all['Parent SKU'][indeks] = '2306592173'\n",
    "\n",
    "indeks = data_all[data_all['Product Name'] == 'Heavenly Blush Yogurt Drink To Go Peach (1 pc)'].index.to_list()\n",
    "data_all['Brand'][indeks] = 'Heavenly Blush'\n",
    "\n",
    "indeks = data_all[data_all['Brand'] == 'HB'].index.to_list()\n",
    "data_all['Brand'][indeks] = 'Heavenly Blush'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['Region Group'] = np.nan\n",
    "\n",
    "index = data_all[data_all['Region'].isin(['Dki Jakarta', 'Banten'])].index.to_list()\n",
    "data_all['Region Group'][index] = 'Jabodetabek'\n",
    "\n",
    "list_city = ['Kota Bekasi', 'Kabupaten Bekasi', 'Kab. Bekasi', 'Kota Bogor', 'Kabupaten Bogor', 'Kab. Bogor', 'Kota Depok', 'Kota Tangerang',\n",
    "             'Kota Tangerang Selatan','Kabupaten Tangerang', 'Kab. Tangerang']\n",
    "\n",
    "index = data_all[data_all['City'].isin(list_city)].index.to_list()\n",
    "data_all['Region Group'][index] = 'Jabodetabek'\n",
    "\n",
    "data_all['Region Group'] = data_all['Region Group'].fillna(data_all['Region'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resellerdb=pd.read_excel(\"D:\\Masterdata\\Master File Reseller - Ecom & NHD.xlsx\")\n",
    "listemail=resellerdb[resellerdb['Email'].str.contains('@',na=False)]['Email'].unique()\n",
    "data_all.loc[data_all['Customer Email'].isin(listemail),'Customer Type']='Reseller'\n",
    "\n",
    "resellerdb['No HP Plain']=resellerdb['No HP'].str[2:]\n",
    "listphone=\"|\".join(resellerdb[resellerdb['No HP'].str.contains(\"62\",na=False)]['No HP Plain'].unique())\n",
    "data_all.loc[data_all['Phone'].str.contains(listphone,na=False),'Customer Type']='Reseller'\n",
    "\n",
    "kodelama=resellerdb[resellerdb['Kode Voucher Lama'].notnull()]['Kode Voucher Lama'].unique()\n",
    "kodebaru=resellerdb[resellerdb['Kode Voucher Baru'].notnull()]['Kode Voucher Baru'].unique()\n",
    "data_all.loc[data_all['Coupon Code'].isin(kodelama),'Customer Type']='Reseller'\n",
    "data_all.loc[data_all['Coupon Code'].isin(kodebaru),'Customer Type']='Reseller'\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.loc[data_all['Store']=='INDOPASIFIK TEKNOLOGI MED INDONESIA, PT','Store']='ECOM RETAIL - LIFEPACK'#[['Store','Channel','Warehouse Name']].drop_duplicates()\n",
    "data_all.loc[data_all['Store']=='EMOS','Store']='ECOM RETAIL - EMOS'\n",
    "data_all.loc[data_all['Store'].isin(['KREASI NOSTRA MANDIRI - BOGOR, PT','CIBINONG CENTER INDUSTRIAL ESTATE , PT']),'Store']='ECOM RETAIL - SAYUR BOX JAKARTA'\n",
    "data_all.loc[data_all['Store'].isin(['KREASI NOSTRA MANDIRI - SURABAYA, PT','KREASI TANI LAKSMI - SURABAYA, PT']),'Store']='ECOM RETAIL - SAYUR BOX SURABAYA'\n",
    "data_all.loc[data_all['Store'].isin(['ASTRO TECHNOLOGIES - TANGERANG, PT']),'Store']='ECOM RETAIL - ASTRO'\n",
    "data_all.loc[data_all['Store'].isin(['RITEL BERSAMA NASIONAL; PT']),'Store']='ECOM RETAIL - JD ID'\n",
    "data_all.loc[data_all['Store'].isin(['SAYUR BOX']),'Store']='ECOM RETAIL - SAYUR BOX JAKARTA'\n",
    "# data_all.loc[data_all['Store']=='INOVASI DIGITAL NIAGA - KALIDERES, PT','Store']='ECOM RETAIL - LIFEPACK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gedung Nutrimart', 'Gedung Nutrimart Pisangan'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year    Month      Warehouse Name  \n",
       "2021.0  April      Blibli Warehouse     7243.0\n",
       "        August     Blibli Warehouse     8012.0\n",
       "        December   Blibli Warehouse     8979.0\n",
       "        February   Blibli Warehouse     6362.0\n",
       "        January    Blibli Warehouse     6098.0\n",
       "        July       Blibli Warehouse    13082.0\n",
       "        June       Blibli Warehouse     8028.0\n",
       "        March      Blibli Warehouse    10670.0\n",
       "        May        Blibli Warehouse     6771.0\n",
       "        November   Blibli Warehouse     7837.0\n",
       "        October    Blibli Warehouse    10120.0\n",
       "        September  Blibli Warehouse     8128.0\n",
       "2022.0  April      Blibli Warehouse     6255.0\n",
       "        February   Blibli Warehouse     5753.0\n",
       "        January    Blibli Warehouse     7911.0\n",
       "        July       Blibli Warehouse       93.0\n",
       "        June       Blibli Warehouse     5282.0\n",
       "        March      Blibli Warehouse     5928.0\n",
       "        May        Blibli Warehouse     5933.0\n",
       "Name: Qty. Invoiced, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3170: DtypeWarning: Columns (23,35,57,60,74,80,81,87,88,94,95,101,110,122,123,134,135,136,138,153,156,157,158,167,168,172,173,174,175,176,194) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a done\n",
      "append done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "print('start')\n",
    "# data_all=pd.read_csv(r\"D:\\Masterdata\\Clean Data\\data_all_16 June With Order Onlinea.csv\", sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "# data_all['True datetime']=pd.to_datetime(data_all['True datetime'])\n",
    "# data_all['Real SKU']=data_all['Real SKU'].astype(str)\n",
    "\n",
    "b=data_all[(data_all['True datetime']>=\"2022-04-01\")]\n",
    "# print(b['True datetime'].min())\n",
    "# c=data_all[(data_all['Store Type']=='Retail Online')&(data_all['True datetime']>'2022-02-10')]\n",
    "# print(c['True datetime'].min())\n",
    "# a=data_all[(data_all['Store']!='Order Online')&(data_all['Store Type']!='Retail Online')]\n",
    "# print(a['True datetime'].max())\n",
    "# del(data_all)\n",
    "# print('b c done')\n",
    "\n",
    "\n",
    "data_all=pd.read_csv(r\"D:\\Masterdata\\Clean Data\\data_all_28 April With Order Online.csv\", sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "data_all['True datetime']=pd.to_datetime(data_all['True datetime'])\n",
    "data_all['Real SKU']=data_all['Real SKU'].astype(str)\n",
    "data_all.loc[(data_all['Store']=='Shopee')&(data_all['Year']==2022)&~(data_all['Customer Name'].str.contains('\\*')),'Warehouse Name']='Primary Warehouse'\n",
    "a=data_all[data_all['True datetime']<\"2022-04-01\"]\n",
    "# d=data_all[(data_all['Store']=='Order Online')&(data_all['True datetime']<\"2022-03-01\")]\n",
    "# print(d['True datetime'].max())\n",
    "# e=data_all[(data_all['Store Type']=='Retail Online')]\n",
    "# print(e['True datetime'].max())\n",
    "\n",
    "del(data_all)\n",
    "print('a done')\n",
    "data_all=a.append(b).reset_index(drop=True).sort_values(['True datetime'])\n",
    "data_all.loc[data_all['Store']=='Blibli','Warehouse Name']='Blibli Warehouse'\n",
    "print('append done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masuk=all_single['Store'].unique()\n",
    "data_all[(data_all['Year']==2022)&~(data_all['Store'].isin(masuk))]['Store'].unique()\n",
    "# ini yg udh masuk\n",
    "# data_all['Store'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export Master Data\n",
      "Filter Status\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31.]\n",
      "Prepare E-mailing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:766: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:779: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2022-04-01 00:00:00\n",
      "Last Date 2022-05-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:808: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2022-05-01 00:00:00\n",
      "Last Date 2022-06-01 00:00:00\n",
      "First Date 2022-06-01 00:00:00\n",
      "Last Date 2022-07-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:859: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:872: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2022-04-01 00:00:00\n",
      "Last Date 2022-05-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:901: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2022-05-01 00:00:00\n",
      "Last Date 2022-06-01 00:00:00\n",
      "First Date 2022-06-01 00:00:00\n",
      "Last Date 2022-07-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1129: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1131: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1133: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1242: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Data Finish\n",
      "Clean Data Non Nubi Finish\n",
      "Export Data 2020 Finish\n",
      "Prepare Emailing\n"
     ]
    }
   ],
   "source": [
    "print(\"Export Master Data\")\n",
    "\n",
    "index = data_all[\n",
    "    (pd.to_datetime(data_all['True datetime']) > '2020-09-11') &\n",
    "    (data_all['Real SKU'].astype(str) == '1101909453') \n",
    "].index.to_list()\n",
    "\n",
    "data_all['Real SKU'][index] = '1101909331'\n",
    "\n",
    "index = data_all[\n",
    "    (pd.to_datetime(data_all['True datetime']) > '2020-09-11') &\n",
    "    (data_all['Real SKU'].astype(str) == '1101569453') \n",
    "].index.to_list()\n",
    "\n",
    "data_all['Real SKU'][index] = '1101569326'\n",
    "\n",
    "index = data_all[\n",
    "    (pd.to_datetime(data_all['True datetime']) > '2020-09-11') &\n",
    "    (data_all['Real SKU'].astype(str) == '1101907453') \n",
    "].index.to_list()\n",
    "\n",
    "data_all['Real SKU'][index] = '1101907331'\n",
    "\n",
    "index = data_all[data_all['Real SKU'] == '(B) 2101656'].index.to_list()\n",
    "data_all['Real SKU'][index] = '(B)2101656'\n",
    "\n",
    "index = data_all[data_all['Real SKU'] == '(B)1101989453'].index.to_list()\n",
    "data_all['Brand'][index] = 'Bonus Produk'\n",
    "\n",
    "data_all.loc[data_all['SKU'].isin(['(U)2104115163', '(U)2101809250', '(U)2309005305', '(U)2101845443',\"(U)2101947250\"]),'Brand']='Bonus Produk'\n",
    "# data_all.loc[data_all['SKU']==\"2152051\",'SKU']='2152051110'\n",
    "# data_all.loc[data_all['SKU']==\"2152051\",'Real SKU']='2152051110'\n",
    "\n",
    "\n",
    "if 'Order Online' not in data_now:\n",
    "    data_now = data_now + ' With Order Online'\n",
    "SKU = pd.read_excel(r'SKU_File/data_SKU.xlsx')\n",
    "SKU_baru = pd.read_excel(r\"D:\\Downloads\\Subbrand Baru.xlsx\")\n",
    "\n",
    "SKU_final = SKU.copy()\n",
    "SKU_baru['Item Group Code'] = SKU_baru['Item Group Code'].astype(str).str.replace('.0','', regex = False)\n",
    "SKU_final['SKU Clean'] = SKU_final['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False)\n",
    "SKU_final = SKU_final.merge(SKU_baru.drop_duplicates('Item Group Code'), how = 'left', left_on = 'SKU Clean', right_on = 'Item Group Code')\n",
    "\n",
    "no_pair = SKU[SKU['SKU'].astype(str).isin(SKU_final[SKU_final['Category Baru'].isnull()]['SKU'].astype(str))]\n",
    "SKU_final = SKU_final[~SKU_final['SKU'].astype(str).isin(no_pair['SKU'].astype(str))]\n",
    "\n",
    "no_pair['SKU Clean'] = no_pair['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False).str.replace('E', '', regex = False)\n",
    "SKU_baru['Item Group Code'] = SKU_baru['Product Code'].astype(str).str.replace('.0','', regex = False)\n",
    "\n",
    "index = no_pair[no_pair['SKU'].astype(str) == '1101984451'].index[0]\n",
    "no_pair['SKU Clean'][index] = '1101984453'\n",
    "\n",
    "index = no_pair[no_pair['SKU'].astype(str) == '2104393210'].index[0]\n",
    "no_pair['SKU Clean'][index] = '2104392210'\n",
    "\n",
    "no_pair = no_pair.merge(SKU_baru.drop_duplicates('Product Code'), how = 'left', left_on = 'SKU Clean', right_on = 'Product Code')\n",
    "\n",
    "SKU_final = SKU_final.append(no_pair, ignore_index = True, sort = False)\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101569360'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK PERAS REF 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101569360'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK PERAS REF 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101686036'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"W'DANK LKLT KOPI KAWISTA PLS 12RX10SX15G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin([\"(E)2104407\",'2104407'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS EXTRA VIRGIN OLIVE OIL 12BTLX500ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2305551106'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2305551106'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(B)2305551106'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2304034180'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN GM MANGGA 6DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101588453', '1101588453', '(B)(R)1101588453', '1101588016'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MILKY ORANGE PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(R)1101588453'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MILKY ORANGE PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101452195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101500195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD PLAIN 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101524180'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD BISCUIT CEREAL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101453195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101651195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2102546125'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(B)2102546125'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2102546125'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2304034180'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN GM MANGGA 6DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101989453', '1101989453', '(B)(R)1101989453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS ES CINCAU PLS 4PX40SX13G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101954453', '1101954453', '(B)(R)1101954453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS SEMANGKA PLS 4PX40SX13G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101927453', '1101927453', '(B)(R)1101927453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS NANAS PLS 4PX40SX13G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104170104'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS WHITE COFFEE 12DX4SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101656318', '(B)1101656318', '(B)(R)1101656318','(E)1101656318'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101930453', '(B)(R)1101930453', '1101930453',\"(E)1101930453\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS COCOPANDAN PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['71210158', '(J)71110121'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 25 RASA'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(J)71110126'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 25 RASA FRESHSTART'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1102574110'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MIX PAKET BALI 12Dx10S'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['71210165'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET KEHANGATAN WDANK'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104170164'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS WHITE COFFEE 12DX4SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2309005300', '2309005305','(E)2309005300'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PROTEIN CRUNCH BBQ BEEF 20BX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)1101688317','1101688317'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS W’DANK EMPON-EMPON PLS 12Rx10Sx12G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2306551173'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN BAR CRUNCHY CHOCOLATE 6SBX12SX22G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2306551173'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN BAR CRUNCHY CHOCOLATE 6SBX12SX22G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101813443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES TELER PLS 8RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101813036'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES TELER FC 36PX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101864443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES PISANG IJO PLS 8RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101845360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101845443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM PLS 8RX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101845443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM PLS 8RX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '71210166'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET LOKALATE UNTUK SOBATKU'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2304008180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN GAINMASS TARO 6DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2305551161'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX38.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2305507288',\"(E)2305507288\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM KACANG HIJAU 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '71210163'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET HAMPERS IMLEK NUTRISARI'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104508105'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104148164'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS MINT COCOA 12DX4SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104214210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAMBAL TERASI 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104214210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAMBAL TERASI 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104115163'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS AVOCADO COFFEE 12DX4SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101609180','(E)2101609180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN TARO 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101445144','(E)2101445144'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE KETAN HITAM 12DX175G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101485195'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE VANILLA 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2102526125'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT LEMONGRASS PANDAN 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104394210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAUS TIRAM 24BTLX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2305545288',\"(E)2305545288\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM KETAN HITAM 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106023014', '(B)2106023014',\"(E)2106023014\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SHIRATAKI NOODLES 40PX71G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110113'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET HILO'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET TAKJIL HILO DESSERT'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110110'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'HAMPER IDUL FITRI TS'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110129'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET TS BEAT HYPERTENSION 2022'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110114'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET RAMADHAN NUTRISARI 2021'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101413144'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE ES TELER 12DX175G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110111'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET KEHANGATAN WDANK - RAMADHAN EDITION'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110115'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'GETPLUS HAMPERS IDUL FITRI TS'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2102584125'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT ROSE VANILLA 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101642180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN POPCORN CARAMEL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101543453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS APEL JERUK PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(B) 2101656'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN RTD COFFEE TIRAMISU 24PX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2106386249'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS RTD OAT DRINK VANILLICIOUS 24PX190ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104241210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS MAYONNAISE ROASTED SESAME 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104241210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS MAYONNAISE ROASTED SESAME 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101996453',\"(E)1101996453\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS ES RUJAK JERUK BALI PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2300542155'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN DAILY POPCORN CARAMEL 12DX250G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102110453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS NUTRI C1000 JERUK PLS 4PX40SX6G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110117'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI MBA NANA SI PENUH PESONA'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110116'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI MAS KAKA YANG BANYAK AKAL'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110119'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI JEJE SI JELI'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102560453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRISARI 4 RASA SUMMER PACKAGE 40 SACHET'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102561453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRISARI 4 RASA LOCAL PACKAGE 40 SACHET'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104543105'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS KOREAN GOGUMA COOKIES 12DX5SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101651155'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 12DX250G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110118'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET ORANGE ADVENTURE'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101578180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD SWEET POTATO 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101551195'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101710110'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO JOINT PLUS 12DX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101710110'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO JOINT PLUS 12DX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101693318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI TAPE KETAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101693318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI TAPE KETAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101694318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ANDALIMAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110120'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET LOKALATE #RASALOKAL'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101444180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL STRAW CHEESECAKE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101486195'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL VANILLA 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101487148', '(B)2101487148'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ALMOND MILK COCONUT 12DX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101469180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO MULTIGRAIN ORIGINAL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101683180', '(B)2101683180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN STRAW MILKSHAKE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2304097159'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLANTPROTEIN OGURA 6Dx216G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106395308'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SHIRATAKI RICE RASA NASI UDUK 24PX72G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1102070350'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS TEA LYCHEE TEA REF 12BAGX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101505453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK NIPIS JAHE PLS 4PX40SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101595453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS ES KUWUD NIPIS PLS 4PX40SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2104589105'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = \"TS COOKIES KLEPON 12DX5SX20G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2304515112'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = \"L-MEN LOSE WEIGHT AVOCADO COFFEE 6DX12SX25G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101453607'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = \"HILO SCHOOL CHOCOLATE 12DX250G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101459180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = \"HILO SCHOOL BUBBLE GUM 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101478180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = \"HILO ACTIVE CARAMEL LATTE 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110124'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'PARSEL NATAL TAHUN BARU'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101479180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL COTTON CANDY 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101692318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI PISANG BAKAR EPE PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101656360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101685360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ALPUKAT 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101686036'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"W'DANK LKLT KOPI KAWISTA PLS 12RX10SX15G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101888360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO KLEPON LATTE REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101847360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO THAI TEA REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101819360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TARO LATTE REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101481118'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE CANDY 12SBX20SX8G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106317152'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS INSTANT CAKE MIX BROWNIES 12Dx230G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2305559288'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM BUBBLE GUM 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2305584288'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM VANILLA CARAMEL 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2304576112'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN LW MANGO STICKY RICE 6DX12SX25G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2105055180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS LOW FAT MILK MACCHIATO COFFEE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101618180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN BISCUIT CARAMEL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2154084141'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'DIABETAMIL'\n",
    "SKU_final['Unnamed: 3'][index] = 'DIABETAMIL MILK VANILLA 12Dx150G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2104119110'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SOY LATTE 12Dx10Sx15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1102611360'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS TEA LEMON TEA REF 12BAGX500G\"\n",
    "\n",
    "SKU = SKU.merge(SKU_final[['SKU', 'Category Baru', 'Unnamed: 3']].drop_duplicates('SKU'), how = 'left', on = 'SKU')\n",
    "SKU = SKU.rename(columns = {'Unnamed: 3' : 'Exported Parent Item'})\n",
    "\n",
    "index = data_all[data_all['Real SKU'] == '2101492P24'].index.to_list()\n",
    "data_all['Brand'][index] = 'Bundle'\n",
    "index = data_all[data_all['SKU'].isin(['71210111', '71210112'])].index.to_list()\n",
    "data_all['Brand'][index] = 'Bundle'\n",
    "index = data_all[data_all['Real SKU'] == '2306592173'].index.to_list()\n",
    "data_all['Brand'][index] = 'L-Men'\n",
    "indeks = data_all[data_all['Brand'] == 'TS'][data_all[data_all['Brand'] == 'TS']['Real SKU'].astype(str) == '2101453180'].index.to_list()\n",
    "data_all['Real SKU'][indeks] = data_all['SKU'][indeks]\n",
    "data_all['Parent Item'][indeks] = 'Tropicana Slim Milk Low Fat Vanilla 500gr'\n",
    "index = data_all[data_all['Brand'] == \"WDANK\"].index.to_list()\n",
    "data_all['Brand'][index] = 'NS'\n",
    "index = data_all[data_all['Brand'] == \"W'dank\"].index.to_list()\n",
    "data_all['Brand'][index] = 'NS'\n",
    "\n",
    "data_all['Real SKU'] = data_all['Real SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "# # # data_all = data_all.drop(['Category Baru', 'Exported Parent Item'], axis = 1)\n",
    "# # data_all.rename(columns = {'SKU_x' : 'SKU'}, inplace = True)\n",
    "\n",
    "no_name = data_all[data_all['Exported Parent Item'].isnull()]\n",
    "no_name = no_name.merge(SKU[['SKU', 'Category Baru', 'Exported Parent Item']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(no_name.index)\n",
    "\n",
    "data_all['Category Baru'][no_name.index] = no_name['Category Baru_y']\n",
    "data_all['Exported Parent Item'][no_name.index] = no_name['Exported Parent Item_y']\n",
    "\n",
    "data_SKU = SKU.copy()\n",
    "data_SKU['Category Baru'] = data_SKU['Category Baru'].fillna(data_SKU['Sub Brand'])\n",
    "data_SKU['Category Baru'] = data_SKU['Category Baru'].fillna(data_SKU['Brand'])\n",
    "data_SKU['Sub Brand'] = data_SKU['Category Baru']\n",
    "data_all['Sub Brand'] = data_all['Category Baru']\n",
    "# data_all = data_all.drop('SKU_y', axis = 1)\n",
    "# data_all.rename(columns = {'SKU_x' : 'SKU'}, inplace = True)\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2102000155'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2153000314'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2304097159'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'L-MEN POWDER'\n",
    "data_all['Sub Brand'][index] = 'L-MEN POWDER'\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2101651155'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'HILO TEEN'\n",
    "data_all['Exported Parent Item'][index] = 'HILO TEEN CHOCOLATE 12DX250G'\n",
    "\n",
    "\n",
    "# # data_SKU['List Brand'] = np.nan\n",
    "# # for i in range(len(data_SKU)):\n",
    "# #     list_brand = []\n",
    "# #     if data_SKU['Brand'][i] == 'Bundle':\n",
    "# #         col_SKU = [x for x in data_SKU.columns if 'SKU Produk' in x]\n",
    "# #         for j in col_SKU:\n",
    "# #             if str(data_SKU[j][i]) != 'nan' and str(data_SKU[j][i]) != '0':\n",
    "# #                 if len(data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Brand']) != 0:\n",
    "# #                     subbrand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Sub Brand'].values[0]\n",
    "# #                     brand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Brand'].values[0]\n",
    "# #                     if brand == 'Gimmick' : \n",
    "# #                         if str(data_SKU['Nama Produk'][i]).lower() != 'nan' :\n",
    "# #                             if 'voucher' in data_SKU['Nama Produk'][i].lower() or 'saldo' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Voucher'\n",
    "# #                             elif 'pouch' in data_SKU['Nama Produk'][i].lower() or 'bag ' in data_SKU['Nama Produk'][i].lower() or 'tas ' in data_SKU['Nama Produk'][i].lower() or 'totebag' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Bag'\n",
    "# #                             elif 'bottle' in data_SKU['Nama Produk'][i].lower() or 'gelas ' in data_SKU['Nama Produk'][i].lower() or 'shaker' in data_SKU['Nama Produk'][i].lower() or 'tumblr' in data_SKU['Nama Produk'][i].lower() or 'tumbler' in data_SKU['Nama Produk'][i].lower() or 'botol' in data_SKU['Nama Produk'][i].lower() or 'thumbler' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Tumblr'\n",
    "# #                             elif 'lunch' in data_SKU['Nama Produk'][i].lower() or 'tupper' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Lunch Box'\n",
    "# #                             elif 'emoney' in data_SKU['Nama Produk'][i].lower() or 'e-money' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'E-Money'\n",
    "# #                             elif 'magnet' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Magnet'\n",
    "# #                             elif 'masker' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Masker'\n",
    "# #                             elif 'spatula' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Spatula'\n",
    "# #                             elif 'nivea' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Nivea'\n",
    "# #                             elif 'card ' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Card'\n",
    "# #                             elif 'mug' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Mug'\n",
    "# #                             list_brand.append(brand)\n",
    "# #                             data_SKU['Sub Brand'][i] = brand\n",
    "# #                     else :\n",
    "# #                         list_brand.append(subbrand)\n",
    "# #     list_brand.sort()\n",
    "# #     data_SKU['List Brand'][i] = list_brand\n",
    "\n",
    "# # for i in range(len(data_SKU)):\n",
    "# #     if data_SKU['Brand'][i] == 'Bundle':\n",
    "# #         list_brand = list(dict.fromkeys(data_SKU['List Brand'][i]))\n",
    "# # #         sum_brand = sum([1 for x in list_brand if x in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]])\n",
    "# # #         if sum_brand == 1:\n",
    "# #         list_brand = ' + '.join(list_brand)\n",
    "# # #         else :\n",
    "# # #             not_brand = [x for x in list_brand if x not in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]]\n",
    "# # #             if len(not_brand) == 0:\n",
    "# # #                 list_brand = 'Cross Brand'\n",
    "# # #             else :\n",
    "# # #                 list_brand = 'Cross Brand + ' + ' + '.join(not_brand)\n",
    "# #         data_SKU['Sub Brand'][i] = list_brand\n",
    "\n",
    "\n",
    "temp = data_all.copy()\n",
    "no_name['Real SKU'] = no_name['Real SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "data_all['Sub Brand'][no_name.index] = no_name.merge(data_SKU[['SKU', 'Sub Brand']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(no_name.index)['Sub Brand_y']\n",
    "\n",
    "print('Filter Status')\n",
    "index = data_all[data_all['Customer Name'] == 'Shopee Brand Portal'].index.to_list()\n",
    "data_all['Order Status'][index] = 'Delivered'\n",
    "\n",
    "data_success =data_all[data_all['Order Status'].isin([\n",
    "        '\"Delivered\"', '\"Ready to Ship\"', '\"Open\"', '\"Printed\"',\n",
    "       '\"Shipped\"', '\"Delivered, Shipped\"', '\"Shipped, Ready to Ship\"',\n",
    "       '\"Shipped, Delivered\"', '\"Ready to Ship, Delivered\"',\n",
    "       '\"Ready to Ship, Shipped\"', '\"Delivered, Ready to Ship\"',\n",
    "       '\"Delivered, Open\"', '\"Open, Delivered\"', 'Delivered',\n",
    "       '\"Ready to Ship, Open\"', '\"Shipped, Open\"','complete', 'payment_confirmed',\n",
    "       'completed_to_wms', 'processing', \n",
    "       'ready_to_ship', \n",
    "       '\"Open, Ready to Ship\"', '\"Open, Shipped, Ready to Ship\"',\n",
    "       'Sudah Settlement', '\"Delivered, Shipped, Ready to Ship\"',\n",
    "       '\"Ready to Ship, Shipped, Delivered\"',\n",
    "       '\"Ready to Ship, Delivered, Shipped\"', '\"Open, Shipped\"',\n",
    "       '\"Printed, Open\"', '\"Shipped, Printed\"', '\"Delivered, Printed\"',\n",
    "       '\"Open, Printed\"', '\"Printed, Shipped\"', '\"Printed, Delivered\"',\n",
    "       '\"Open, Delivered, Printed\"', '\"Open, Shipped, Printed\"',\n",
    "       '\"Shipped, Open, Printed\"', '\"Ready to Ship, Printed\"',\n",
    "       '\"Printed, Delivered, Open\"', '\"Delivered, Printed, Shipped\"',\n",
    "       '\"Printed, Shipped, Open\"', '\"Delivered, Shipped, Open\"',\n",
    "       '\"Shipped, Open, Ready to Ship\"',\n",
    "       '\"Delivered, Open, Ready to Ship\"', \n",
    "       '\"Ready to Ship, Open, Shipped\"', \n",
    "       'Sudah Isi Pickup Time', '\"Shipped, Ready to Ship, Open\"',\n",
    "       '\"Payout\"',  '\"Printed, Ready to Ship\"',\n",
    "       'Ready to Ship', 'Open',\n",
    "       'Shipped', 'Delivered, Shipped', \n",
    "       'Delivered, Open', 'Printed', 'cod_sent',\n",
    "       'entri_verified', 'incoming', 'completed', 'Open, Ready to Ship',\n",
    "       'Open, Shipped', 'Ready to Ship, Shipped', 'completed_with_awb','Packed','Shipped','Delivered','Ready to Ship'\n",
    "    ])]\n",
    "\n",
    "print(data_success[(data_success['Store']=='Order Online')&(data_success['Year']==2022)]['Date'].unique())\n",
    "all_single = data_success[data_success['Brand'].isin(['NS', 'TS', 'L-Men', 'HiLo'])]\n",
    "all_single = all_single[all_single['Exported Parent Item'] != \"W'DANK LKLT KOPI DURIAN PLS 12RX10SX15G\"]\n",
    "all_single = all_single[all_single['Store'].isin(['JD Indonesia', 'Lazada', 'Bukalapak', 'Blibli', 'Tokopedia',\n",
    "                                                  'Shopee', 'Nutrimart', 'Elevenia', 'Order Online',\n",
    "                                                  'CARI SAYUR',  'EMOS', 'INOVASI DIGITAL NIAGA - KALIDERES, PT',\n",
    "                                                  'RITEL BERSAMA NASIONAL; PT', 'SAYUR BOX', 'TANIHUB','INOVASI DIGITAL NIAGA - SURABAYA, PT',\n",
    "                                                  'INDOPASIFIK TEKNOLOGI MED INDONESIA, PT','ASTRO TECHNOLOGIES - TANGERANG, PT', 'Aladin Mall','KREASI TANI LAKSMI - SURABAYA, PT', 'TikTok',\n",
    "                                                  'CIBINONG CENTER INDUSTRIAL ESTATE , PT','KREASI NOSTRA MANDIRI - BOGOR, PT','KREASI NOSTRA MANDIRI - SURABAYA, PT','ECOM RETAIL - ASTRO',\n",
    "                                                  'ECOM RETAIL - BAYI NINJA JAKARTA','ECOM RETAIL - BAYI NINJA SURABAYA', 'ECOM RETAIL - EMOS',\n",
    "                                                  'ECOM RETAIL - LIFEPACK','ECOM RETAIL - SAYUR BOX JAKARTA',\n",
    "                                                  'ECOM RETAIL - SAYUR BOX SURABAYA', 'ECOM RETAIL - TANIHUB'])]\n",
    "\n",
    "indeks = all_single[all_single['Store'].isin(['CARI SAYUR',  'EMOS', 'INOVASI DIGITAL NIAGA - KALIDERES, PT',\n",
    "                                              'RITEL BERSAMA NASIONAL; PT', 'SAYUR BOX', 'TANIHUB'])].index.to_list()\n",
    "all_single['Exported Parent Item'][indeks] = all_single['Product Name'][indeks]\n",
    "\n",
    "indeks = all_single[(all_single['Store'].isin(['CARI SAYUR',  'EMOS', 'INOVASI DIGITAL NIAGA - KALIDERES, PT',\n",
    "       'RITEL BERSAMA NASIONAL; PT', 'SAYUR BOX', 'TANIHUB']))&\n",
    "                   (all_single['Sub Brand'].isnull())].index.to_list()\n",
    "all_single['Sub Brand'][indeks] = all_single['Category'][indeks]\n",
    "\n",
    "all_single['Total Net'] = all_single['Total Net'].astype(float).astype('int64')\n",
    "\n",
    "bundle_name = data_all[data_all['Real SKU'] == 'PN50N86N87N89G162']['Product Name'].unique()\n",
    "bundle_name = list(bundle_name) + ['NutriSari Orange Adventure (5 x 10 Sch)','NutriSari Bundle - Orange Adventure']\n",
    "indeks = all_single[all_single['Bundle Name'].astype(str).isin(bundle_name)].index.to_list()\n",
    "all_single['Brand'][indeks] = 'NS'\n",
    "all_single['Sub Brand'][indeks] = 'PAKET NUTRISARI'\n",
    "all_single['Exported Parent Item'][indeks] = 'PAKET ORANGE ADVENTURE'\n",
    "\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS SHIRATAKI NOODLES 40Px71G', 'TS SHIRATAKI NOODLES 40PX71G')\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS KOREAN GARLIC BUTTERCOOKIES12DX5SX20G', 'TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G')\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS WHITE COFFEE 12DX4SX20G', 'TS WHITE COFFEE 12DX4SX15G')\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS AVOCADO COFFEE 12DX4SX20G', 'TS AVOCADO COFFEE 12DX4SX14G')\n",
    "\n",
    "all_single.loc[all_single['Real SKU'] == '2152051','Exported Parent Item']='TS DM COOKIES CHOCO 12DX10SX20G'#[['Year','Month','Brand','Store','Sub Brand','Real SKU','Real Nama Produk','Bundle Name']]#.drop_duplicates()\n",
    "all_single.loc[all_single['Real SKU'] == '2152051','Sub Brand']='TS KUNING OTHERS'\n",
    "all_single=all_single[all_single['Real SKU']!=\"(U)1102101155\"]\n",
    "all_single=all_single[all_single['Real SKU']!=\"(U)2307061250\"]\n",
    "all_single.loc[all_single['Order #']=='1000103864','Region Group']='Kab. Bogor'\n",
    "\n",
    "zipnotmapped=all_single[(all_single['Region Group'].isnull())&(all_single['Store Type']=='Marketplace')&(all_single['Year']==2022)&(all_single['Zip Code'].notnull())]['Zip Code'].unique()#.to_excel('Gk ke mapping.xlsx',index=False)\n",
    "for i in zipnotmapped:\n",
    "    regionvalue=all_single[(all_single['Zip Code']==i)&(all_single['Region Group'].notnull())]['Region Group'].unique()[0]\n",
    "    all_single.loc[(all_single['Region Group'].isnull())&(all_single['Region Group'].isnull())&(all_single['Store Type']=='Marketplace')&(all_single['Year']==2022),'Region Group']=regionvalue\n",
    "\n",
    "\n",
    "indeks = all_single[all_single['Exported Parent Item'].isnull()].index.to_list()\n",
    "indeks = indeks + all_single[all_single['Exported Parent Item'] == 'nan'].index.to_list()\n",
    "\n",
    "if len(indeks) == 0:\n",
    "    print(\"Prepare E-mailing\")\n",
    "    \n",
    "    ########################################################\n",
    "    \n",
    "    table_brand = all_single[all_single['Store']=='Order Online'][['Brand','Sub Brand']].drop_duplicates().reset_index(drop = True)\n",
    "    all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "    from datetime import datetime, timedelta\n",
    "    today = datetime.today()\n",
    "    yesterday = datetime.today() - timedelta(days=1)\n",
    "    today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "    yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "    yesterday_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "    yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    yesterday_sales['Total Net'] = yesterday_sales['Total Net']/1.1\n",
    "    yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "    table_brand = table_brand.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "    else :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(yesterday.strftime('%d')))\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    mtd_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "    mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    mtd_sales['Total Net'] = mtd_sales['Total Net']/1.1\n",
    "    mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "    table_brand = table_brand.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    from calendar import monthrange\n",
    "\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "        number_of_days = monthrange(today.year, today.month)[1]\n",
    "    else :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(yesterday.strftime('%d')))\n",
    "        number_of_days = monthrange(yesterday.year, yesterday.month)[1]\n",
    "\n",
    "    table_brand['Projected'] = table_brand['Average This Month'] * number_of_days\n",
    "\n",
    "    from dateutil import rrule\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "    start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "    end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "    for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "        first_date = pd.to_datetime(dt)\n",
    "        print(\"First Date \" + str(first_date))\n",
    "        last_date = first_date + relativedelta(months=1)\n",
    "        print(\"Last Date \" + str(last_date))\n",
    "        temp_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "        temp_sales = temp_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "        temp_sales['Total Net'] = temp_sales['Total Net']/1.1\n",
    "        colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "        temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "        table_brand = table_brand.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    cols = list(table_brand)\n",
    "    cols[len(cols)-1], cols[len(cols)-3] = cols[len(cols)-3], cols[len(cols)-1]\n",
    "    table_brand = table_brand.loc[:,cols]\n",
    "    table_brand = table_brand.reset_index(drop = True)\n",
    "    table_brand = table_brand.drop('Average This Month', axis = 1)\n",
    "\n",
    "    def highlight_max(x):\n",
    "        return ['font-weight: bold' if v == x.loc[x.index.max()] else ''\n",
    "                    for v in x]\n",
    "\n",
    "    #     table_brand = table_brand[table_brand['Local Sales'].notnull()]\n",
    "    table_brand['Yesterday Sales'] = table_brand['Yesterday Sales'].fillna(0).astype('int64')\n",
    "    table_brand['Local Sales'] = table_brand['Local Sales'].fillna(0).astype('int64')\n",
    "    table_brand = table_brand.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "    table_ecom = table_brand.copy()\n",
    "\n",
    "    for i in table_ecom.columns[2:]:\n",
    "        table_ecom[i] = table_ecom[i].fillna(0).astype('int64')\n",
    "\n",
    "    table_ecom = table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "    # for i in table_ecom.columns[2:]:\n",
    "    #     table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "    #     table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "    table_ecom = table_ecom.drop('Brand', axis = 1)\n",
    "    table_ecom['Sub Brand'][table_ecom.index.max()] = '<b>Total E-Commerce (NHD) Sales<b>'\n",
    "    table_ecom = table_ecom.rename(columns = {'Sub Brand' : ''})\n",
    "\n",
    "    table_ecom2 = table_ecom.iloc[[-1]].reset_index(drop = True)\n",
    "\n",
    "    ###############################################################\n",
    "\n",
    "    table_brand = all_single[all_single['Store']!='Order Online'][['Brand','Sub Brand']].drop_duplicates().reset_index(drop = True)\n",
    "    all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    today = datetime.today()\n",
    "    yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "    today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "    yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "\n",
    "    yesterday_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "    yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    yesterday_sales['Total Net'] = yesterday_sales['Total Net']/1.1\n",
    "    yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "    table_brand = table_brand.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "    else :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(yesterday.strftime('%d')))\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    mtd_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "    mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    mtd_sales['Total Net'] = mtd_sales['Total Net']/1.1\n",
    "    mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "    table_brand = table_brand.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    from calendar import monthrange\n",
    "\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "        number_of_days = monthrange(today.year, today.month)[1]\n",
    "    else :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(yesterday.strftime('%d')))\n",
    "        number_of_days = monthrange(yesterday.year, yesterday.month)[1]\n",
    "\n",
    "    table_brand['Projected'] = table_brand['Average This Month'] * number_of_days\n",
    "\n",
    "    from dateutil import rrule\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "    start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "    end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "    for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "        first_date = pd.to_datetime(dt)\n",
    "        print(\"First Date \" + str(first_date))\n",
    "        last_date = first_date + relativedelta(months=1)\n",
    "        print(\"Last Date \" + str(last_date))\n",
    "        temp_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "        temp_sales = temp_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "        temp_sales['Total Net'] = temp_sales['Total Net']/1.1\n",
    "        colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "        temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "        table_brand = table_brand.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    cols = list(table_brand)\n",
    "    cols[len(cols)-1], cols[len(cols)-3] = cols[len(cols)-3], cols[len(cols)-1]\n",
    "    table_brand = table_brand.loc[:,cols]\n",
    "    table_brand = table_brand.reset_index(drop = True)\n",
    "    table_brand = table_brand.drop('Average This Month', axis = 1)\n",
    "\n",
    "    def highlight_max(x):\n",
    "        return ['font-weight: bold' if v == x.loc[x.index.max()] else ''\n",
    "                    for v in x]\n",
    "\n",
    "    #     table_brand = table_brand[table_brand['Local Sales'].notnull()]\n",
    "    table_brand['Yesterday Sales'] = table_brand['Yesterday Sales'].fillna(0).astype('int64')\n",
    "    table_brand['Local Sales'] = table_brand['Local Sales'].fillna(0).astype('int64')\n",
    "    table_brand = table_brand.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "    table_ecom = table_brand.copy()\n",
    "\n",
    "    for i in table_ecom.columns[2:]:\n",
    "        table_ecom[i] = table_ecom[i].fillna(0).astype('int64')\n",
    "\n",
    "    table_ecom = table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "    # for i in table_ecom.columns[2:]:\n",
    "    #     table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "    #     table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "    table_ecom = table_ecom.drop('Brand', axis = 1)\n",
    "    table_ecom['Sub Brand'][table_ecom.index.max()] = '<b>Total E-Commerce (Non NHD) Sales</b>'\n",
    "    table_ecom = table_ecom.rename(columns = {'Sub Brand' : ''})\n",
    "\n",
    "    table_ecom1 = table_ecom.iloc[[-1]].reset_index(drop = True)\n",
    "    # table_ecom=table_ecom1.append(table_ecom2,ignore_index=True,sort=False)\n",
    "    # table_ecom=table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True,sort=False)\n",
    "\n",
    "    table_ecom=table_ecom1.append(table_ecom2,ignore_index=True,sort=False)\n",
    "    table_ecom=table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "    table_ecom.loc[(table_ecom[\"\"].isnull()),\"\"]='<b>Total E-Commerce Sales</b>'\n",
    "    table_ecom\n",
    "\n",
    "    for i in table_ecom.columns[1:]:\n",
    "        table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "    ###############################################################\n",
    "    from datetime import date\n",
    "    sales_total=all_single.groupby(['Year','Month','True datetime','Store'],dropna=False)[['Total Net']].sum().reset_index()\n",
    "    sales_total.loc[sales_total['Store']=='Order Online','Store Group']='<b>Total Ecommerce (NHD) Sales</b>'\n",
    "    sales_total.loc[sales_total['Store']!='Order Online','Store Group']='<b>Total Ecommerce (Non NHD) Sales</b>'\n",
    "\n",
    "    sales_total['Total Net Before PPN']=sales_total['Total Net']/1.1\n",
    "    sales_total.loc[sales_total['True datetime']>='2022-04-01','Total Net Before PPN']=sales_total['Total Net']/1.11\n",
    "\n",
    "    sales_total['Date']=pd.to_datetime(sales_total['True datetime']).dt.date\n",
    "\n",
    "    col1=sales_total[(sales_total['Date']>=(date.today()-timedelta(1)))&\n",
    "                        (sales_total['Date']<(date.today()))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Yesterday Sales'}))\n",
    "\n",
    "    if '<b>Total Ecommerce (NHD) Sales</b>' not in col1['Store Group'].unique():\n",
    "        col1=col1.append(pd.DataFrame({'Store Group': [\"<b>Total Ecommerce (NHD) Sales</b>\"], 'Yesterday Sales': [0]}))\n",
    "\n",
    "    col2=sales_total[(sales_total['Year']==(datetime.now()-timedelta(1)).year)&\n",
    "                         (sales_total['Month']==(datetime.now()-timedelta(1)).strftime(\"%B\"))&\n",
    "                         (sales_total['Date']<(date.today()))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Local Sales'}))\n",
    "    lastmonth1=(date.today().replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth2=(lastmonth1.replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth3=(lastmonth2.replace(day=1)-timedelta(1))\n",
    "    col3=col2.copy()\n",
    "    maxday=monthrange((datetime.now()-timedelta(1)).year, (datetime.now()-timedelta(1)).month)[1]\n",
    "    col3['Projected']=col3['Local Sales']*maxday/((datetime.now()-timedelta(1)).day)\n",
    "\n",
    "    col4=sales_total[(sales_total['Year']==lastmonth1.year)&\n",
    "                 (sales_total['Month']==lastmonth1.strftime(\"%B\"))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth1.strftime(\"%B\")} {lastmonth1.year}'}))\n",
    "    col5=sales_total[(sales_total['Year']==lastmonth2.year)&\n",
    "                 (sales_total['Month']==lastmonth2.strftime(\"%B\"))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth2.strftime(\"%B\")} {lastmonth2.year}'}))\n",
    "    col6=sales_total[(sales_total['Year']==lastmonth3.year)&\n",
    "                 (sales_total['Month']==lastmonth3.strftime(\"%B\"))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth3.strftime(\"%B\")} {lastmonth3.year}'}))\n",
    "    tblall=col1.merge(col2,how='left').merge(col3,how='left').merge(col4,how='left').merge(col5,how='left').merge(col6,how='left')\n",
    "    tblall=tblall.fillna(int(0))\n",
    "    tblall=tblall.sort_values('Store Group',ascending=False).reset_index(drop=True)\n",
    "\n",
    "    total_row=tblall.sum(numeric_only=True)\n",
    "\n",
    "    tblall=tblall.append(total_row,ignore_index=True)\n",
    "    tblall.loc[tblall['Store Group'].isnull(),'Store Group']='<b>Total Ecommerce Sales</b>'\n",
    "    tblall.rename(columns={'Store Group':\"\"})\n",
    "    for i in tblall.columns[1:]:\n",
    "        tblall[i] = tblall[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        tblall[i][tblall.index.max()] = \"<b> {} </b>\".format(tblall[i][tblall.index.max()])\n",
    "\n",
    "    # tblall   \n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    sales_region=all_single.groupby(['Year','Month','True datetime','Region Group'],dropna=False)[['Total Net']].sum().reset_index()\n",
    "    mappingarea=pd.read_excel(\"D:\\Masterdata\\Database Area untuk Report.xlsx\")\n",
    "    mappingarea=mappingarea.rename(columns=({'Region':'Real Region',\"City\":'Region Group'}))\n",
    "    sales_region=sales_region.merge(mappingarea,how='left')\n",
    "    sales_region.loc[sales_region['Region Group'].isnull(),'Real Region']='Retail Online'\n",
    "    \n",
    "    \n",
    "    sales_region['Total Net Before PPN']=sales_region['Total Net']/1.1\n",
    "    sales_region.loc[sales_region['True datetime']>='2022-04-01','Total Net Before PPN']=sales_region['Total Net']/1.11\n",
    "    sales_region['Date']=pd.to_datetime(sales_region['True datetime']).dt.date\n",
    "\n",
    "    tblreg=sales_region[(sales_region['Date']>=(date.today()-timedelta(1)))&\n",
    "                        (sales_region['Date']<(date.today()))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Yesterday Sales'}))\n",
    "    no_ytd_sales=mappingarea[~mappingarea['Real Region'].isin(tblreg['Real Region'].unique())]['Real Region'].unique()\n",
    "    for i in no_ytd_sales:\n",
    "        tblreg=tblreg.append(pd.DataFrame({'Real Region': [f\"{i}\"], 'Yesterday Sales': [0]}))\n",
    "        tblreg=tblreg.sort_values('Real Region')    \n",
    "    if 'Retail Online' not in tblreg['Real Region'].unique():\n",
    "        tblreg=tblreg.append(pd.DataFrame({'Real Region': [\"Retail Online\"], 'Yesterday Sales': [0]}))\n",
    "\n",
    "    tblreg2=sales_region[(sales_region['Year']==(datetime.now()-timedelta(1)).year)&\n",
    "                         (sales_region['Month']==(datetime.now()-timedelta(1)).strftime(\"%B\"))&\n",
    "                         (sales_region['Date']<(date.today()))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Local Sales'}))\n",
    "    lastmonth1=(date.today().replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth2=(lastmonth1.replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth3=(lastmonth2.replace(day=1)-timedelta(1))\n",
    "    tblreg3=tblreg2.copy()\n",
    "    maxday=monthrange((datetime.now()-timedelta(1)).year, (datetime.now()-timedelta(1)).month)[1]\n",
    "    tblreg3['Projected']=tblreg3['Local Sales']*maxday/((datetime.now()-timedelta(1)).day)\n",
    "\n",
    "    tblregshopee=tblreg3[tblreg3[\"Real Region\"]=='Retail Online']\n",
    "    tblreg3=tblreg3[tblreg3[\"Real Region\"]!='Retail Online']#.copy()\n",
    "\n",
    "    totprj=tblreg3[tblreg3[\"Real Region\"]!='Retail Online']['Projected'].sum()\n",
    "    tblreg3['Projected %']=tblreg3['Projected']/totprj\n",
    "    tblreg3=tblreg3.append(tblregshopee)\n",
    "\n",
    "    tblreg3=tblreg3[['Real Region','Projected','Projected %']]\n",
    "    tblreg4=sales_region[(sales_region['Year']==lastmonth1.year)&\n",
    "                 (sales_region['Month']==lastmonth1.strftime(\"%B\"))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth1.strftime(\"%B\")} {lastmonth1.year}'}))\n",
    "    tblreg5=sales_region[(sales_region['Year']==lastmonth2.year)&\n",
    "                 (sales_region['Month']==lastmonth2.strftime(\"%B\"))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth2.strftime(\"%B\")} {lastmonth2.year}'}))\n",
    "    tblreg6=sales_region[(sales_region['Year']==lastmonth3.year)&\n",
    "                 (sales_region['Month']==lastmonth3.strftime(\"%B\"))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth3.strftime(\"%B\")} {lastmonth3.year}'}))\n",
    "    tblreg=tblreg.merge(tblreg2,how='left').merge(tblreg3,how='left').merge(tblreg4,how='left').merge(tblreg5,how='left').merge(tblreg6,how='left')\n",
    "    tblreg=tblreg.rename(columns={'Real Region':'Region'})\n",
    "\n",
    "    total_row=tblreg.sum(numeric_only=True)\n",
    "    sub_total_row=tblreg[tblreg[\"Region\"]!='Retail Online'].sum(numeric_only=True)\n",
    "    # tblreg.loc[(tblreg[\"Region\"].isnull()),\"Region\"]='<b>Total Sales</b>'\n",
    "    res=pd.DataFrame()\n",
    "    res=res.append(tblreg[tblreg[\"Region\"]!='Retail Online']).append(sub_total_row,ignore_index=True).append(tblreg[tblreg[\"Region\"]=='Retail Online'])\n",
    "    res.loc[res[\"Region\"].isnull(),'Region']='<b>Sub Total Sales</b>'\n",
    "    res=res.append(total_row,ignore_index=True)\n",
    "    res.loc[res[\"Region\"].isnull(),'Region']='<b>Total Sales</b>'\n",
    "\n",
    "    res.loc[(res['Region']=='Retail Online')&\n",
    "               (res['Local Sales'].isnull()),'Local Sales']=0\n",
    "    res.loc[(res['Region']=='Retail Online')&\n",
    "               (res['Projected'].isnull()),'Projected']=0\n",
    "\n",
    "    tblreg=res.copy()\n",
    "\n",
    "    for i in tblreg.columns[1:4]:\n",
    "        tblreg[i] = tblreg[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
    "\n",
    "    for i in tblreg.columns[4:5]:\n",
    "        tblreg[i] = tblreg[i].apply(lambda x: \"{:.2f} %\".format(x*100))#.str.replace(',','.', regex = False)\n",
    "        tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
    "\n",
    "\n",
    "    for i in tblreg.columns[5:]:\n",
    "        tblreg[i] = tblreg[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
    "\n",
    "    for i in tblreg.columns[1:]:\n",
    "        tblreg[i][tblreg.index.max()-2] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()-2])\n",
    "\n",
    "    tblreg.loc[(tblreg[\"Projected %\"]==\"nan %\"),\"Projected %\"]=''\n",
    "\n",
    "\n",
    "    tblreg\n",
    "\n",
    "    ###################################################################################\n",
    "\n",
    "    for i in table_brand.columns[2:]:\n",
    "        table_brand[i] = table_brand[i].fillna(0).astype('int64')\n",
    "\n",
    "    table_brand_hilo = table_brand[table_brand['Brand'] == 'HiLo'].reset_index(drop = True)\n",
    "    table_brand_hilo = table_brand_hilo.append(table_brand_hilo.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_hilo['Sub Brand'][table_brand_hilo.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_hilo['Brand'][table_brand_hilo.index.max()] = ''\n",
    "\n",
    "\n",
    "    table_brand_ns= table_brand[table_brand['Brand'] == 'NS'].reset_index(drop = True)\n",
    "    table_brand_ns = table_brand_ns.append(table_brand_ns.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_ns['Sub Brand'][table_brand_ns.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_ns['Brand'][table_brand_ns.index.max()] = ''\n",
    "\n",
    "\n",
    "    table_brand_lmen = table_brand[table_brand['Brand'] == 'L-Men'].reset_index(drop = True)\n",
    "    table_brand_lmen = table_brand_lmen.append(table_brand_lmen.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_lmen['Sub Brand'][table_brand_lmen.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_lmen['Brand'][table_brand_lmen.index.max()] = ''\n",
    "\n",
    "\n",
    "    table_brand_ts = table_brand[table_brand['Brand'] == 'TS'].reset_index(drop = True)\n",
    "    table_brand_ts = table_brand_ts.append(table_brand_ts.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_ts['Sub Brand'][table_brand_ts.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_ts['Brand'][table_brand_ts.index.max()] = ''\n",
    "\n",
    "\n",
    "    for i in table_brand_hilo.columns[2:]:\n",
    "        table_brand_hilo[i] = table_brand_hilo[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_hilo[i][table_brand_hilo.index.max()] = \"<b> {} </b>\".format(table_brand_hilo[i][table_brand_hilo.index.max()])\n",
    "\n",
    "    for i in table_brand_lmen.columns[2:]:\n",
    "        table_brand_lmen[i] = table_brand_lmen[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_lmen[i][table_brand_lmen.index.max()] = \"<b> {} </b>\".format(table_brand_lmen[i][table_brand_lmen.index.max()])\n",
    "\n",
    "    for i in table_brand_ns.columns[2:]:\n",
    "        table_brand_ns[i] = table_brand_ns[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_ns[i][table_brand_ns.index.max()] = \"<b> {} </b>\".format(table_brand_ns[i][table_brand_ns.index.max()])\n",
    "\n",
    "    for i in table_brand_ts.columns[2:]:\n",
    "        table_brand_ts[i] = table_brand_ts[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_ts[i][table_brand_ts.index.max()] = \"<b> {} </b>\".format(table_brand_ts[i][table_brand_ts.index.max()])\n",
    "\n",
    "    table_brand = table_brand_hilo.append(pd.Series(), ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(table_brand_lmen, ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(table_brand_ns, ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(table_brand_ts, ignore_index = True, sort = False)\n",
    "    for i in table_brand.columns:\n",
    "        table_brand[i] = table_brand[i].fillna('')\n",
    "\n",
    "    table_brand = table_brand[(table_brand == 'Rp 0').sum(1) < 5]\n",
    "    table_brand = table_brand.reset_index(drop = True)\n",
    "\n",
    "    # table_brand_hilo.style.apply(highlight_max)\n",
    "    # table_brand_ns.style.apply(highlight_max)\n",
    "    # table_brand_lmen.style.apply(highlight_max)\n",
    "    # table_brand_ts.style.apply(highlight_max)\n",
    "\n",
    "    table_item = all_single[['Brand', 'Sub Brand', 'Exported Parent Item']].drop_duplicates().reset_index(drop = True)\n",
    "    all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    today = datetime.today()\n",
    "    yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "    today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "    yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "\n",
    "    yesterday_sales = all_single[all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "    yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "    yesterday_sales['Total Net'] = yesterday_sales['Total Net']/1.1\n",
    "    yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "    table_item = table_item.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "    else :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(yesterday.strftime('%d')))\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    mtd_sales = all_single[all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "    mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "    mtd_sales['Total Net'] = mtd_sales['Total Net']/1.1\n",
    "    mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "    table_item = table_item.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        table_item['Average This Month'] = table_item['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "        number_of_days = monthrange(today.year, today.month)[1]\n",
    "    else :\n",
    "        table_item['Average This Month'] = table_item['Local Sales']/(int(yesterday.strftime('%d')))\n",
    "        number_of_days = monthrange(yesterday.year, yesterday.month)[1]\n",
    "\n",
    "    table_item['Projected'] = table_item['Average This Month'] * number_of_days\n",
    "\n",
    "    from dateutil import rrule\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "    start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "    end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "    for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "        first_date = pd.to_datetime(dt)\n",
    "        last_date = first_date + relativedelta(months=1)\n",
    "        temp_sales = all_single[all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "        temp_sales = temp_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "        temp_sales['Total Net'] = temp_sales['Total Net']/1.11\n",
    "        colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "        temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "        table_item = table_item.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "    cols = list(table_item)\n",
    "    cols[len(cols)-1], cols[len(cols)-3] = cols[len(cols)-3], cols[len(cols)-1]\n",
    "    table_item = table_item.loc[:,cols]\n",
    "\n",
    "    #     table_item = table_item[table_item['Local Sales'].notnull()]\n",
    "    table_item['Yesterday Sales'] = pd.to_numeric(table_item['Yesterday Sales'], errors = 'coerce').fillna(0).astype('int64')\n",
    "    table_item['Local Sales'] = pd.to_numeric(table_item['Local Sales'], errors = 'coerce').fillna(0).astype('int64')\n",
    "    table_item = table_item.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "    for i in table_item.columns[3:]:\n",
    "        table_item[i] = table_item[i].fillna(0).apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "\n",
    "    table_item = table_item[(table_item == 'Rp 0').sum(1) < 5]\n",
    "    table_item = table_item.reset_index(drop = True)\n",
    "    table_item = table_item.drop('Average This Month', axis = 1)\n",
    "\n",
    "    all_single = all_single.sort_values('True datetime')\n",
    "\n",
    "    first_product = all_single.groupby('Exported Parent Item')['True datetime'].first().reset_index()\n",
    "\n",
    "    product_launch = first_product[first_product['True datetime'] > pd.to_datetime(datetime.today() - relativedelta(months=3))]['Exported Parent Item'].unique()\n",
    "    non_launch =  [\"PARSEL NATAL TAHUN BARU\",'HAMPER IDUL FITRI TS', 'GETPLUS HAMPERS IDUL FITRI TS', 'PAKET TAKJIL HILO DESSERT',\n",
    "                   'HILO CHOCOLATE PLS 15RX10SX14G', 'HILO TEEN TARO 12DX500G', 'TS SAMBAL TERASI 24BTLX200G',\n",
    "                   'TS AVOCADO COFFEE 12DX4SX20G', 'L-MEN PLATINUM KETAN HITAM 6KLRX800G', 'HILO AVOCADO CHOCOLATE PLS 15RX10SX14G', 'TS SHIRATAKI NOODLES 40PX71G',\n",
    "                   'TS KOREAN GARLIC BUTTERCOOKIES12DX5SX20G','TS AVOCADO COFFEE 12DX4SX14G', 'TS SWT CLASSIC 24DX100G', 'HILO WHITE CHOCOLATE PLS 15RX10SX14G', \n",
    "                   'HILO CHOCO HAZELNUT PLS 15RX10SX14G', 'NS ANGGUR PLS 4PX40SX11G',\"NS JERUK MANADO PLS 4PX40SX11G\",\n",
    "                   \"NS TEA LYCHEE TEA REF 12BAGX500G\",\"NUTRISARI 4 RASA SUMMER PACKAGE 40 SACHET\",\"NUTRISARI 4 RASA LOCAL PACKAGE 40 SACHET\",\n",
    "                   'PAKET NUTRISARI 25 RASA FRESHSTART','PAKET TS BEAT HYPERTENSION 2022','HILO SCHOOL CHOCOLATE CANDY 12SBX20SX8G','HILO ES TELER FC 36PX10SX15G']\n",
    "    product_launch = [x for x in product_launch if x not in non_launch]\n",
    "\n",
    "    table_launch = table_item[table_item['Exported Parent Item'].isin(product_launch)]\n",
    "    table_item = table_item[~table_item['Exported Parent Item'].isin(product_launch)]\n",
    "\n",
    "    table_hilo = table_item[table_item['Brand'] == 'HiLo'].reset_index(drop = True)\n",
    "    table_ns= table_item[table_item['Brand'] == 'NS'].reset_index(drop = True)\n",
    "    table_ns = table_ns[table_ns['Exported Parent Item'] != \"W'DANK LKLT KOPI DURIAN PLS 12RX10SX15G\"]\n",
    "    table_lmen = table_item[table_item['Brand'] == 'L-Men'].reset_index(drop = True)\n",
    "    table_ts = table_item[table_item['Brand'] == 'TS'].reset_index(drop = True)\n",
    "\n",
    "    new_table_launch = pd.DataFrame()\n",
    "    for i in table_launch['Brand'].unique():\n",
    "        if i != table_launch['Brand'].unique()[-1]:\n",
    "            new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
    "        else :\n",
    "            new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False)\n",
    "\n",
    "    for i in new_table_launch.columns:\n",
    "        new_table_launch[i] = new_table_launch[i].fillna('')\n",
    "\n",
    "    index = data_all[data_all['Sub Brand'] == 'WDANK TRADITIONAL'][data_all[data_all['Sub Brand'] == 'WDANK TRADITIONAL']['Bundle Flag'].isnull()].index.to_list()\n",
    "    data_all['Brand'][index] = 'WDANK'\n",
    "\n",
    "    # data_all['PL Before PPN'] = data_all['Price List NFI']/1.11\n",
    "    data_all['PL Before PPN'] = data_all['Price List NFI']/1.1\n",
    "    data_all.loc[data_all['True datetime']>='2022-04-01','PL Before PPN']= data_all['Price List NFI']/1.11\n",
    "    data_all['Total Net Before PPN'] = data_all['PL Before PPN'] * data_all['Qty. Invoiced']\n",
    "\n",
    "    # data_all.to_csv(r'Clean Data/data_all_' + data_now + '.csv', sep = ';', index = False)\n",
    "    print(\"Clean Data Finish\")\n",
    "    #     data_all[data_all['Store Type'] != 'Retail Online'].to_csv(r'Clean Data/Non Nubi/data_all_non_nubi' + data_now + '.csv', sep = ';', index = False)\n",
    "    print(\"Clean Data Non Nubi Finish\")\n",
    "\n",
    "\n",
    "    # data_all[data_all['Year'] == 2021][['Order #','Order Status','Date', 'Month','Year',\n",
    "    #          'Hour',\n",
    "    #          'Channel', 'Store','Store Type',\n",
    "    #          'SKU',\n",
    "    #          'Brand',\n",
    "    #          'Product Name',\n",
    "    #          'Bundle Name',\n",
    "    #          'Price List NFI',\n",
    "    #          'Qty. Invoiced',\n",
    "    #          'Total Net',\n",
    "    #          'Sub Brand',\n",
    "    #          'Real SKU',\n",
    "    #          'Real Nama Produk',\n",
    "    #          'Parent Item',\n",
    "    #          'Parent SKU',\n",
    "    #          'Bundle Flag',\n",
    "    #          'Customer Email',\n",
    "    #          'Customer Name',\n",
    "    #          'Customer Group',\n",
    "    #          'Phone',\n",
    "    #          'Country',\n",
    "    #          'Region',\n",
    "    #          'City',\n",
    "    #          'Kecamatan',\n",
    "    #          'Kelurahan',\n",
    "    #          'Address',\n",
    "    #          'Zip Code','Shipping Courier',\n",
    "    #          'Total',\n",
    "    #          'Coupon Code','Subtotal',\n",
    "    #          'Discounts','Cart Name Rule','Voucher Amount','Warehouse Name',\n",
    "    #          'Regular Price',\n",
    "    #          'Selling Price','Shipping',\n",
    "    #          'Actual Shipping',\n",
    "    #          'Seller Discount','True datetime',\n",
    "    #          'Promo',\n",
    "    #          'Discount MC',\n",
    "    #          'Harga Cost',\n",
    "    #          'Total Harga Cost','nominal',\n",
    "    #          'btlcost',\n",
    "    #          'gs',\n",
    "    #          'commfee',\n",
    "    #          'fullfee','Shipping Province',\n",
    "    #          'Shipping City',\n",
    "    #          'Shipping Address1',\n",
    "    #          'Shipping Phone', 'PL Before PPN', 'Total Net Before PPN']].to_csv(r'Export Data/data_all_2021_' + data_now + '.csv', sep = ';', index = False)\n",
    "    print(\"Export Data 2020 Finish\")\n",
    "\n",
    "\n",
    "    print(\"Prepare Emailing\")\n",
    "    ### sad sdh gk bisa via gmail ####\n",
    "#     s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "#     # start TLS for security \n",
    "#     s.starttls() \n",
    "\n",
    "#     # Authentication \n",
    "#     s.login(\"automationnfi@gmail.com\", \"nutrifood24\") \n",
    "\n",
    "#     me = \"automationnfi@gmail.com\"\n",
    "#     to = \"andra.miftah@nutrifood.co.id\"\n",
    "\n",
    "#     html = '''\n",
    "#     <html>\n",
    "#     <head>\n",
    "#     <style>\n",
    "\n",
    "#         h2 {\n",
    "#             text-align: center;\n",
    "#             font-family: Helvetica, Arial, sans-serif;\n",
    "#         }\n",
    "#         table { \n",
    "#             margin-left: auto;\n",
    "#             margin-right: auto;\n",
    "#         }\n",
    "#         table, th, td {\n",
    "#             border: 1px solid black;\n",
    "#             border-collapse: collapse;\n",
    "#         }\n",
    "#         th, td {\n",
    "#             padding: 5px;\n",
    "#             text-align: center;\n",
    "#             font-family: Helvetica, Arial, sans-serif;\n",
    "#             font-size: 90%;\n",
    "#         }\n",
    "#         table tbody tr:hover {\n",
    "#             background-color: #dddddd;\n",
    "#         }\n",
    "#         .wide {\n",
    "#             width: 90%; \n",
    "#         }\n",
    "\n",
    "#     </style>\n",
    "#     </head>\n",
    "#     <body>\n",
    "#         '''\n",
    "#     html = html + \"\"\"\n",
    "#         <p> Dear all, </p>\n",
    "#         <p> Berikut data penjualan E-Com (Before PPN) tanggal <b> {tanggal} </b> dengan rincian channel sebagai berikut : </p>\n",
    "#         <p> Channel Marketplace : Blibli, Bukalapak, Elevenia, Lazada, Nutrimart, Order Online, Shopee, Tokopedia, Aladin Mall, TikTok </p>\n",
    "#         <p> Channel Retail : Cari Sayur, Emos, Farmaku, Inovasi Digital Niaga, Ritel Bersama Nasional, Sayurbox, Tanihub  </p>\n",
    "#     \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y')))\n",
    "\n",
    "#     html = html + tblall.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "    \n",
    "#     html = html + \"\"\"\n",
    "#         <p> Dan berikut data penjualan E-Com (After PPN) per Area :</p>\n",
    "#         \"\"\"\n",
    "\n",
    "#     html = html + tblreg.to_html(classes='wide', escape=False)\n",
    "\n",
    "#     html = html + \"\"\"\n",
    "#         <p> Dan Berikut data penjualan E-Com (After PPN) tanggal <b> {tanggal} </b> per Brand :</p>\n",
    "#     \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y'))) \n",
    "\n",
    "#     html = html + table_brand.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "#     html = html + \"\"\"\n",
    "#         <p> Dan berikut data penjualan E-Com (After PPN) per Item :</p>\n",
    "#         <p> Item Launching : </p>\"\"\"\n",
    "\n",
    "#     html = html + new_table_launch.to_html(classes='wide', escape=False)\n",
    "\n",
    "#     html = html + \"<p> HiLo : </p>\"    \n",
    "\n",
    "#     html = html + table_hilo.to_html(classes='wide', escape=False)\n",
    "\n",
    "#     html = html + \"<p> L-Men : </p>\"    \n",
    "\n",
    "#     html = html + table_lmen.to_html(classes='wide', escape=False)\n",
    "\n",
    "#     html = html + \"<p> NutriSari : </p>\"    \n",
    "\n",
    "#     html = html + table_ns.to_html(classes='wide', escape=False)\n",
    "\n",
    "#     html = html + \"<p> Tropicana Slim : </p>\"    \n",
    "\n",
    "#     html = html + table_ts.to_html(classes='wide', escape=False)\n",
    "\n",
    "\n",
    "\n",
    "#     html = html + \"\"\"\n",
    "#         <p></p>\n",
    "#         <p> Best regards, </p>\n",
    "#         <p> Andra Miftah Ar Rahman </p>\n",
    "#         <p> E-Commerce Executive </p>\n",
    "#     <body>\n",
    "#     </html>\n",
    "#     \"\"\"\n",
    "\n",
    "#     # text = text.format(tanggal = str(datetime.today().date()), table_brand = table_brand.to_html(), table_hilo = table_hilo.to_html(), table_ns = table_ns.to_html(), table_lmen = table_lmen.to_html(), table_ts = table_ts.to_html())\n",
    "\n",
    "#     msg = MIMEMultipart(\"alternative\", None, [MIMEText(html, 'html')])\n",
    "#     msg['Subject'] = \"Testing Report Ecom \" + str(datetime.today().date().strftime('%B %d, %Y'))\n",
    "\n",
    "#     # part1 = MIMEText(text)\n",
    "#     # msg.attach(part1)\n",
    "\n",
    "#     # sending the mail \n",
    "#     s.sendmail(\"automationnfi@gmail.com\", ['timotius.giovandi@nutrifood.co.id'], msg.as_string()) \n",
    "# # ,\"andra.miftah@nutrifood.co.id\"\n",
    "#     # terminating the session\n",
    "#     s.quit()\n",
    "    import win32com.client\n",
    "    o = win32com.client.Dispatch(\"Outlook.Application\")\n",
    "    for oacc in o.Session.Accounts:\n",
    "        if oacc.SmtpAddress == \"customer@nutrifood.co.id\":\n",
    "            oacctouse = oacc\n",
    "            break\n",
    "    Msg = o.CreateItem(0)\n",
    "    if oacctouse:\n",
    "        Msg._oleobj_.Invoke(*(64209, 0, 8, 0, oacctouse))  # Msg.SendUsingAccount = oacctouseif to:\n",
    "\n",
    "        to = ['timotius.giovandi@nutrifood.co.id']\n",
    "\n",
    "        list_to = ';'.join(to)\n",
    "\n",
    "        Msg.To = list_to\n",
    "        Msg.Subject = \"Report E-commerce \" + \\\n",
    "        str(datetime.today().date().strftime('%B %d, %Y'))\n",
    "\n",
    "\n",
    "    html = '''\n",
    "    <html>\n",
    "    <head>\n",
    "    <style>\n",
    "\n",
    "        h2 {\n",
    "            text-align: center;\n",
    "            font-family: Helvetica, Arial, sans-serif;\n",
    "        }\n",
    "        table { \n",
    "            margin-left: auto;\n",
    "            margin-right: auto;\n",
    "        }\n",
    "        table, th, td {\n",
    "            border: 1px solid black;\n",
    "            border-collapse: collapse;\n",
    "        }\n",
    "        th, td {\n",
    "            padding: 5px;\n",
    "            text-align: center;\n",
    "            font-family: Helvetica, Arial, sans-serif;\n",
    "            font-size: 90%;\n",
    "        }\n",
    "        table tbody tr:hover {\n",
    "            background-color: #dddddd;\n",
    "        }\n",
    "        .wide {\n",
    "            width: 90%; \n",
    "        }\n",
    "        p\n",
    "\n",
    "    </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        '''\n",
    "    html = html + \"\"\"\n",
    "        <p> Dear all,</p>\n",
    "        <p> Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> dengan rincian channel sebagai berikut : </p>\n",
    "        <p> Channel Marketplace : Blibli, Bukalapak, Elevenia, JD Indonesia, Lazada, Nutrimart, Order Online, Shopee, Tokopedia, Aladin Mall, TikTok </p>\n",
    "        <p> Channel Retail : Cari Sayur, Emos, Farmaku, Inovasi Digital Niaga, Ritel Bersama Nasional, Sayurbox, Tanihub, Astro, Lifepack  </p>\n",
    "        <p> Notes: Mohon maaf ada keterlambatan data untuk retail online </p>\n",
    "\n",
    "    \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y')))\n",
    "\n",
    "    html = html + tblall.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p> Dan berikut data penjualan E-Com (Before PPN) per Area :</p>\n",
    "        \"\"\"\n",
    "\n",
    "    html = html + tblreg.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p> Dan Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> per Brand :</p>\n",
    "    \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y'))) \n",
    "\n",
    "\n",
    "    html = html + table_brand.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p> Dan berikut data penjualan E-Com (Before PPN) per Item :</p>\n",
    "        <p> Item Launching : </p>\"\"\"\n",
    "\n",
    "    html = html + new_table_launch.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> HiLo : </p>\"    \n",
    "\n",
    "    html = html + table_hilo.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> L-Men : </p>\"    \n",
    "\n",
    "    html = html + table_lmen.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> NutriSari : </p>\"    \n",
    "\n",
    "    html = html + table_ns.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> Tropicana Slim : </p>\"    \n",
    "\n",
    "    html = html + table_ts.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p></p>\n",
    "        <p> Best regards, </p>\n",
    "        <p> E-Commerce Nutrifood </p>\n",
    "    <body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    Msg.HTMLBody = html\n",
    "    Msg.Send()\n",
    "else :\n",
    "    print('Missing Parent Item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2101819360', 'HiLo Taro Latte Refill 500g']], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_single[all_single['Exported Parent Item'].isnull()]\n",
    "all_single[all_single['Exported Parent Item'] == 'nan'][['Real SKU','Real Nama Produk']].drop_duplicates().values\n",
    "\n",
    "# TS SOY LATTE 12Dx10Sx15G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Central Sulawesi'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ini cek kalau pembagian region sama total (tbl 1 & 2 Beda) update di file area utk report\n",
    "sales_region[(sales_region['Region Group'].notnull())&(~sales_region['Region Group'].isin(mappingarea['Region Group'].unique()))]['Region Group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 July With Order Online\n"
     ]
    }
   ],
   "source": [
    "# data_now=\"27 June With Order Online\"\n",
    "print(data_now)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.to_csv(r'Clean Data/data_all_' + data_now + 'a.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['PL Before PPN'] = data_all['Price List NFI']/1.1\n",
    "data_all.loc[data_all['True datetime']>='2022-04-01','PL Before PPN']= data_all['Price List NFI']/1.11\n",
    "data_all['Total Net Before PPN'] = data_all['PL Before PPN'] * data_all['Qty. Invoiced']\n",
    "data_all.to_csv(r'Clean Data/data_all_' + data_now + '.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Sub Brand</th>\n",
       "      <th>Exported Parent Item</th>\n",
       "      <th>Yesterday Sales</th>\n",
       "      <th>Local Sales</th>\n",
       "      <th>Projected</th>\n",
       "      <th>June 2022</th>\n",
       "      <th>May 2022</th>\n",
       "      <th>April 2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS CANOLA OIL 12BX946ML</td>\n",
       "      <td>Rp 6.131.236</td>\n",
       "      <td>Rp 48.111.436</td>\n",
       "      <td>Rp 248.575.754</td>\n",
       "      <td>Rp 227.539.999</td>\n",
       "      <td>Rp 184.325.999</td>\n",
       "      <td>Rp 205.033.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS CHOCOLATE SPREAD 12BTLX300G</td>\n",
       "      <td>Rp 4.732.636</td>\n",
       "      <td>Rp 44.500.909</td>\n",
       "      <td>Rp 229.921.363</td>\n",
       "      <td>Rp 199.103.153</td>\n",
       "      <td>Rp 142.520.000</td>\n",
       "      <td>Rp 145.810.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS BIRU</td>\n",
       "      <td>TS LOW FAT MILK VANILLA 12DX500G</td>\n",
       "      <td>Rp 8.854.772</td>\n",
       "      <td>Rp 40.535.181</td>\n",
       "      <td>Rp 209.431.772</td>\n",
       "      <td>Rp 189.929.999</td>\n",
       "      <td>Rp 152.100.000</td>\n",
       "      <td>Rp 187.849.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS SFD CAFE LATTE 12DX10S</td>\n",
       "      <td>Rp 5.000.550</td>\n",
       "      <td>Rp 34.896.886</td>\n",
       "      <td>Rp 180.300.579</td>\n",
       "      <td>Rp 166.155.000</td>\n",
       "      <td>Rp 152.030.500</td>\n",
       "      <td>Rp 151.341.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT DIABETICS 12DX100SX2G</td>\n",
       "      <td>Rp 3.602.454</td>\n",
       "      <td>Rp 31.715.727</td>\n",
       "      <td>Rp 163.864.590</td>\n",
       "      <td>Rp 269.500.000</td>\n",
       "      <td>Rp 129.919.999</td>\n",
       "      <td>Rp 342.159.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS JAM STRAWBERRY 12BTLX375G</td>\n",
       "      <td>Rp 5.247.272</td>\n",
       "      <td>Rp 31.090.090</td>\n",
       "      <td>Rp 160.632.136</td>\n",
       "      <td>Rp 152.486.486</td>\n",
       "      <td>Rp 101.789.414</td>\n",
       "      <td>Rp 99.254.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS HOKKAIDO CHEESE COOKIES 12DX5SX20G</td>\n",
       "      <td>Rp 5.548.990</td>\n",
       "      <td>Rp 30.106.227</td>\n",
       "      <td>Rp 155.548.840</td>\n",
       "      <td>Rp 156.643.500</td>\n",
       "      <td>Rp 127.549.499</td>\n",
       "      <td>Rp 194.453.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS CORN OIL 12BTLX946ML</td>\n",
       "      <td>Rp 2.147.345</td>\n",
       "      <td>Rp 27.608.727</td>\n",
       "      <td>Rp 142.645.090</td>\n",
       "      <td>Rp 120.003.999</td>\n",
       "      <td>Rp 100.471.999</td>\n",
       "      <td>Rp 129.579.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS EXTRA VIRGIN OLIVE OIL 12BTLX500ML</td>\n",
       "      <td>Rp 4.092.872</td>\n",
       "      <td>Rp 26.131.418</td>\n",
       "      <td>Rp 135.012.327</td>\n",
       "      <td>Rp 102.023.999</td>\n",
       "      <td>Rp 64.583.999</td>\n",
       "      <td>Rp 357.707.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT STEVIA 24DX50SX2.6G</td>\n",
       "      <td>Rp 4.827.490</td>\n",
       "      <td>Rp 23.673.272</td>\n",
       "      <td>Rp 122.311.909</td>\n",
       "      <td>Rp 107.501.999</td>\n",
       "      <td>Rp 68.724.000</td>\n",
       "      <td>Rp 87.997.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS BIRU</td>\n",
       "      <td>TS RTD OAT DRINK VANILLICIOUS 24PX190ML</td>\n",
       "      <td>Rp 4.302.763</td>\n",
       "      <td>Rp 20.726.727</td>\n",
       "      <td>Rp 107.088.090</td>\n",
       "      <td>Rp 103.044.499</td>\n",
       "      <td>Rp 87.515.999</td>\n",
       "      <td>Rp 90.349.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS BIRU</td>\n",
       "      <td>TS NFDM PLAIN 6DX1000G</td>\n",
       "      <td>Rp 3.945.545</td>\n",
       "      <td>Rp 20.070.818</td>\n",
       "      <td>Rp 103.699.227</td>\n",
       "      <td>Rp 72.080.000</td>\n",
       "      <td>Rp 76.160.000</td>\n",
       "      <td>Rp 67.490.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS SOY SAUCE 24BTLX200ML</td>\n",
       "      <td>Rp 2.800.227</td>\n",
       "      <td>Rp 19.071.818</td>\n",
       "      <td>Rp 98.537.727</td>\n",
       "      <td>Rp 105.549.999</td>\n",
       "      <td>Rp 111.249.999</td>\n",
       "      <td>Rp 119.724.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT CLASSIC 12DX100SX2.5G</td>\n",
       "      <td>Rp 1.555.009</td>\n",
       "      <td>Rp 18.862.936</td>\n",
       "      <td>Rp 97.458.504</td>\n",
       "      <td>Rp 108.807.999</td>\n",
       "      <td>Rp 86.094.999</td>\n",
       "      <td>Rp 105.792.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS GULA JAWA 12BX350ML</td>\n",
       "      <td>Rp 4.551.000</td>\n",
       "      <td>Rp 16.816.500</td>\n",
       "      <td>Rp 86.885.250</td>\n",
       "      <td>Rp 117.919.999</td>\n",
       "      <td>Rp 92.454.999</td>\n",
       "      <td>Rp 149.435.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS BIRU</td>\n",
       "      <td>TS NFDM CHOCOLATE 12DX500G</td>\n",
       "      <td>Rp 2.779.036</td>\n",
       "      <td>Rp 16.365.436</td>\n",
       "      <td>Rp 84.554.754</td>\n",
       "      <td>Rp 66.911.999</td>\n",
       "      <td>Rp 52.733.999</td>\n",
       "      <td>Rp 54.263.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS BIRU</td>\n",
       "      <td>TS LOW FAT MILK MACCHIATO COFFEE 12DX500G</td>\n",
       "      <td>Rp 3.345.136</td>\n",
       "      <td>Rp 16.135.363</td>\n",
       "      <td>Rp 83.366.045</td>\n",
       "      <td>Rp 69.355.000</td>\n",
       "      <td>Rp 56.354.999</td>\n",
       "      <td>Rp 75.335.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS BIRU</td>\n",
       "      <td>TS NFDM COFFEE 12DX500G</td>\n",
       "      <td>Rp 3.808.309</td>\n",
       "      <td>Rp 15.542.018</td>\n",
       "      <td>Rp 80.300.427</td>\n",
       "      <td>Rp 67.626.000</td>\n",
       "      <td>Rp 53.345.999</td>\n",
       "      <td>Rp 64.361.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT DIABETICS 24DX50SX2G</td>\n",
       "      <td>Rp 1.810.309</td>\n",
       "      <td>Rp 15.308.918</td>\n",
       "      <td>Rp 79.096.077</td>\n",
       "      <td>Rp 230.567.999</td>\n",
       "      <td>Rp 162.864.000</td>\n",
       "      <td>Rp 303.693.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT CLASSIC 12DX500G</td>\n",
       "      <td>Rp 1.561.063</td>\n",
       "      <td>Rp 12.763.990</td>\n",
       "      <td>Rp 65.947.286</td>\n",
       "      <td>Rp 70.707.000</td>\n",
       "      <td>Rp 57.875.999</td>\n",
       "      <td>Rp 62.425.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS DM COOKIES CHOCO 12DX10SX20G</td>\n",
       "      <td>Rp 2.538.872</td>\n",
       "      <td>Rp 12.022.309</td>\n",
       "      <td>Rp 62.115.263</td>\n",
       "      <td>Rp 66.710.999</td>\n",
       "      <td>Rp 53.057.999</td>\n",
       "      <td>Rp 93.683.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT CLASSIC 24DX50SX2.5G</td>\n",
       "      <td>Rp 1.194.763</td>\n",
       "      <td>Rp 11.835.627</td>\n",
       "      <td>Rp 61.150.740</td>\n",
       "      <td>Rp 90.279.999</td>\n",
       "      <td>Rp 82.658.000</td>\n",
       "      <td>Rp 82.325.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS HONEY 12BTLX350ML</td>\n",
       "      <td>Rp 1.664.999</td>\n",
       "      <td>Rp 11.155.500</td>\n",
       "      <td>Rp 57.636.750</td>\n",
       "      <td>Rp 65.559.999</td>\n",
       "      <td>Rp 67.925.000</td>\n",
       "      <td>Rp 63.909.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS COOKIES KLEPON 12DX5SX20G</td>\n",
       "      <td>Rp 1.652.890</td>\n",
       "      <td>Rp 10.763.468</td>\n",
       "      <td>Rp 55.611.252</td>\n",
       "      <td>Rp 51.421.499</td>\n",
       "      <td>Rp 48.964.499</td>\n",
       "      <td>Rp 87.944.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS AVOCADO COFFEE 12DX4SX14G</td>\n",
       "      <td>Rp 1.719.490</td>\n",
       "      <td>Rp 10.329.054</td>\n",
       "      <td>Rp 53.366.781</td>\n",
       "      <td>Rp 67.200.000</td>\n",
       "      <td>Rp 52.799.999</td>\n",
       "      <td>Rp 80.940.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS MINT COCOA 12DX4SX15G</td>\n",
       "      <td>Rp 2.013.136</td>\n",
       "      <td>Rp 9.445.090</td>\n",
       "      <td>Rp 48.799.636</td>\n",
       "      <td>Rp 51.989.999</td>\n",
       "      <td>Rp 66.719.999</td>\n",
       "      <td>Rp 243.734.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS WHITE COFFEE 12DX4SX15G</td>\n",
       "      <td>Rp 900.613</td>\n",
       "      <td>Rp 9.324.000</td>\n",
       "      <td>Rp 48.174.000</td>\n",
       "      <td>Rp 54.608.693</td>\n",
       "      <td>Rp 40.177.770</td>\n",
       "      <td>Rp 55.224.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS KOREAN GOGUMA COOKIES 12DX5SX20G</td>\n",
       "      <td>Rp 1.397.086</td>\n",
       "      <td>Rp 9.130.254</td>\n",
       "      <td>Rp 47.172.981</td>\n",
       "      <td>Rp 38.649.000</td>\n",
       "      <td>Rp 35.256.000</td>\n",
       "      <td>Rp 68.328.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS BIRU</td>\n",
       "      <td>TS NFDM OMEGA FIBER PLAIN 6DX500G</td>\n",
       "      <td>Rp 617.563</td>\n",
       "      <td>Rp 8.748.818</td>\n",
       "      <td>Rp 45.202.227</td>\n",
       "      <td>Rp 36.108.000</td>\n",
       "      <td>Rp 31.007.999</td>\n",
       "      <td>Rp 31.925.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS BIRU</td>\n",
       "      <td>TS DM CHOCOLATE 12DX500G</td>\n",
       "      <td>Rp 720.490</td>\n",
       "      <td>Rp 7.925.399</td>\n",
       "      <td>Rp 40.947.899</td>\n",
       "      <td>Rp 20.502.000</td>\n",
       "      <td>Rp 22.541.999</td>\n",
       "      <td>Rp 29.375.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS KENTAL MANIS 24BTLX150ML</td>\n",
       "      <td>Rp 1.280.536</td>\n",
       "      <td>Rp 6.811.363</td>\n",
       "      <td>Rp 35.192.045</td>\n",
       "      <td>Rp 42.848.999</td>\n",
       "      <td>Rp 34.020.000</td>\n",
       "      <td>Rp 55.268.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G</td>\n",
       "      <td>Rp 1.121.604</td>\n",
       "      <td>Rp 6.788.659</td>\n",
       "      <td>Rp 35.074.738</td>\n",
       "      <td>Rp 39.078.000</td>\n",
       "      <td>Rp 30.166.499</td>\n",
       "      <td>Rp 63.862.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS SAUS TIRAM 24BTLX200ML</td>\n",
       "      <td>Rp 1.041.381</td>\n",
       "      <td>Rp 5.885.018</td>\n",
       "      <td>Rp 30.405.927</td>\n",
       "      <td>Rp 41.424.000</td>\n",
       "      <td>Rp 47.519.999</td>\n",
       "      <td>Rp 61.079.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS SHIRATAKI NOODLES 40PX71G</td>\n",
       "      <td>Rp 914.740</td>\n",
       "      <td>Rp 5.805.804</td>\n",
       "      <td>Rp 29.996.656</td>\n",
       "      <td>Rp 32.152.999</td>\n",
       "      <td>Rp 28.804.166</td>\n",
       "      <td>Rp 29.673.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS SYRUP COCOPANDAN 12BTLX750ML</td>\n",
       "      <td>Rp 593.345</td>\n",
       "      <td>Rp 5.650.909</td>\n",
       "      <td>Rp 29.196.363</td>\n",
       "      <td>Rp 32.283.999</td>\n",
       "      <td>Rp 25.479.999</td>\n",
       "      <td>Rp 139.020.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS MAYONNAISE ROASTED SESAME 24BTLX200G</td>\n",
       "      <td>Rp 741.681</td>\n",
       "      <td>Rp 5.170.390</td>\n",
       "      <td>Rp 26.713.686</td>\n",
       "      <td>Rp 36.076.108</td>\n",
       "      <td>Rp 31.520.999</td>\n",
       "      <td>Rp 45.694.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS SAMBAL TERASI 24BTLX200G</td>\n",
       "      <td>Rp 844.581</td>\n",
       "      <td>Rp 4.875.309</td>\n",
       "      <td>Rp 25.189.096</td>\n",
       "      <td>Rp 40.832.828</td>\n",
       "      <td>Rp 18.452.000</td>\n",
       "      <td>Rp 15.371.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS SFD SWEET ORANGE 12DX10SX6G</td>\n",
       "      <td>Rp 776.999</td>\n",
       "      <td>Rp 4.485.409</td>\n",
       "      <td>Rp 23.174.613</td>\n",
       "      <td>Rp 23.607.499</td>\n",
       "      <td>Rp 24.254.999</td>\n",
       "      <td>Rp 36.540.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT CLASSIC IND 8PX160SX2.5G</td>\n",
       "      <td>Rp 626.645</td>\n",
       "      <td>Rp 4.386.518</td>\n",
       "      <td>Rp 22.663.677</td>\n",
       "      <td>Rp 18.147.000</td>\n",
       "      <td>Rp 12.074.999</td>\n",
       "      <td>Rp 14.144.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS SUNFLOWER OIL 12BTLX946ML</td>\n",
       "      <td>Rp 418.314</td>\n",
       "      <td>Rp 4.043.707</td>\n",
       "      <td>Rp 20.892.487</td>\n",
       "      <td>Rp 10.709.103</td>\n",
       "      <td>Rp 11.192.740</td>\n",
       "      <td>Rp 31.574.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS SALTY SOY SAUCE 24BTLX200ML</td>\n",
       "      <td>Rp 417.763</td>\n",
       "      <td>Rp 3.806.290</td>\n",
       "      <td>Rp 19.665.836</td>\n",
       "      <td>Rp 27.139.999</td>\n",
       "      <td>Rp 17.572.000</td>\n",
       "      <td>Rp 19.895.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS SYRUP LYCHEE 12BTLX750ML</td>\n",
       "      <td>Rp 649.854</td>\n",
       "      <td>Rp 3.786.109</td>\n",
       "      <td>Rp 19.561.563</td>\n",
       "      <td>Rp 16.771.999</td>\n",
       "      <td>Rp 18.928.000</td>\n",
       "      <td>Rp 71.428.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS SHIRATAKI RICE RASA NASI UDUK 24PX72G</td>\n",
       "      <td>Rp 408.681</td>\n",
       "      <td>Rp 3.705.381</td>\n",
       "      <td>Rp 19.144.472</td>\n",
       "      <td>Rp 20.790.000</td>\n",
       "      <td>Rp 18.873.000</td>\n",
       "      <td>Rp 28.295.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS SANTAN 24DX5SX20G</td>\n",
       "      <td>Rp 746.222</td>\n",
       "      <td>Rp 3.438.477</td>\n",
       "      <td>Rp 17.765.465</td>\n",
       "      <td>Rp 17.516.000</td>\n",
       "      <td>Rp 15.688.999</td>\n",
       "      <td>Rp 29.188.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TS</td>\n",
       "      <td>DIABETAMIL</td>\n",
       "      <td>DIABETAMIL MILK VANILLA 12Dx150G</td>\n",
       "      <td>Rp 1.008.081</td>\n",
       "      <td>Rp 3.133.227</td>\n",
       "      <td>Rp 16.188.340</td>\n",
       "      <td>Rp 14.822.999</td>\n",
       "      <td>Rp 9.639.000</td>\n",
       "      <td>Rp 19.278.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT I SWEET 12DX25SX2.5G</td>\n",
       "      <td>Rp 399.599</td>\n",
       "      <td>Rp 2.974.799</td>\n",
       "      <td>Rp 15.369.799</td>\n",
       "      <td>Rp 15.641.999</td>\n",
       "      <td>Rp 10.274.000</td>\n",
       "      <td>Rp 18.480.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT LEMON-C 12DX25SX2.5G</td>\n",
       "      <td>Rp 666.000</td>\n",
       "      <td>Rp 2.641.800</td>\n",
       "      <td>Rp 13.649.300</td>\n",
       "      <td>Rp 7.633.999</td>\n",
       "      <td>Rp 8.624.000</td>\n",
       "      <td>Rp 9.240.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS SYRUP ORANGE 12BTLX750ML</td>\n",
       "      <td>Rp 395.563</td>\n",
       "      <td>Rp 2.627.672</td>\n",
       "      <td>Rp 13.576.309</td>\n",
       "      <td>Rp 15.399.999</td>\n",
       "      <td>Rp 17.192.000</td>\n",
       "      <td>Rp 106.063.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS MERAH</td>\n",
       "      <td>TS INSTANT CAKE MIX BROWNIES 12Dx230G</td>\n",
       "      <td>Rp 326.945</td>\n",
       "      <td>Rp 1.743.709</td>\n",
       "      <td>Rp 9.009.163</td>\n",
       "      <td>Rp 10.557.000</td>\n",
       "      <td>Rp 8.072.999</td>\n",
       "      <td>Rp 16.550.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT HONEY 24DX50SX2.5G</td>\n",
       "      <td>Rp 511.609</td>\n",
       "      <td>Rp 1.180.636</td>\n",
       "      <td>Rp 6.099.954</td>\n",
       "      <td>Rp 6.590.999</td>\n",
       "      <td>Rp 6.473.999</td>\n",
       "      <td>Rp 7.448.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT DIABETICS INDUSTRIAL 8PX150S</td>\n",
       "      <td>Rp 0</td>\n",
       "      <td>Rp 558.027</td>\n",
       "      <td>Rp 2.883.140</td>\n",
       "      <td>Rp 6.003.999</td>\n",
       "      <td>Rp 4.661.000</td>\n",
       "      <td>Rp 2.843.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS BIRU</td>\n",
       "      <td>TS GOLDENMIL VANILLA 12DX6SX30G</td>\n",
       "      <td>Rp 0</td>\n",
       "      <td>Rp 497.481</td>\n",
       "      <td>Rp 2.570.322</td>\n",
       "      <td>Rp 3.566.999</td>\n",
       "      <td>Rp 1.536.999</td>\n",
       "      <td>Rp 2.725.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT ROSE VANILLA 24DX50SX2G</td>\n",
       "      <td>Rp 118.063</td>\n",
       "      <td>Rp 432.899</td>\n",
       "      <td>Rp 2.236.649</td>\n",
       "      <td>Rp 7.526.999</td>\n",
       "      <td>Rp 4.251.000</td>\n",
       "      <td>Rp 4.212.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT JAHE 24Dx50SX2.5G</td>\n",
       "      <td>Rp 39.354</td>\n",
       "      <td>Rp 275.481</td>\n",
       "      <td>Rp 1.423.322</td>\n",
       "      <td>Rp 1.481.999</td>\n",
       "      <td>Rp 701.999</td>\n",
       "      <td>Rp 273.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT CLASSIC INDUSTRIAL 12PX125SX2.5G</td>\n",
       "      <td>Rp 0</td>\n",
       "      <td>Rp 262.363</td>\n",
       "      <td>Rp 1.355.545</td>\n",
       "      <td>Rp 585.000</td>\n",
       "      <td>Rp 519.999</td>\n",
       "      <td>Rp 194.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT CLASSIC STICK IND 12PX100SX2.5G</td>\n",
       "      <td>Rp 43.390</td>\n",
       "      <td>Rp 216.954</td>\n",
       "      <td>Rp 1.120.931</td>\n",
       "      <td>Rp 2.751.999</td>\n",
       "      <td>Rp 429.999</td>\n",
       "      <td>Rp 1.418.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>TS</td>\n",
       "      <td>TS KUNING - SWT POWDER</td>\n",
       "      <td>TS SWT DIABETICS 12DX25SX2G</td>\n",
       "      <td>Rp 0</td>\n",
       "      <td>Rp 0</td>\n",
       "      <td>Rp 0</td>\n",
       "      <td>Rp 71.820.000</td>\n",
       "      <td>Rp 35.532.000</td>\n",
       "      <td>Rp 185.219.999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand               Sub Brand                        Exported Parent Item  \\\n",
       "0     TS                TS MERAH                     TS CANOLA OIL 12BX946ML   \n",
       "1     TS        TS KUNING OTHERS              TS CHOCOLATE SPREAD 12BTLX300G   \n",
       "2     TS                 TS BIRU            TS LOW FAT MILK VANILLA 12DX500G   \n",
       "3     TS        TS KUNING OTHERS                   TS SFD CAFE LATTE 12DX10S   \n",
       "4     TS  TS KUNING - SWT POWDER                TS SWT DIABETICS 12DX100SX2G   \n",
       "5     TS        TS KUNING OTHERS                TS JAM STRAWBERRY 12BTLX375G   \n",
       "6     TS        TS KUNING OTHERS       TS HOKKAIDO CHEESE COOKIES 12DX5SX20G   \n",
       "7     TS                TS MERAH                     TS CORN OIL 12BTLX946ML   \n",
       "8     TS                TS MERAH       TS EXTRA VIRGIN OLIVE OIL 12BTLX500ML   \n",
       "9     TS  TS KUNING - SWT POWDER                  TS SWT STEVIA 24DX50SX2.6G   \n",
       "10    TS                 TS BIRU     TS RTD OAT DRINK VANILLICIOUS 24PX190ML   \n",
       "11    TS                 TS BIRU                      TS NFDM PLAIN 6DX1000G   \n",
       "12    TS                TS MERAH                    TS SOY SAUCE 24BTLX200ML   \n",
       "13    TS  TS KUNING - SWT POWDER                TS SWT CLASSIC 12DX100SX2.5G   \n",
       "14    TS        TS KUNING OTHERS                      TS GULA JAWA 12BX350ML   \n",
       "15    TS                 TS BIRU                  TS NFDM CHOCOLATE 12DX500G   \n",
       "16    TS                 TS BIRU   TS LOW FAT MILK MACCHIATO COFFEE 12DX500G   \n",
       "17    TS                 TS BIRU                     TS NFDM COFFEE 12DX500G   \n",
       "18    TS  TS KUNING - SWT POWDER                 TS SWT DIABETICS 24DX50SX2G   \n",
       "19    TS  TS KUNING - SWT POWDER                     TS SWT CLASSIC 12DX500G   \n",
       "20    TS        TS KUNING OTHERS             TS DM COOKIES CHOCO 12DX10SX20G   \n",
       "21    TS  TS KUNING - SWT POWDER                 TS SWT CLASSIC 24DX50SX2.5G   \n",
       "22    TS        TS KUNING OTHERS                        TS HONEY 12BTLX350ML   \n",
       "23    TS        TS KUNING OTHERS                TS COOKIES KLEPON 12DX5SX20G   \n",
       "24    TS        TS KUNING OTHERS                TS AVOCADO COFFEE 12DX4SX14G   \n",
       "25    TS        TS KUNING OTHERS                    TS MINT COCOA 12DX4SX15G   \n",
       "26    TS        TS KUNING OTHERS                  TS WHITE COFFEE 12DX4SX15G   \n",
       "27    TS        TS KUNING OTHERS         TS KOREAN GOGUMA COOKIES 12DX5SX20G   \n",
       "28    TS                 TS BIRU           TS NFDM OMEGA FIBER PLAIN 6DX500G   \n",
       "29    TS                 TS BIRU                    TS DM CHOCOLATE 12DX500G   \n",
       "30    TS        TS KUNING OTHERS                 TS KENTAL MANIS 24BTLX150ML   \n",
       "31    TS        TS KUNING OTHERS  TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G   \n",
       "32    TS                TS MERAH                   TS SAUS TIRAM 24BTLX200ML   \n",
       "33    TS                TS MERAH                TS SHIRATAKI NOODLES 40PX71G   \n",
       "34    TS        TS KUNING OTHERS             TS SYRUP COCOPANDAN 12BTLX750ML   \n",
       "35    TS                TS MERAH     TS MAYONNAISE ROASTED SESAME 24BTLX200G   \n",
       "36    TS                TS MERAH                 TS SAMBAL TERASI 24BTLX200G   \n",
       "37    TS        TS KUNING OTHERS              TS SFD SWEET ORANGE 12DX10SX6G   \n",
       "38    TS  TS KUNING - SWT POWDER             TS SWT CLASSIC IND 8PX160SX2.5G   \n",
       "39    TS                TS MERAH                TS SUNFLOWER OIL 12BTLX946ML   \n",
       "40    TS                TS MERAH              TS SALTY SOY SAUCE 24BTLX200ML   \n",
       "41    TS        TS KUNING OTHERS                 TS SYRUP LYCHEE 12BTLX750ML   \n",
       "42    TS                TS MERAH    TS SHIRATAKI RICE RASA NASI UDUK 24PX72G   \n",
       "43    TS                TS MERAH                        TS SANTAN 24DX5SX20G   \n",
       "44    TS              DIABETAMIL            DIABETAMIL MILK VANILLA 12Dx150G   \n",
       "45    TS  TS KUNING - SWT POWDER                 TS SWT I SWEET 12DX25SX2.5G   \n",
       "46    TS  TS KUNING - SWT POWDER                 TS SWT LEMON-C 12DX25SX2.5G   \n",
       "47    TS        TS KUNING OTHERS                 TS SYRUP ORANGE 12BTLX750ML   \n",
       "48    TS                TS MERAH       TS INSTANT CAKE MIX BROWNIES 12Dx230G   \n",
       "49    TS  TS KUNING - SWT POWDER                   TS SWT HONEY 24DX50SX2.5G   \n",
       "50    TS  TS KUNING - SWT POWDER         TS SWT DIABETICS INDUSTRIAL 8PX150S   \n",
       "51    TS                 TS BIRU             TS GOLDENMIL VANILLA 12DX6SX30G   \n",
       "52    TS  TS KUNING - SWT POWDER              TS SWT ROSE VANILLA 24DX50SX2G   \n",
       "53    TS  TS KUNING - SWT POWDER                    TS SWT JAHE 24Dx50SX2.5G   \n",
       "54    TS  TS KUNING - SWT POWDER     TS SWT CLASSIC INDUSTRIAL 12PX125SX2.5G   \n",
       "55    TS  TS KUNING - SWT POWDER      TS SWT CLASSIC STICK IND 12PX100SX2.5G   \n",
       "56    TS  TS KUNING - SWT POWDER                 TS SWT DIABETICS 12DX25SX2G   \n",
       "\n",
       "   Yesterday Sales    Local Sales       Projected       June 2022  \\\n",
       "0     Rp 6.131.236  Rp 48.111.436  Rp 248.575.754  Rp 227.539.999   \n",
       "1     Rp 4.732.636  Rp 44.500.909  Rp 229.921.363  Rp 199.103.153   \n",
       "2     Rp 8.854.772  Rp 40.535.181  Rp 209.431.772  Rp 189.929.999   \n",
       "3     Rp 5.000.550  Rp 34.896.886  Rp 180.300.579  Rp 166.155.000   \n",
       "4     Rp 3.602.454  Rp 31.715.727  Rp 163.864.590  Rp 269.500.000   \n",
       "5     Rp 5.247.272  Rp 31.090.090  Rp 160.632.136  Rp 152.486.486   \n",
       "6     Rp 5.548.990  Rp 30.106.227  Rp 155.548.840  Rp 156.643.500   \n",
       "7     Rp 2.147.345  Rp 27.608.727  Rp 142.645.090  Rp 120.003.999   \n",
       "8     Rp 4.092.872  Rp 26.131.418  Rp 135.012.327  Rp 102.023.999   \n",
       "9     Rp 4.827.490  Rp 23.673.272  Rp 122.311.909  Rp 107.501.999   \n",
       "10    Rp 4.302.763  Rp 20.726.727  Rp 107.088.090  Rp 103.044.499   \n",
       "11    Rp 3.945.545  Rp 20.070.818  Rp 103.699.227   Rp 72.080.000   \n",
       "12    Rp 2.800.227  Rp 19.071.818   Rp 98.537.727  Rp 105.549.999   \n",
       "13    Rp 1.555.009  Rp 18.862.936   Rp 97.458.504  Rp 108.807.999   \n",
       "14    Rp 4.551.000  Rp 16.816.500   Rp 86.885.250  Rp 117.919.999   \n",
       "15    Rp 2.779.036  Rp 16.365.436   Rp 84.554.754   Rp 66.911.999   \n",
       "16    Rp 3.345.136  Rp 16.135.363   Rp 83.366.045   Rp 69.355.000   \n",
       "17    Rp 3.808.309  Rp 15.542.018   Rp 80.300.427   Rp 67.626.000   \n",
       "18    Rp 1.810.309  Rp 15.308.918   Rp 79.096.077  Rp 230.567.999   \n",
       "19    Rp 1.561.063  Rp 12.763.990   Rp 65.947.286   Rp 70.707.000   \n",
       "20    Rp 2.538.872  Rp 12.022.309   Rp 62.115.263   Rp 66.710.999   \n",
       "21    Rp 1.194.763  Rp 11.835.627   Rp 61.150.740   Rp 90.279.999   \n",
       "22    Rp 1.664.999  Rp 11.155.500   Rp 57.636.750   Rp 65.559.999   \n",
       "23    Rp 1.652.890  Rp 10.763.468   Rp 55.611.252   Rp 51.421.499   \n",
       "24    Rp 1.719.490  Rp 10.329.054   Rp 53.366.781   Rp 67.200.000   \n",
       "25    Rp 2.013.136   Rp 9.445.090   Rp 48.799.636   Rp 51.989.999   \n",
       "26      Rp 900.613   Rp 9.324.000   Rp 48.174.000   Rp 54.608.693   \n",
       "27    Rp 1.397.086   Rp 9.130.254   Rp 47.172.981   Rp 38.649.000   \n",
       "28      Rp 617.563   Rp 8.748.818   Rp 45.202.227   Rp 36.108.000   \n",
       "29      Rp 720.490   Rp 7.925.399   Rp 40.947.899   Rp 20.502.000   \n",
       "30    Rp 1.280.536   Rp 6.811.363   Rp 35.192.045   Rp 42.848.999   \n",
       "31    Rp 1.121.604   Rp 6.788.659   Rp 35.074.738   Rp 39.078.000   \n",
       "32    Rp 1.041.381   Rp 5.885.018   Rp 30.405.927   Rp 41.424.000   \n",
       "33      Rp 914.740   Rp 5.805.804   Rp 29.996.656   Rp 32.152.999   \n",
       "34      Rp 593.345   Rp 5.650.909   Rp 29.196.363   Rp 32.283.999   \n",
       "35      Rp 741.681   Rp 5.170.390   Rp 26.713.686   Rp 36.076.108   \n",
       "36      Rp 844.581   Rp 4.875.309   Rp 25.189.096   Rp 40.832.828   \n",
       "37      Rp 776.999   Rp 4.485.409   Rp 23.174.613   Rp 23.607.499   \n",
       "38      Rp 626.645   Rp 4.386.518   Rp 22.663.677   Rp 18.147.000   \n",
       "39      Rp 418.314   Rp 4.043.707   Rp 20.892.487   Rp 10.709.103   \n",
       "40      Rp 417.763   Rp 3.806.290   Rp 19.665.836   Rp 27.139.999   \n",
       "41      Rp 649.854   Rp 3.786.109   Rp 19.561.563   Rp 16.771.999   \n",
       "42      Rp 408.681   Rp 3.705.381   Rp 19.144.472   Rp 20.790.000   \n",
       "43      Rp 746.222   Rp 3.438.477   Rp 17.765.465   Rp 17.516.000   \n",
       "44    Rp 1.008.081   Rp 3.133.227   Rp 16.188.340   Rp 14.822.999   \n",
       "45      Rp 399.599   Rp 2.974.799   Rp 15.369.799   Rp 15.641.999   \n",
       "46      Rp 666.000   Rp 2.641.800   Rp 13.649.300    Rp 7.633.999   \n",
       "47      Rp 395.563   Rp 2.627.672   Rp 13.576.309   Rp 15.399.999   \n",
       "48      Rp 326.945   Rp 1.743.709    Rp 9.009.163   Rp 10.557.000   \n",
       "49      Rp 511.609   Rp 1.180.636    Rp 6.099.954    Rp 6.590.999   \n",
       "50            Rp 0     Rp 558.027    Rp 2.883.140    Rp 6.003.999   \n",
       "51            Rp 0     Rp 497.481    Rp 2.570.322    Rp 3.566.999   \n",
       "52      Rp 118.063     Rp 432.899    Rp 2.236.649    Rp 7.526.999   \n",
       "53       Rp 39.354     Rp 275.481    Rp 1.423.322    Rp 1.481.999   \n",
       "54            Rp 0     Rp 262.363    Rp 1.355.545      Rp 585.000   \n",
       "55       Rp 43.390     Rp 216.954    Rp 1.120.931    Rp 2.751.999   \n",
       "56            Rp 0           Rp 0            Rp 0   Rp 71.820.000   \n",
       "\n",
       "          May 2022      April 2022  \n",
       "0   Rp 184.325.999  Rp 205.033.999  \n",
       "1   Rp 142.520.000  Rp 145.810.000  \n",
       "2   Rp 152.100.000  Rp 187.849.999  \n",
       "3   Rp 152.030.500  Rp 151.341.500  \n",
       "4   Rp 129.919.999  Rp 342.159.999  \n",
       "5   Rp 101.789.414   Rp 99.254.999  \n",
       "6   Rp 127.549.499  Rp 194.453.999  \n",
       "7   Rp 100.471.999  Rp 129.579.999  \n",
       "8    Rp 64.583.999  Rp 357.707.999  \n",
       "9    Rp 68.724.000   Rp 87.997.999  \n",
       "10   Rp 87.515.999   Rp 90.349.999  \n",
       "11   Rp 76.160.000   Rp 67.490.000  \n",
       "12  Rp 111.249.999  Rp 119.724.999  \n",
       "13   Rp 86.094.999  Rp 105.792.999  \n",
       "14   Rp 92.454.999  Rp 149.435.000  \n",
       "15   Rp 52.733.999   Rp 54.263.999  \n",
       "16   Rp 56.354.999   Rp 75.335.000  \n",
       "17   Rp 53.345.999   Rp 64.361.999  \n",
       "18  Rp 162.864.000  Rp 303.693.000  \n",
       "19   Rp 57.875.999   Rp 62.425.999  \n",
       "20   Rp 53.057.999   Rp 93.683.999  \n",
       "21   Rp 82.658.000   Rp 82.325.000  \n",
       "22   Rp 67.925.000   Rp 63.909.999  \n",
       "23   Rp 48.964.499   Rp 87.944.999  \n",
       "24   Rp 52.799.999   Rp 80.940.000  \n",
       "25   Rp 66.719.999  Rp 243.734.999  \n",
       "26   Rp 40.177.770   Rp 55.224.481  \n",
       "27   Rp 35.256.000   Rp 68.328.000  \n",
       "28   Rp 31.007.999   Rp 31.925.999  \n",
       "29   Rp 22.541.999   Rp 29.375.999  \n",
       "30   Rp 34.020.000   Rp 55.268.513  \n",
       "31   Rp 30.166.499   Rp 63.862.499  \n",
       "32   Rp 47.519.999   Rp 61.079.999  \n",
       "33   Rp 28.804.166   Rp 29.673.999  \n",
       "34   Rp 25.479.999  Rp 139.020.000  \n",
       "35   Rp 31.520.999   Rp 45.694.108  \n",
       "36   Rp 18.452.000   Rp 15.371.999  \n",
       "37   Rp 24.254.999   Rp 36.540.000  \n",
       "38   Rp 12.074.999   Rp 14.144.999  \n",
       "39   Rp 11.192.740   Rp 31.574.582  \n",
       "40   Rp 17.572.000   Rp 19.895.000  \n",
       "41   Rp 18.928.000   Rp 71.428.000  \n",
       "42   Rp 18.873.000   Rp 28.295.999  \n",
       "43   Rp 15.688.999   Rp 29.188.499  \n",
       "44    Rp 9.639.000   Rp 19.278.000  \n",
       "45   Rp 10.274.000   Rp 18.480.000  \n",
       "46    Rp 8.624.000    Rp 9.240.000  \n",
       "47   Rp 17.192.000  Rp 106.063.999  \n",
       "48    Rp 8.072.999   Rp 16.550.999  \n",
       "49    Rp 6.473.999    Rp 7.448.999  \n",
       "50    Rp 4.661.000    Rp 2.843.999  \n",
       "51    Rp 1.536.999    Rp 2.725.999  \n",
       "52    Rp 4.251.000    Rp 4.212.000  \n",
       "53      Rp 701.999      Rp 273.000  \n",
       "54      Rp 519.999      Rp 194.999  \n",
       "55      Rp 429.999    Rp 1.418.999  \n",
       "56   Rp 35.532.000  Rp 185.219.999  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buang = ['PAKET HILO']\n",
    "table_brand = table_brand[~table_brand['Sub Brand'].isin(buang)]\n",
    "table_hilo = table_hilo[~table_hilo['Sub Brand'].isin(buang)]\n",
    "table_hilo\n",
    "\n",
    "buang = ['PAKET TS']\n",
    "table_brand = table_brand[~table_brand['Sub Brand'].isin(buang)]\n",
    "table_ts = table_ts[~table_ts['Sub Brand'].isin(buang)]\n",
    "table_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "\n",
    "o = win32com.client.Dispatch(\"Outlook.Application\")\n",
    "for oacc in o.Session.Accounts:\n",
    "    if oacc.SmtpAddress == \"customer@nutrifood.co.id\":\n",
    "        oacctouse = oacc\n",
    "        break\n",
    "\n",
    "Msg = o.CreateItem(0)\n",
    "if oacctouse:\n",
    "    Msg._oleobj_.Invoke(*(64209, 0, 8, 0, oacctouse))  # Msg.SendUsingAccount = oacctouseif to:\n",
    "    \n",
    "    to=[\"andra.miftah@nutrifood.co.id\",\"zakaria@nutrifood.co.id\",\"geovano.satria@nutrifood.co.id\",\"didit@nutrifood.co.id\",\"agus_s@nutrifood.co.id\", \n",
    "        \"romi.anggara@nutrifood.co.id\",\"manthovani.annice@nutrifood.co.id\", \"edward@nutrifood.co.id\", \"elisa.putri@nutrifood.co.id\", \"Elvina@nutrifood.co.id\", \n",
    "        \"geny.pitaloka@nutrifood.co.id\", \"christian.jesaya@nutrifood.co.id\", \"joshua.suhendro@nutrifood.co.id\", \"lisa.arianti@nutrifood.co.id\", \n",
    "        \"stephanie.wonoadi@nutrifood.co.id\", \"mardi@nutrifood.co.id\", \"Meirza@nutrifood.co.id\", \"noviana@nutrifood.co.id\", \"susana@nutrifood.co.id\", \n",
    "        \"teddy.andreas@nutrifood.co.id\", \"muroby.rocky@nutrifood.co.id\", \"ignasius.dwi@nutrifood.co.id\", \"may@nutrifood.co.id\", \"evelyn@nutrifood.co.id\", \n",
    "        \"reynald.tjandra@nutrifood.co.id\", \"sheila.odilia@nutrifood.co.id\", \"timotius.giovandi@nutrifood.co.id\", \"novita.vidianti@nutrifood.co.id\", \n",
    "        \"elvira@nutrifood.co.id\", 'ronaldo.yolanda@nutrifood.co.id', 'bagus.sindhu@nutrifood.co.id',\n",
    "        \"sony.hartono@nutrifood.co.id\",'christovertand.wim@nutrifood.co.id','steven.nathanael@nutrifood.co.id']\n",
    "    # to = ['timotius.giovandi@nutrifood.co.id']\n",
    "\n",
    "    list_to = ';'.join(to)\n",
    "\n",
    "    Msg.To = list_to\n",
    "    Msg.Subject = \"Report E-commerce \" + \\\n",
    "    str(datetime.today().date().strftime('%B %d, %Y'))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "\n",
    "    h2 {\n",
    "        text-align: center;\n",
    "        font-family: Helvetica, Arial, sans-serif;\n",
    "    }\n",
    "    table { \n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "    }\n",
    "    table, th, td {\n",
    "        border: 1px solid black;\n",
    "        border-collapse: collapse;\n",
    "    }\n",
    "    th, td {\n",
    "        padding: 5px;\n",
    "        text-align: center;\n",
    "        font-family: Helvetica, Arial, sans-serif;\n",
    "        font-size: 90%;\n",
    "    }\n",
    "    table tbody tr:hover {\n",
    "        background-color: #dddddd;\n",
    "    }\n",
    "    .wide {\n",
    "        width: 90%; \n",
    "    }\n",
    "    p\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "    '''\n",
    "html = html + \"\"\"\n",
    "    <p> Dear all,</p>\n",
    "    <p> Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> dengan rincian channel sebagai berikut : </p>\n",
    "    <p> Channel Marketplace : Blibli, Bukalapak, Elevenia, JD Indonesia, Lazada, Nutrimart, Order Online, Shopee, Tokopedia, Aladin Mall, TikTok </p>\n",
    "    <p> Channel Retail : Cari Sayur, Emos, Farmaku, Inovasi Digital Niaga, Ritel Bersama Nasional, Sayurbox, Tanihub, Astro, Lifepack  </p>\n",
    "    <p> Notes: Mohon maaf ada keterlambatan data untuk retail online </p>\n",
    "\n",
    "\"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y')))\n",
    "\n",
    "html = html + tblall.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p> Dan berikut data penjualan E-Com (Before PPN) per Area :</p>\n",
    "    \"\"\"\n",
    "\n",
    "html = html + tblreg.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p> Dan Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> per Brand :</p>\n",
    "\"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y'))) \n",
    "\n",
    "\n",
    "html = html + table_brand.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p> Dan berikut data penjualan E-Com (Before PPN) per Item :</p>\n",
    "    <p> Item Launching : </p>\"\"\"\n",
    "\n",
    "html = html + new_table_launch.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> HiLo : </p>\"    \n",
    "\n",
    "html = html + table_hilo.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> L-Men : </p>\"    \n",
    "\n",
    "html = html + table_lmen.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> NutriSari : </p>\"    \n",
    "\n",
    "html = html + table_ns.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> Tropicana Slim : </p>\"    \n",
    "\n",
    "html = html + table_ts.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p></p>\n",
    "    <p> Best regards, </p>\n",
    "    <p> E-Commerce Nutrifood </p>\n",
    "<body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "Msg.HTMLBody = html\n",
    "Msg.Send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>City</th>\n",
       "      <th>Region</th>\n",
       "      <th>Region Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sulawesi Tengah</td>\n",
       "      <td>Sulawesi Tengah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12638</th>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dki Jakarta</td>\n",
       "      <td>Jabodetabek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21227</th>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bali</td>\n",
       "      <td>Bali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36742</th>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sulawesi Tenggara</td>\n",
       "      <td>Sulawesi Tenggara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45260</th>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Riau</td>\n",
       "      <td>Riau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348111</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kepulauan Riau</td>\n",
       "      <td>Kepulauan Riau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303232</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kepulauan Riau</td>\n",
       "      <td>Kepulauan Riau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338288</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kepulauan Riau</td>\n",
       "      <td>Kepulauan Riau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303171</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303170</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7123 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Store City             Region       Region Group\n",
       "3526     Tokopedia  NaN    Sulawesi Tengah    Sulawesi Tengah\n",
       "12638    Nutrimart  NaN        Dki Jakarta        Jabodetabek\n",
       "21227    Tokopedia  NaN               Bali               Bali\n",
       "36742    Tokopedia  NaN  Sulawesi Tenggara  Sulawesi Tenggara\n",
       "45260    Bukalapak  NaN               Riau               Riau\n",
       "...            ...  ...                ...                ...\n",
       "2348111     Shopee  NaN     Kepulauan Riau     Kepulauan Riau\n",
       "2303232     Shopee  NaN     Kepulauan Riau     Kepulauan Riau\n",
       "2338288     Shopee  NaN     Kepulauan Riau     Kepulauan Riau\n",
       "2303171     TikTok  NaN        Jawa Tengah        Jawa Tengah\n",
       "2303170     TikTok  NaN        Jawa Tengah        Jawa Tengah\n",
       "\n",
       "[7123 rows x 4 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[(data_all['City'].isnull())&(data_all['Region Group'].notnull())][['Store','City','Region','Region Group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingarea=pd.read_excel(\"D:\\Masterdata\\Database Area untuk Report.xlsx\")\n",
    "mappingarea=mappingarea.rename(columns=({'Region':'Real Region',\"City\":'Region Group'}))\n",
    "temp=data_all.merge(mappingarea,how='left')\n",
    "temp.loc[temp['Region Group'].isnull(),'Real Region']='Retail Online'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "osf=pd.read_excel(r\"D:\\Masterdata\\order filter.xlsx\")\n",
    "data_all[(data_all['Year'].isin([2022]))&\n",
    "         (data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Store Type','Store','Channel','Warehouse Name','Order Status','Region Group','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'masterdata_{date.today()}_lite.xlsx',index=False)\n",
    "# data_all.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel(f'Cek order gerak {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[data_all['Year']==2022][\n",
    "    ['Order #','Order Status','Year','Month','Date','Store Type','Store',\n",
    "     'Channel','Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced',\n",
    "     'Total Net Before PPN','Total','Coupon Code','Customer Name','Customer Email',\n",
    "     'Phone','Warehouse Name','City','Region Group']].to_excel(f'Masterdata Lite Order {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_val=data_all[(data_all['Store Type']!='Retail Online')&(data_all['True datetime']>'2022-04-25')&(data_all['Order Status'].isin(osf['order filter'].unique()))&(data_all['Bundle Name'].isnull())].groupby(['Order #'])[['Total']].sum().reset_index()\n",
    "ord500k=ord_val[ord_val['Total']>=500000]['Order #'].unique()\n",
    "data_all[data_all['Order #'].isin(ord500k)][['Order #','Order Status','Year','Month','Date','Store','Brand','Real SKU','Real Nama Produk','Bundle Name','Total','Total Net Before PPN','Phone','Customer Email']].to_excel(f'Order 500k update {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[(data_all['Store']=='Tokopedia')&(data_all['Year']==2022)][['Order #','Year','Month','Date','Store Type','Store','Channel','Order Status','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced','Total','Total Net','Total Net Before PPN','Customer Name','Customer Email','Phone','City','Region']].to_excel(f'Masterdata Tokopedia Customer {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalpercust=data_all[(data_all['Store Type']!='Retail Online')&(data_all['True datetime']>='2022-03-25')&(data_all['Order Status'].isin(osf['order filter'].unique()))&(data_all['Brand'].isin(['L-Men','NS','TS','WDANK','Lain Lain']))].groupby(['Store','Phone'])[['Total']].sum().reset_index()\n",
    "custloyal=totalpercust[(totalpercust['Total']>2500000)]['Phone'].unique()\n",
    "data_all[(data_all['Phone'].str.len()>7)&(data_all['Store Type']!='Retail Online')&(data_all['True datetime']>='2022-03-25')&\n",
    "         (data_all['Order Status'].isin(osf['order filter'].unique()))&(data_all['Brand'].isin(['L-Men','NS','TS','WDANK','Lain Lain']))&\n",
    "         (data_all['Phone'].isin(custloyal))][['Order #','Order Status','Year','Month','Date','Store','Brand','Real SKU','Real Nama Produk','Bundle Name','Total','Total Net Before PPN','Phone','Customer Email']].to_excel(f'Loyal Spender {date.today()}.xlsx',index=False)\n",
    "# ord500k=ord_val[ord_val['Total']>=500000]['Order #'].unique()\n",
    "# data_all[data_all['Order #'].isin(ord500k)][['Order #','Order Status','Year','Month','Date','Store','Brand','Real SKU','Real Nama Produk','Bundle Name','Total','Total Net Before PPN','Phone','Customer Email']].to_excel(f'Order 500k update {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[data_all['Total']>1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "osf=pd.read_excel(r\"D:\\Masterdata\\order filter.xlsx\")\n",
    "temp[(temp['Year'].isin([2021,2022]))&(temp['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Real Region','Store Type','Store','Channel','Order Status','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'masterdata_region_{date.today()}_lite.xlsx',index=False)\n",
    "# temp.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel(f'Cek order gerak {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf=pd.read_excel(r\"D:\\Masterdata\\order filter.xlsx\")\n",
    "temp=data_all[(data_all['Year']==2022)&(data_all['Month']=='February')&(data_all['Store']=='Lazada')&\n",
    "         (data_all['Bundle Name'].isnull())&(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Phone'])[['Total']].sum().reset_index()#.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'masterdata_region_{date.today()}_lite.xlsx',index=False)\n",
    "temp['ph len']=temp['Phone'].str.len()\n",
    "temp=temp[temp['ph len']>10]\n",
    "\n",
    "temp.loc[temp['Total']>10000000,'cat']='>10000k'\n",
    "temp.loc[temp['Total']<10000000,'cat']='<10000k'\n",
    "temp.loc[temp['Total']<5000000,'cat']='<5000k'\n",
    "temp.loc[temp['Total']<2000000,'cat']='<2000k'\n",
    "temp.loc[temp['Total']<1000000,'cat']='<1000k'\n",
    "temp.loc[temp['Total']<500000,'cat']='<500k'\n",
    "temp.loc[temp['Total']<100000,'cat']='<100k'\n",
    "\n",
    "temp.groupby('cat')[['Phone']].nunique().reset_index().sort_values('Phone',ascending=False)\n",
    "# temp[temp['cat']=='>10000k']\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all[data_all['Phone']=='=\"08111881425\"']['Store']\n",
    "from datetime import date\n",
    "osf=pd.read_excel(r\"D:\\Masterdata\\order filter.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "osf=pd.read_excel(r\"D:\\Masterdata\\order filter.xlsx\")\n",
    "data_all[(data_all['Year'].isin([2021,2022]))&(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'masterdata_{date.today()}_lite.xlsx',index=False)\n",
    "# data_all.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel(f'Cek order gerak {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resb=data_all[(data_all['Year'].isin([2021,2022]))&(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index()\n",
    "resb=resb[resb['Store Type']!='Organic']#['Store'].unique()\n",
    "resa=data_all[(data_all['Year'].isin([2022,2021]))&(data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "                           (data_all['Store Type']=='Organic')][['Order #','Year','Month','Date','Store Type','Store','Channel','Order Status','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced','Total','Total Net','Total Net Before PPN','Customer Name','Customer Email','Phone','City','Region']]\n",
    "print('tinggal append export')\n",
    "resa.append(resb).to_excel(f'masterdata_{date.today()}_custlite v2.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=data_all[(data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "         (data_all['True datetime']<'2021-12-01')&\n",
    "         (data_all['Brand'].isin(['HiLo','L-Men','NS','TS','WDANK']))&\n",
    "         (data_all['Year'].isin([2020,2021]))&\n",
    "         ~(data_all['Real SKU'].astype(str).str.contains('R|J|B|E|S'))&\n",
    "         (data_all['Store Type'].isin(['Marketplace','Organic']))].groupby(['Real SKU','Real Nama Produk','Brand','Year']).agg({'Month':'nunique','Total Net Before PPN':'sum'}).reset_index()\n",
    "temp['Monthly Sales']=temp['Total Net Before PPN']/temp['Month']\n",
    "# temp[temp[]].pivot(index=['Real SKU','Real Nama Produk'],columns='Year').reset_index()\n",
    "\n",
    "temp20=temp[temp['Year']==2020][['Real SKU','Real Nama Produk','Brand','Monthly Sales']].rename(columns={'Monthly Sales':'Monthly Sales 2020'})\n",
    "temp21=temp[temp['Year']==2021][['Real SKU','Real Nama Produk','Brand','Monthly Sales']].rename(columns={'Monthly Sales':'Monthly Sales 2021'})\n",
    "temp21=temp21.merge(temp20,how=\"left\")\n",
    "temp21['Growth']=temp21['Monthly Sales 2021']/temp21['Monthly Sales 2020']-1\n",
    "temp21\n",
    "# sg=data_all[(data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "#          (data_all['True datetime']<'2021-12-01')&\n",
    "#          (data_all['Year'].isin([2020,2021]))&\n",
    "#          (data_all['Store Type'].isin(['Marketplace','Organic']))&\n",
    "#          (data_all['Bundle Name'].isnull())].groupby(['Year','Month'])[['Total Net Before PPN']].sum().reset_index().groupby(['Year'])[['Total Net Before PPN']].mean().T\n",
    "# temp21['Store Growth']=sg[2021]['Total Net Before PPN']/sg[2020]['Total Net Before PPN']-1\n",
    "# #.to_excel([''])\n",
    "\n",
    "temp=data_all[(data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "         (data_all['True datetime']<'2021-12-01')&\n",
    "         (data_all['Brand'].isin(['HiLo','L-Men','NS','TS','WDANK']))&\n",
    "         (data_all['Year'].isin([2020,2021]))&\n",
    "         ~(data_all['Real SKU'].astype(str).str.contains('R|J|B|E|S'))&\n",
    "         (data_all['Store Type'].isin(['Marketplace','Organic']))].groupby(['Brand','Year']).agg({'Month':'nunique','Total Net Before PPN':'sum'}).reset_index()\n",
    "temp['Monthly Sales']=temp['Total Net Before PPN']/temp['Month']\n",
    "hbg=temp[(temp['Brand']=='HiLo')&(temp['Year']==2021)]['Monthly Sales'].max()/temp[(temp['Brand']=='HiLo')&(temp['Year']==2020)]['Monthly Sales'].max()-1\n",
    "tbg=temp[(temp['Brand']=='TS')&(temp['Year']==2021)]['Monthly Sales'].max()/temp[(temp['Brand']=='TS')&(temp['Year']==2020)]['Monthly Sales'].max()-1\n",
    "lbg=temp[(temp['Brand']=='L-Men')&(temp['Year']==2021)]['Monthly Sales'].max()/temp[(temp['Brand']=='L-Men')&(temp['Year']==2020)]['Monthly Sales'].max()-1\n",
    "nbg=temp[(temp['Brand']=='NS')&(temp['Year']==2021)]['Monthly Sales'].max()/temp[(temp['Brand']=='NS')&(temp['Year']==2020)]['Monthly Sales'].max()-1\n",
    "wbg=temp[(temp['Brand']=='WDANK')&(temp['Year']==2021)]['Monthly Sales'].max()/temp[(temp['Brand']=='WDANK')&(temp['Year']==2020)]['Monthly Sales'].max()-1\n",
    "print(hbg,tbg,lbg,nbg,wbg)\n",
    "\n",
    "temp21.loc[temp21['Brand']=='TS','Brand Growth']=tbg\n",
    "temp21.loc[temp21['Brand']=='HiLo','Brand Growth']=hbg\n",
    "temp21.loc[temp21['Brand']=='L-Men','Brand Growth']=lbg\n",
    "temp21.loc[temp21['Brand']=='NS','Brand Growth']=nbg\n",
    "temp21.loc[temp21['Brand']=='WDANK','Brand Growth']=wbg\n",
    "temp21[temp21['Growth']>temp21['Brand Growth']].sort_values('Monthly Sales 2021',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skupotensial=temp21[temp21['Growth']>temp21['Brand Growth']]['Real SKU'].unique()#.sort_values('Monthly Sales 2021',ascending=False).groupby(['Brand'])[['Real SKU']].nunique().reset_index()#.to_excel('item potensial growth.xlsx',index=False)\n",
    "data_all[(data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "         (data_all['True datetime']<'2021-12-01')&\n",
    "         (data_all['Brand'].isin(['HiLo','L-Men','NS','TS','WDANK']))&\n",
    "         (data_all['Year'].isin([2020,2021]))&\n",
    "         (data_all['Real SKU'].isin(skupotensial))&\n",
    "         (data_all['Store Type'].isin(['Marketplace','Organic']))].groupby(['Year','Month','Store','Real SKU','Real Nama Produk'])[['Total Net Before PPN']].sum().reset_index().to_excel('growth sku potensial.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=data_all[(data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "         (data_all['True datetime']<'2021-12-01')&\n",
    "         (data_all['Brand'].isin(['HiLo','L-Men','NS','TS','WDANK']))&\n",
    "         (data_all['Year'].isin([2020,2021]))&\n",
    "         ~(data_all['Real SKU'].astype(str).str.contains('R|J|B|E|S'))&\n",
    "         (data_all['Store Type'].isin(['Marketplace','Organic']))].groupby(['Brand','Year']).agg({'Month':'nunique','Total Net Before PPN':'sum'}).reset_index()\n",
    "\n",
    "hbg=temp[(temp['Brand']=='HiLo')&(temp['Year']==2021)]['Monthly Sales'][0]/temp[(temp['Brand']=='HiLo')&(temp['Year']==2020)]['Monthly Sales'][0]\n",
    "tbg=temp[(temp['Brand']=='HiLo')&(temp['Year']==2021)]['Monthly Sales'][0]/temp[(temp['Brand']=='HiLo')&(temp['Year']==2020)]['Monthly Sales'][0]\n",
    "hbg=temp[(temp['Brand']=='HiLo')&(temp['Year']==2021)]['Monthly Sales'][0]/temp[(temp['Brand']=='HiLo')&(temp['Year']==2020)]['Monthly Sales'][0]\n",
    "hbg=temp[(temp['Brand']=='HiLo')&(temp['Year']==2021)]['Monthly Sales'][0]/temp[(temp['Brand']=='HiLo')&(temp['Year']==2020)]['Monthly Sales'][0]\n",
    "hbg=temp[(temp['Brand']=='HiLo')&(temp['Year']==2021)]['Monthly Sales'][0]/temp[(temp['Brand']=='HiLo')&(temp['Year']==2020)]['Monthly Sales'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl=['NS', 'L-Men', 'HiLo', 'TS','WDANK']\n",
    "res=pd.DataFrame()\n",
    "skus=data_all[(data_all['Store']=='Tokopedia')&\n",
    "         (data_all['Brand'].isin(bl))&\n",
    "         (data_all['Year']==2021)&\n",
    "         ~(data_all['Real SKU'].str.contains(\"E|R|B|J\"))]['Real SKU'].unique()#['Brand'].unique()\n",
    "for sku in skus:\n",
    "    item=data_all[data_all['Real SKU']==sku]['Real Nama Produk'].unique()[0]\n",
    "    brand=data_all[data_all['Real SKU']==sku]['Brand'].unique()[0]\n",
    "    print(item)\n",
    "    temp=data_all[(data_all['Store']=='Tokopedia')&\n",
    "             (data_all['Brand'].isin(bl))&\n",
    "             (data_all['Year']==2021)&\n",
    "             (data_all['Real SKU']==sku)].groupby(['Phone']).agg({'Order #':'nunique','True datetime':'max'}).reset_index()\n",
    "    temp['Last Purchase']=datetime.now()-temp[\"True datetime\"]\n",
    "    temp.loc[temp['Order #']==1,'Status']='Trial'\n",
    "    temp.loc[temp['Order #']>1,'Status']='Repeat'\n",
    "    temp.loc[(temp['Order #']>1)&(temp['Last Purchase']<='30 days'),'Status']='Loyal'\n",
    "    temp2=temp.groupby(['Status'])[['Phone']].nunique().T\n",
    "    if (temp[temp['Status']=='Loyal']['Phone'].nunique()==0):\n",
    "        temp2['Loyal']=0\n",
    "    if (temp[temp['Status']=='Repeat']['Phone'].nunique()==0):\n",
    "        temp2['Repeat']=0\n",
    "    temp2['Total Customer']=temp2[\"Loyal\"]+temp2[\"Repeat\"]+temp2[\"Trial\"]\n",
    "    temp2['Loyal %']=temp2[\"Loyal\"]/temp2['Total Customer']\n",
    "    temp2['Repeat %']=temp2[\"Repeat\"]/temp2['Total Customer']\n",
    "    temp2['Trial %']=temp2[\"Trial\"]/temp2['Total Customer']\n",
    "    temp2['Item']=item\n",
    "    temp2['Brand']=brand\n",
    "    # temp2.reset_index(drop=True)\n",
    "    res=res.append(temp2.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[data_all['Real SKU'].isin([\"2104228230\",\"2104251230\"])].groupby(['Year','Month','Store Type','Store','Real Nama Produk'])[['Total Net Before PPN']].sum().reset_index().to_excel('spreadjam.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[data_all['Real SKU'].str.contains('E')]['Real Nama Produk'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[(data_all['Year']==2022)&(data_all['Store Type']=='Marketplace')&(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Store','Date','day_names'])[['Order #']].nunique().reset_index().to_excel('dailyorder.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## untuk vin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=data_all[(data_all['Store']=='Lazada')&(data_all['Year']==2022)][['Order #','Year','Month','Date','Store Type','Store','Channel','Order Status','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced','Total','Total Net','Total Net Before PPN','Customer Name','Customer Email','Phone','City','Region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordmc=temp[temp['Real SKU']=='2104148164']['Order #'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.loc[temp['Order #'].isin(ordmc),'Beli Mint Cocoa']='Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_excel('analisa ts mint cocoa.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_SKU[data_SKU['SKU']=='2104402P12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res\n",
    "# import seaborn as sns\n",
    "res['Norm Loyal %']=(res['Loyal %']-(res['Loyal %'].min()))/((res['Loyal %'].max())-(res['Loyal %'].min()))\n",
    "res['Norm Repeat %']=(res['Repeat %']-(res['Repeat %'].min()))/((res['Repeat %'].max())-(res['Repeat %'].min()))\n",
    "res['Norm Trial %']=(res['Trial %']-(res['Trial %'].min()))/((res['Trial %'].max())-(res['Trial %'].min()))\n",
    "res['Norm Repeat %'].min()\n",
    "for brand in res['Brand'].unique():\n",
    "    res[res['Brand']==brand][['Item','Norm Loyal %','Norm Repeat %','Norm Trial %']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_excel(\"D:\\desktop\\TRL 2nd tier.xlsx\")\n",
    "# sns.clustermap(temp[temp['Brand']=='HiLo'][['Item','Loyal %','Repeat %','Trial %']].set_index('Item'),z_score=1,yticklabels=True)\n",
    "res=pd.DataFrame()\n",
    "for brand in df['Brand'].unique():\n",
    "    print(brand)\n",
    "    temp=df[df['Brand']==brand]\n",
    "    temp['Norm Loyal %']=(temp['Loyal %']-(temp['Loyal %'].min()))/((temp['Loyal %'].max())-(temp['Loyal %'].min()))\n",
    "    temp['Norm Repeat %']=(temp['Repeat %']-(temp['Repeat %'].min()))/((temp['Repeat %'].max())-(temp['Repeat %'].min()))\n",
    "    temp['Norm Trial %']=(temp['Trial %']-(temp['Trial %'].min()))/((temp['Trial %'].max())-(temp['Trial %'].min()))\n",
    "    res=res.append(temp)\n",
    "# temp.to_excel('TRL 2nd tier.xlsx',index=False)\n",
    "# plt.savefig('save_as_a_png.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.loc[(res['Item'].str.contains('ketan',case=False))&(res['Brand']=='L-Men'),'Item']=\"L-Men Platinum Ketan Hitam 800g - 25gr protein\"\n",
    "res[res['Brand']=='L-Men']['Item'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(res[(res['Brand']=='L-Men')&(res['Item']!=\"L-Men Lose Weight Avocado Coffee 300g\")][['Item','Norm Trial %','Norm Repeat %','Norm Loyal %']].set_index('Item'),col_cluster=False,yticklabels=True)\n",
    "plt.savefig('L-Men.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['Item'].str.contains('Cookies',case=False)]\n",
    "res[res['Brand']=='TS'][['Item','Norm Loyal %','Norm Repeat %','Norm Trial %']].set_index('Item')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[(data_all['Brand']=='L-Men')&\n",
    "         (data_all['Real Nama Produk'].str.contains('daily',case=False))][['Real SKU','Real Nama Produk']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[data_all['Real SKU'].isin([\"2300551155\",\"2300542155\"])].groupby(['Year','Month','Store Type','Store','Real Nama Produk'])[['Total Net Before PPN']].sum().reset_index().to_excel('daily.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[(data_all['Year']==2021)&(data_all['Store Type']=='Marketplace')].groupby(['Year','Month','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel('order status 2021.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=data_all[data_all['Real SKU'].str.contains('B104')] # filtering\n",
    "b=a.groupby(['Store','Real Nama Produk'])[['Qty. Invoiced']].sum() # groupby\n",
    "b.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lat=data_all[data_all['Store']=='TikTok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lat\n",
    "# if Order Status == \"Delivered\":\n",
    "#     maka\n",
    "# loc\n",
    "\n",
    "data_lat.loc[data_lat['Order Status']=='Delivered','Order Status']='terkirim'\n",
    "data_lat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[data_all['Store']=='Tokopedia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
